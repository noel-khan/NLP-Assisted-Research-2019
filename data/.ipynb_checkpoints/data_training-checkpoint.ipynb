{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# OBJECTIVE: IMPORTING SOURCE DATA\n",
    "#####################################\n",
    "# DATABASE is an Excel(#,IntegerClass,BinaryClass,Abstract)\n",
    "# Convert to a list of lists using text-editor:\n",
    "#    - global replace \" with '\n",
    "#    - global replace:\n",
    "#      (\\d{0,3})\\t(\\d)\\t(\\d)\\t --> [\\1,\\2,\\3,\" \n",
    "#      (\\d{1,3})\\t{3} --> [\\1,0,0,\"\n",
    "#      \\n --> \"],\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = [[1,0,0,\"Computer vision algorithms are notorious for their computational expense. Distributed vision, the use of more than one processor, can decrease computation costs and speed up algorithms. There are various ways to do this, ranging from parallelism at the sensor level to true multiprocessor systems. This correspondence first describes a system of the latter type: a system of microprocessors on a high-speed bus. A canonical vision task, locating a number of objects and measuring certain two-dimensional features of those objects, serves as a benchmark test for the system. An algorithm for this task is presented. Performance measures are compared from implementations on the distributed system, a Vax 11/750, and a Vax 11/780. Results indicate that three microprocessors outperform a Vax 11/780 at this task. Finally, other more interesting distributed algorithms are briefly discussed.\"],\n",
    "[2,0,0,\"\"],\n",
    "[3,0,0,\"Scientific activities related to experimentation in long duration microgravity missions can only be accomplished by the implementation of the Telescience Concept. Telescience is in fact the logical answer to the need of an intelligent interactive conduct of experiments, to the lack (or very little availability) of crew time on board of the Segments of the Columbus project and to the PIs demand for decentralized operations. Telescience could also be seen as the preparative phase for the ultimate, future exploitation of Microgravity by means of Expert Systems that will utilize AI and Robotics for routine operations (Data Factories, Space Productions and Commercial Enterprises). The implications of Telescience on future Space Activities is reviewed with reference to the Principal Investigator Activities, Crew Members Roles and Facilities. The possibilities offered by newly designed Facilities to be operated in Telescience are pointed out with reference to the scientific objectives that would not be achieved otherwise. Diagnostic facilities (mainly non invasive) that provide digital measurements to be inputted (in real time) into numerical codes for computation of field parameters are being considered. Ground Segment Structure, User Support Centers Organization and Test Bedding activities will be discussed as essential factors of the Telescience Scenario of the Multiuser, permanent platform Facilities for the Microgravity disciplines (Material, Fluid, Life and Engineering Science).\"],\n",
    "[4,0,0,\"Housing for the twenty-first century will be shaped by the changes that are occurring in society. These include the demographics of the occupant, the products and materials used for construction and furnishing, and the basic use of the structure. An aging population will have different demands on design and function. The health concerns of an aging population encompass chronic degenerative diseases as well as injury. The lessons of the past must make us mindful that chronic, low-level exposures to substances can occur at home. Products and materials used in homes can release vapors that may affect immunologic and neurologic function. Manifestations of dysfunctions will be more important as our population ages and if there is a continued reliance on new chemical formulation for products used in homes and workplaces. The future portends changes in functional use of residences. Electronic communications and robotics will decentralize our work force. Manufacturing or office functions will occur at home. This will present new challenges for health and safety for both monitoring and prevention.\"],\n",
    "[5,0,0,\"\"],\n",
    "[6,0,0,\"A conceptual model of the human haptic system in relation to object identification is presented. The model encompasses major architectural elements including representations of haptically accessible object properties and exploratory procedures (EPs)--dedicated movement patterns that are specialized to extract particular properties. These architectural units are related in processing-specific ways. Properties are associated with exploratory procedures in keeping with the extent to which a given procedure delivers information about a given property. The EPs are associated with one another in keeping with their compatibility, as determined by parameters of motor execution and interactions with the object and the workspace. The resulting architecture is treated as a system of constraints which guide the exploration of an object during the course of identification. The selection of the next step in a sequence of exploration requires that constraints be optimally satisfied. A network approach to constraint satisfaction is implemented and shown to account for a number of previous empirical results concerning the time course of exploration, object classification speed, and incidental learning about object properties. This system has potential applications for robotic haptic exploration.\"],\n",
    "[7,0,0,\"The effects of human error on aviation and space flight are discussed and the role of human factor engineering in aviation and aerospace safety is examined. Specific areas discussed are docking and extravehicular activity; quantification of human capacity for space station design; and measurement of habitability, workload, and task analysis.\"],\n",
    "[8,0,0,\"The rapid development of minimally invasive surgery means that there will be fundamental changes in interventional treatment. Technological advances will allow new minimally invasive procedures to be developed. Application of robotics will allow some procedures to be done automatically, and coupling of slave robotic instruments with virtual reality images will allow surgeons to perform operations by remote control. Miniature motors and instruments designed by microengineering could be introduced into body cavities to perform operations that are currently impossible. New materials will allow changes in instrument construction, such as use of memory metals to make heat activated scissors or forceps. With the reduced trauma associated with minimally invasive surgery, fewer operations will require long hospital stays. Traditional surgical wards will become largely redundant, and hospitals will need to cope with increased through-put of patients. Operating theatres will have to be equipped with complex high technology equipment, and hospital staff will need to be trained to manage it. Conventional nursing care will be carried out more in the community. Many traditional specialties will be merged, and surgical training will need fundamental revision to ensure that surgeons are competent to carry out the new procedures.\"],\n",
    "[9,0,0,\"Automated materials handling systems have provided dramatic labor savings and efficiency benefits to healthcare facilities. A growing trend is the use of a new breed of service robots that provide automated materials handling without major modifications to the existing building. The robots navigate through hallways, go through doors and ride elevators using a computerized controller that contains a layout of each floor of the hospital; the robots do not rely on any type of physical track to guide them on their way. The robots are programmed to pick up or deliver supplies to nursing stations or other departments, and determine the best route. Purchase and rental options exist at a substantial savings over human labor.\"],\n",
    "[10,0,0,\"The project's aim is to develop a dedicated workstation in order to process multiple channels of electrophysiological signals in real-time during sleep. In ESPIS we are aiming to define both an architecture and an environment for EEG signal interpretation in medicine based on computer science gold standards (Unix, XWindow, Motif). Signal processing and pattern recognition analysis are provided by parallel processing on a specific developed acquisition architecture (DSP) based on transputers. The main result is a high performance prototype demonstrating signal interpretation during sleep which has already been tested in a medical environment. The overall specifications allow this biomedical device to be extended to other types of medical signals.\"],\n",
    "[11,0,0,\"In this paper we propose a parallel network which gradually computes the three-dimensional (3-D) structure of a moving scene from its image sequence, using an incremental scheme based upon a constraint called the maximal rigidity principle. At each instant an internal model (i.e., current estimate) of the 3-D structure is updated, based upon the observations accumulated until then. The updating process favors rigid transformations but tolerates a limited amount of deviation from rigidity. This deviation eventually leads the internal model to converge towards the actual 3-D structure of the scene, An application of this network to the problem of structure from two views is also presented. The main advantage of this architecture is its ability to accurately estimate the 3-D structure of a scene, at a low computational cost. Testing has been successfully performed on synthetic data as well as real image sequences.\"],\n",
    "[12,0,0,\"Since torque in harmonic drives is transmitted by a pure couple, harmonic drives do not generate radial forces and therefore can be instrumented with torque sensors without interference from radial forces. The installation of torque sensors on the stationary component of harmonic drives (the Flexipline cup in this research work) produce backdrivability needed for robotic and telerobotic compliant maneuvers. Backdrivability of a harmonic drive, when used as torque increaser, means that the output shaft can be rotated via finite amount of torque. A high ratio harmonic drive is non-backdrivable because its output shaft cannot be turned by applying a torque on it. This article first develops the dynamic behavior of a harmonic drive, in particular the non-backdrivability, in terms of a sensitivity transfer function. The instrumentation of the harmonic drive with torque sensor is then described. This leads to a description of the control architecture which allows modulation of the sensitivity transfer function within the limits established by the closed-loop stability. A set of experiments on an active hand controller, powered by a DC motor coupled to an instrumented harmonic drive, is given to exhibit this method's limitations.\"],\n",
    "[13,1,0,\"The industrial robot's dynamic performance is frequently measured by positioning accuracy at high speeds and a good dynamic controller is essential that can accurately compute robot dynamics at a servo rate high enough to ensure system stability. A real-time dynamic controller for an industrial robot is developed here using neural networks. First, an efficient time-selectable hidden layer architecture has been developed based on system dynamics localized in time, which lends itself to real-time learning and control along with enhanced mapping accuracy. Second, the neural network architecture has also been specially tuned to accommodate servo dynamics. This not only facilitates the system design through reduced sensing requirements for the controller but also enhances the control performance over the control architecture neglecting servo dynamics. Experimental results demonstrate the controller's excellent learning and control performances compared with a conventional controller and thus has good potential for practical use in industrial robots.\"],\n",
    "[14,0,0,\"This paper describes the development of a system for simultaneous planning and execution of surgical operations in the cranio-maxillo facial area. Simultaneous planning and execution is the process of taking an implicit task description, planning a sequence of explicit execution commands e.g. for robots and monitoring their execution. As the execution planning process is running completely on-line, that means during the actual execution of the assembly task, the planning process is highly reactive based on sensor information about the robot's present environment. In order to meet the problem that medical data is usually complex and needs time-costly preprocessing an appropriate architecture for evaluating sensor data has been developed. In this paper, a detailed presentation of the phases of execution planning and sensor data evaluation is given. As an example, the execution of a LeFort I osteotomy is presented.\"],\n",
    "[15,0,0,\"This paper describes the development of a system for simultaneous planning and execution of surgical operations in the cranio-maxillo-facial area. Simultaneous planning and execution is the process of taking an implicit task description, planning a sequence of explicit execution commands (e.g. for robots) and monitoring their execution. As the execution planning process is run completely on-line, during the execution of the assembly task, the planning process is highly reactive, based on sensor information about the robot's present environment. In order to meet the problem that medical data are usually complex and need time-consuming preprocessing, an appropriate architecture for evaluating sensor data has been developed. In this paper, a detailed presentation of the phases of execution planning and sensor data evaluation is given. As an example, the execution of a LeFort I osteotomy is presented.\"],\n",
    "[16,0,0,\"The aim of this paper is to illustrate the AGROBOT project. This project was initiated to develop a complete robotic system for the production cycle of tomato plants in a greenhouse environment. The robot architecture is based on a vehicle carrying the picking arm (a six degrees of freedom anthropomorphic arm with a gripper/hand), the head with the two micro cameras (for the color stereoscopic vision system) and the VME rack for the complete control of the system. The head was purposely developed to permit complete visibility of the overall area. The vision system drives the head to point the path during navigation or to explore the plants looking for the work objects. The robot will be able to navigate between rows of plants, stop near each plant and identify the relevant objects (fruits or flowers) so as to be able to pick ripe tomatoes or spray anticryptogamic substances on flowers. Due to its flexible architecture, the system can be suited to operate on other kinds of cultivation or could be modified to perform other kinds of operations such as transplanting or packaging. Also the field of action could be different from greenhouses: changing from a wheeled locomotion system to a tracked system, the robot will be able to operate on particularly irregular surfaces. These features make this robotic system particularly adapted to replace human from tiring and harmful tasks or operating within adverse environment.\"],\n",
    "[17,0,0,\"Many robotics and navigation systems utilizing stereopsis to determine depth have rigid size and power constraints and require direct physical implementation of the stereo algorithm. The main challenges lie in managing the communication between image sensor and image processor arrays, and in parallelizing the computation to determine stereo correspondence between image pixels in real-time. This paper describes the first comprehensive system level demonstration of a dedicated low-power analog VLSI (very large scale integration) architecture for stereo correspondence suitable for real-time implementation. The inputs to the implemented chip are the ordered pixels from a stereo image pair, and the output is a two-dimensional disparity map. The approach combines biologically inspired silicon modeling with the necessary interfacing options for a complete practical solution that can be built with currently available technology in a compact package. Furthermore, the strategy employed considers multiple factors that may degrade performance, including the spatial correlations in images and the inherent accuracy limitations of analog hardware, and augments the design with countermeasures.\"],\n",
    "[18,0,0,\"\"],\n",
    "[19,0,0,\"A courier robot at Abington Memorial Hospital has allowed the hospital to maintain high standards of patient care in the face of budget constraints. The robot handles after-hours deliveries of meals and supplies efficiently and cost-effectively, thus freeing support staff to focus on other tasks.\"],\n",
    "[20,0,0,\"The clinical laboratory is changing from a place of activity based on sample analysis to an in vitro diagnostic network. To convince our team, partners, and administrators, we need new comprehensive tools to define a strategy with limited risk of failure or conflicts. Specific quality goals should be established before choosing automated tools for sample handling, analytical systems, laboratory information systems, communication systems, or advanced technologies. A system approach maps and simplifies the process, based more on a functional study than on classical disciplines. A customer-supplier approach establishes the requirements between partners either inside or outside the laboratory. The quality system must be a management tool, linking samples, tasks, information, and documents. Quantitative simulation modeling explores different automation alternatives and their impact on laboratory workflow. Finally, integration of results in interactive semirealistic simulation tools for laboratory design or reengineering can be used as communications tools to involve laboratory professionals in the change of their practice.\"],\n",
    "[21,0,0,\"In maxillofacial surgery the quality of the surgical outcome mainly depends on the experience of the operating surgeon. Thus we intend to support the surgeon before and during surgery in order to enhance the surgical results. On the one hand this implies the use of image processing, three dimensional modelling techniques and visualization techniques of medical image data, on the other hand planning systems, intraoperative navigation devices and surgical robots are needed. In this paper a complex expert system is presented, which uses a planner for generating treatment plans, an infrared navigation for monitoring both patient, robot, and surgical tool, and a surgical robotic system in order to work on bone. Special stress is laid on the architecture of the planning system, the structure of the treatment plans, and the intraoperative communication protocols.\"],\n",
    "[22,0,0,\"\"],\n",
    "[23,5,0,\"This paper proposes a new self-organizing, biologically-inspired control architecture for mobile robots consisting of a controller and a value system. The controller uses activity patterns of visual sensors to determine the motor commands, whereas the value system receives stimuli from proprioceptive sensors. This design decision is justified by the following arguments: (1) the feedback of proprioceptive sensory patterns is omnipresent in biological systems and has been widely neglected in control systems, (2) both components are significantly decoupled by using different sensory modalities, and (3) proprioceptive sensors operate more reliably and can be used more efficiently than visual sensors, such as pixels in a CCD camera. Practical experiments with the Khepera robot show that by using proprioceptive sensor values, the control architecture can adapt to different environments and yield very robust behavior with respect to, for example, sensor failures. Furthermore, the new control architecture can be easily enhanced by further components.\"],\n",
    "[24,0,0,\"A new generation biochip is described as capable of supporting high-throughput (HT), multiplexed enzyme-linked immunosorbent assays (ELISAs). These biochips consist of an optically flat, glass plate containing 96 wells formed by an enclosing hydrophobic Teflon mask. The footprint dimensions of each well and the plate precisely match those of a standard microplate. Each well contains four identical 36-element arrays (144 elements per well) comprising 8 different antigens and a marker protein. Arrays are formed by a custom, continuous flow, capillary-based print head attached to a precise, high-speed, X-Y-Z robot. The array printing capacity of a single robot exceeds 20,000 arrays per day. Arrays are quantitatively imaged using a custom, high-resolution, scanning charge-coupled device (CCD) detector with an imaging throughout of 96 arrays every 30 s. Using this new process, arrayed antigens were individually and collectively detected using standard ELISA techniques. Experiments demonstrate that specific multiplex detection of protein antigens arrayed on a glass substrate is feasible. Because of the open microarray architecture, the 96-well microarray format is compatible with automated robotic systems and supports a low-cost, highly parallel assay format. Future applications of this new high-throughput screening (HTS) format include direct cellular protein expression profiling, multiplexed assays for detection of infectious agents and cancer diagnostics.\"],\n",
    "[25,0,0,\"ARTEMIS, the Advanced Robotics and TElemanipulator System for Minimally Invasive Surgery, is designed as an integrated teleoperation and telepresence system for planning, training and performing different minimally invasive surgical procedures. The actual prototype was developed as an experimental device for exploring and testing the needed technologies and their capability and quality with respect to surgical application. The main components are two master-slave units guiding the surgical instruments and a remotely controlled endoscope guiding system. Each master-slave device consists of the slave or work unit and the master or control unit which are interconnected by a computer based control system. The work unit is operating at the patient by means of dexterous surgical instruments consisting of multifunctional endoeffectors with flexible distal section providing six degrees of freedom. The kinematic structure of the work unit ensures a precise motion around the incision point through the abdominal or thoracic wall. The master or control unit guided by the surgeon is designed to enable the surgeon to operate intuitively as if he were guiding the tip of the endoeffector manually. The powered endoscope guiding system is equipped with a 3D-endoscope. The computer based control system interconnecting control and work units has an open system architecture which allows to couple differently designed masters and slaves, monitoring systems, graphical system and user interfaces. The endoscope can be guided by a simple joystick, voice control or automatic camera tracking. For minimally invasive cardiac surgery a new concept has to be developed. In co-operation with the Cardiovascular Institute of the University of Dresden a step-by-step procedure was agreed. The state-of-the-art is described.\"],\n",
    "[26,0,0,\"Advances in computer technology will revolutionize surgical techniques in the next decade. The operating room (OR) of the future will be connected with a laboratory where clinical specialists and researchers prepare image-guided interventions and explore the possibilities of these techniques. The virtual reality is linked to the actual situation in the OR with the aid of navigation instruments. During complicated operations the images prepared preoperatively will be corrected during the operation on the basis of the information obtained peroperatively. MRI currently offers maximal possibilities for image-guided surgery of soft tissues. Simpler techniques such as fluoroscopy and echography will become increasingly integrated in computer-assisted peroperative navigation. The development of medical robot systems will make possible microsurgical procedures by the endoscopic route. Tele-manipulation systems will also play a part in the training of surgeons. Design and construction of the OR will be adapted to the surgical technology, and include an information and control unit where preoperative and peroperative data come together and from where the surgeon operates the instruments. Concepts for the future OR should be regularly adjusted to allow for new surgical technology.\"],\n",
    "[27,0,0,\"Spatiotemporal arm and body movements of able-bodied subjects performing nine everyday tasks were recorded for the purpose of guiding the development of an upper-limb orthosis. To provide a user the opportunity to carry out these tasks with natural movements, the orthosis should allow replication of the measured trajectories. We outline the orthosis architecture, which supports the user's upper arm and forearm, and analyze the movement data to obtain orthosis design specifications. Trajectories were obtained using six-degree-of-freedom magnetic position sensors affixed to the wrist, elbow, shoulder, trunk and head. Elbow trajectory data were decomposed into ranges along the principle Cartesian axes to provide a generally useful envelope measure. The smallest Cartesian parallel-piped that contained the elbow trajectories for most tasks was approximately 30 cm front/back, 15 cm side/side, and 17 cm up/down. A rough lower bound estimate obtained by asking subjects to repeat the tasks while minimizing elbow movement substantially reduced movement in the up/down and side/side dimensions. Elbow angles were generally in the range 50 degrees-150 degrees, and the angle of the forearm with respect to vertical was 10 degrees-110 degrees. Raw trajectory data may be downloaded from www://asel.udel.edu/robotics/orthosis/range.h tml.\"],\n",
    "[28,0,0,\"This research is motivated by the need to design a Nuclear Magnetic Resonance Image guided surgical robot. The achievement of this objective requires the solution of two problems: design and construction of a magnetic resonance compatible mechanical manipulator and development of the appropriate robot control system. It is beneficial to keep robot actuators outside the magnet. Therefore, the parallel architecture should be used for the mechanical manipulator. Newly developed University of Western Australia Robot satisfies this requirement. Moreover, it has substantially larger workspace and torsional stiffness when compared to existing parallel configurations such as the Delta. The plausible method of dealing with the delays in the robot control system caused by the image analysis is the prediction of the deformation based on the mathematical model of the organ mechanical and geometric properties. The hyper-viscoelastic constitutive models offer a good way of representing non-linear stress-strain and stress-strain rate relations of soft tissues such as the brain. The numerical values for material constants for brain tissue are given. Additional advantage of the proposed model is that it can be easily implemented in commercially available finite element codes and immediately applied to large-scale computer simulations.\"],\n",
    "[29,1,0,\"The evolution of simulated robots with three different architectures is studied in this article. We compare a nonmodular feed-forward network, a hardwired modular, and a duplication-based modular motor control network. We conclude that both modular architectures outperform the non-modular architecture, both in terms of rate of adaptation as well as the level of adaptation achieved. The main difference between the hardwired and duplication-based modular architectures is that in the latter the modules reached a much higher degree of functional specialization of their motor control units with regard to high-level behavioral functions. The hardwired architectures reach the same level of performance, but have a more distributed assignment of functional tasks to the motor control units. We conclude that the mechanism through which functional specialization is achieved is similar to the mechanism proposed for the evolution of duplicated genes. It is found that the duplication of multifunctional modules first leads to a change in the regulation of the module, leading to a differentiation of the functional context in which the module is used. Then the module adapts to the new functional context. After this second step the system is locked into a functionally specialized state. We suggest that functional specialization may be an evolutionary absorption state.\"],\n",
    "[30,0,0,\"We present the concept of a system architecture for the computer aided craniofacial surgery. The architecture is based on CORBA, an industrial standard specification for the development of distributed applications. Our concept includes a fundamental behaviour oriented communication model and some fundamental software safety considerations. We've developed a standard library for the integration of new services and devices into our system architecture. It decreases development time noticeably. We tested the performance and usability of our concept on an evaluation set up consisting of a surgery robot system, an infrared navigation system, a force-torque sensor and a visualisation software, obtaining excellent results. Future work will consist in the integration of further devices and the extension of our safety concept. An accurate clinical evaluation will take place continuously.\"],\n",
    "[31,0,0,\"The outcome variability and failures of conventional osteotomy have been attributed to lack of preoperative planning and inaccuracy in performing the correction. We present a computer and robotic assisted surgery system that can aid in accurate surgical planning for realignment, and in precisely implementing the plan in theatre. The approach seeks to avoid the cost and risks associated with the use of CT, and the insertion of fiducial markers, which are characteristic of existing computer assisted surgical systems. The paper details the architecture of the system as a whole, placing particular emphasis on planning technique. It is anticipated that the increased accuracy possible with the system will prove particularly useful for correcting multi-plane deformities, which are more problematic with conventional techniques.\"],\n",
    "[32,0,0,\"The aim of the study was to perform endoscopic coronary artery bypass grafting on the beating heart using a surgical robotic system. In the study, the surgical system ZEUS was used in combination with 3D visualization for endoscopic coronary artery bypass grafting in 25 patients. In a total of 10 cases, the coronary artery anastomosis was done on the beating heart using endoscopic stabilizers without cardiopulmonary bypass. In all cases, total OR time ranged from 4.0 to 8.0 hours (median 5.5 h); the times for endoscopic coronary artery anastomoses ranged from 14 to 50 minutes (median 25 minutes) with no difference between arrested-heart or beating-heart procedures. All patients had an uneventful angiographic control result. An endoscopic coronary artery anastomosis is possible on the arrested as well as on the beating heart.\"],\n",
    "[33,0,0,\"BACKGROUND: The advantages of surgical robots and manipulators are well recognized in the clinical and technical community. Precision, accuracy and the potential for telesurgery are the prime motivations in applying advanced robot technology in surgery. In this paper critical interactions between Magnetic Resonance Imaging equipment and mechatronic devices are discussed and a novel Magnetic Resonance compatible surgical robot is described. MATERIAL AND METHODS: Experimental results of the effects from several passive (metallic materials) and active (ultrasound motors) mechanical elements are demonstrated. The design principles for Magnetic Resonance compatible robots are established and the compatibility of the proposed robot is assessed by comparing images taken with and without the robot's presence within Signa SP/I GE Medical Systems scanner. RESULTS: The results showed that, in principle, it is possible to construct precision mechatronic devices intended to operate inside MR scanner. Use of such a device will not cause image shift or significant degradation of signal-to-noise-ratio. An MR compatible surgical assist robot was designed and constructed. The robot is not affected by the presence of strong magnetic fields and is able to manoeuvre during imaging without compromising the quality of images. A novel image-guided robot control scheme was proposed. As a part of the control scheme, biomechanics-based organ deformation model was constructed and validated by in-vivo experiment. It has been recognised that for robust control of an image guided surgical robot the precise knowledge of the mechanical properties of soft organs operated on must be known. As an illustration, results in mathematical modelling and computer simulation of brain deformation are given. CONCLUSION: The novel MR compatible robot was designed to position and direct an axisymmetric tool, such as a laser pointer or a biopsy catheter. New Robot control system based on the prediction of soft organ deformation was proposed.\"],\n",
    "[34,5,0,\"Any biological object, and specifically the brain, is the result of evolution. Evolution proceeds by accumulation and combination of stable intermediate states-as is well known, survival of the fittest really means survival of the stable. Simple examples abound: for instance, human emotional response involves both a fast archaic loop bypassing the cortex, and a slower cortical loop; motion control architecture in vertebrates is believed to involve combinations of simple motor primitives. However, in themselves, accumulations and combinations of stable elements have no reason to be stable. Hence the hypothesis that evolution will favor a particular form of stability, which automatically guarantees stability in combination. Such a form of stability, which we refer to as 'contraction,' can be characterized mathematically. Thus, contraction theory may help guide functional modeling of the central nervous system, and conversely it provides a systematic method to build arbitrarily complex robots out of simpler elements. Furthermore, contraction theory may shed light on the problem of perceptual unity (binding problem) by providing simple models and conditions for the overall convergence of a large number of specialized processing elements connected through networks of feedback loops.\"],\n",
    "[35,0,0,\"Today, surgeons accept computer assisted technologies as important tools to enhance the treatment of a patient. The positive impact and acceptance of computer assisted technologies could be increased to a great extent, if all methods and devices used for diagnosis and treatment of a patient are better co-ordinated and more finely tuned. Often computer assisted treatments cannot be performed due to a lack of communication between hospital departments, useless patient data, deficient interfaces, etc. Risks for the patient and potential errors within the treatment are often unrecognised, as up to now the safety of computer integrated surgery is only product-, device and security oriented. We have developed a new approach for a safety architecture, which includes safety aspects considering patients, users, interdependencies and interactions of computer assisted methods and apparatuses.\"],\n",
    "[36,0,0,\"An overview of the development of the International Space Station (ISS) is presented starting with a brief history of space station concepts from the 1960's to the decision to build the present ISS. Other topics discussed include partnerships with Japan, Canada, ESA countries, and Russia; design changes to the ISS modules, the use of the ISS for scientific purposes and the application of space research to medicine on Earth; building ISS modules on Earth, international funding for Russian components, and the political aspects of including Russia in critical building plans. Sidebar articles examine commercialization of the ISS, multinational efforts in the design and building of the ISS, emergency transport to Earth, the use of robotics in ISS assembly, application of lessons learned from the Skylab project to the ISS, initial ISS assembly in May 1999, planned ISS science facilities, and an overview of space stations in science fiction.\"],\n",
    "[37,0,0,\"\"],\n",
    "[38,0,0,\"A revolutionary new concept for the early establishment of robust, self-sustaining Martian colonies is described. The colonies would be located on the North Polar Cap of Mars and utilize readily available water ice and the CO2 Martian atmosphere as raw materials to produce all of the propellants, fuel, air, water, plastics, food, and other supplies needed by the colony. The colonists would live in thermally insulated large, comfortable habitats under the ice surface, fully shielded from cosmic rays. The habitats and supplies would be produced by a compact, lightweight (~4 metric tons) nuclear powered robotic unit termed ALPH (Atomic Liberation of Propellant and Habitat), which would land 2 years before the colonists arrived. Using a compact, lightweight 5 MW (th) nuclear reactor/steam turbine (1 MW(e)) power source and small process units (e.g., H2O electrolyzer, H2 and O2 liquefiers, methanator, plastic polymerizer, food producer, etc.) ALPH would stockpile many hundreds of tons of supplies in melt cavities under the ice, plus insulated habitats, to be in place and ready for use when the colonists landed. With the stockpiled supplies, the colonists would construct and operate rovers and flyers to explore the surface of Mars. ALPH greatly reduces the amount of Earth supplied material needed and enables large permanent colonies on Mars. It also greatly reduces human and mission risks and vastly increases the capability not only for exploration of the surrounding Martian surface, but also the ice cap itself. The North Polar Cap is at the center of the vast ancient ocean that covered much of the Martian Northern Hemisphere. Small, nuclear heated robotic probes would travel deep (1 km or more) inside the ice cap, collecting data on its internal structure, the composition and properties of the ancient Martian atmosphere, and possible evidence of ancient life forms (microfossils, traces of DNA, etc.) that were deposited either by wind or as remnants of the ancient ocean. Details of the ALPH system, which is based on existing technology, are presented. ALPH units could be developed and demonstrated on Earth ice sheets within a few years. An Earth-Mars space transport architecture is described, in which Mars produced propellant and supplies for return journeys to Earth would be lifted with relatively low DeltaV to Mars orbit, and from there transported back to Earth orbit, enabling faster and lower cost trips from Earth to Mars. The exploration capability and quality of life in a mature Martian colony of 500 persons located on the North Polar Cap is outlined.\"],\n",
    "[39,0,0,\"\"],\n",
    "[40,0,0,\"Although it has been over 15 years since the first recorded use of a robot for a surgical procedure, the field of medical robotics is still an emerging one that has not yet reached a critical mass. Although robots have the potential to improve the precision and capabilities of physicians, the number of robots in clinical use is still very small. In this review article, we begin with a short historical review of medical robotics, followed by an overview of clinical applications where robots have been applied. The clinical applications are then discussed; they include neurosurgery, orthopedics, urology, maxillofacial surgery, radiosurgery, ophthalmology, and cardiac surgery. We conclude with a listing of technology challenges and research areas, including system architecture, software design, mechanical design, imaging compatible systems, user interface, and safety issues.\"],\n",
    "[41,5,0,\"This article describes an expanded version of a previously proposed motor control scheme, based on rules for combining sensory and motor signals within the central nervous system. Classical control elements of the previous cybernetic circuit were replaced by artificial neural network modules having an architecture based on the connectivity of the cerebellar cortex, and whose functioning is regulated by reinforcement learning. The resulting model was then applied to the motion control of a mechanical, single-joint robot arm actuated by two McKibben artificial muscles. Various biologically plausible learning schemes were studied using both simulations and experiments. After learning, the model was able to accurately pilot the movements of the robot arm, both in velocity and position.\"],\n",
    "[42,5,0,\"In studying brain activity during the behavior of living animals, it is not possible simultaneously to analyze all levels of control from molecular events to motor responses. To provide insights into how levels of control interact, we have carried out synthetic neural modeling using a brain-based real-world device. We describe here the design and performance of such a device, designated Darwin VII, which is guided by computer-simulated analogues of cortical and subcortical structures. All levels of Darwin VII's neural architecture can be examined simultaneously as the device behaves in a real environment. Analysis of its neural activity during perceptual categorization and conditioned behavior suggests neural mechanisms for invariant object recognition, experience-dependent perceptual categorization, first-order and second-order conditioning, and the effects of different learning rates on responses to appetitive and aversive events. While individual Darwin VII exemplars developed similar categorical responses that depended on exploration of the environment and sensorimotor adaptation, each showed highly individual patterns of changes in synaptic strengths. By allowing exhaustive analysis and manipulation of neuroanatomy and large-scale neural dynamics, such brain-based devices provide valuable heuristics for understanding cortical interactions. These devices also provide the groundwork for the development of intelligent machines that follow neurobiological rather than computational principles in their construction.\"],\n",
    "[43,0,0,\"The crystallization facility of the TB (Tuberculosis) structural genomics consortium, one of nine NIH sponsored p50 structural genomic centres, provides TB consortium members with automated crystallization, data collection and basic molecular replacement (MR) structure solution up to bias minimized electron density maps. Crystallization setup of up to ten proteins per day follows the CRYSTOOL combinatorial screen protocol using a modular and affordable robotic design with an open architecture. Components include screen preparation, plate setup, automated image acquisition and analysis, and optimisation design. A new 96 well crystallization plate has been designed for optimal robotic handling while maintaining ease of manual crystal harvesting. Robotic crystal mounting, screening, and data collection are conducted in-house and at the Advanced Light Source (ALS) in Berkeley. A simple automated protocol based on MR and homology based structure prediction automatically solves modestly difficult problems. Multiple search models are evaluated in parallel MR and the best multi-segment rigid body refined MR solution is subjected to simulated annealing torsion angle molecular dynamics using CNS, bringing even marginal MR solutions within the convergence radius of the subsequent highly effective bias removal and map reconstruction protocol, Shake&wARP, used to generate electron density for initial rebuilding. Real space correlation plots allow rapid assessment of local structure quality. Modular design of robotics and automated scripts using publicly available programs for structure solution allow for efficient high throughput crystallography - at a reasonable cost.\"],\n",
    "[44,0,0,\"The Environmental Restoration Contractor at the Hanford Site is tasked with removing auxiliary reactor structures and leaving the remaining concrete structure surrounding each reactor core. This is referred to as Interim Safe Storage. Part of placing the F Reactor into Interim Safe Storage is the demolition of the fuel storage basin, which was deactivated in 1970 by placing debris material into the basin prior to back filling with soil. Besides the debris material (wooden floor decking, handrails, and monorail pieces), the fuel storage basin contents included the possibility of spent nuclear fuel, fuel buckets, fuel spacers, process tubes, and tongs. Demolition of the fuel storage basin offered many unique radiological control challenges and innovative approaches to demolition. This paper describes how the total effective dose equivalent and contamination were controlled, how the use of a remote operated excavator was employed to remove high-dose-rate material, and how wireless technology was used to monitor changing radiological conditions.\"],\n",
    "[45,5,0,\"A novel hierarchical neural network architecture for sensory-motor learning and behavior generation is proposed. Two levels of forward model neural networks are operated on different time scales while parametric interactions are allowed between the two network levels in the bottom-up and top-down directions. The models are examined through experiments of behavior learning and generation using a real robot arm equipped with a vision system. The results of the learning experiments showed that the behavioral patterns are learned by self-organizing the behavioral primitives in the lower level and combining the primitives sequentially in the higher level. The results contrast with prior work by Pawelzik et al. [Neural Comput. 8 (1996) 340], Tani and Nolfi [From animals to animats, 1998], and Wolpert and Kawato [Neural Networks 11 (1998) 1317] in that the primitives are represented in a distributed manner in the network in the present scheme whereas, in the prior work, the primitives were localized in specific modules in the network. Further experiments of on-line planning showed that the behavior could be generated robustly against a background of real world noise while the behavior plans could be modified flexibly in response to changes in the environment. It is concluded that the interaction between the bottom-up process of recalling the past and the top-down process of predicting the future enables both robust and flexible situated behavior.\"],\n",
    "[46,5,0,\"Robotics involves complex processing and requires modular controllers. For the connectionist approach, the adaptation of each module within the global system remains a major problem to be solved. This paper proposes the idea that biological learning can take advantage of the structures of the modules and the nature of modular decomposition. Therefore, we address this problem starting with the architecture of the system. We illustrate this approach using a robotic application: the visual servoing of the arm's end-effector. The on-line adaptation of a simple controller permits excellent results. To process several variables, and to limit the size of the memory required, this controller is decomposed into modules, in the image of sensorial or motor processing centers. The learning of the modules is realized on-line, a bi-directional architecture permits the adaptation of each module using a simple algorithm. The results obtained with various modular arrangements, both during intensive computer simulations and on our robotic platform, confirm the practical interest of this approach.\"],\n",
    "[47,5,0,\"As the complexity of the missions to planetary surfaces increases, so too does the need for autonomous rover systems. This need is complicated by the power, mass and computer storage restrictions on such systems (Miller, D. P. (1992). Reducing software mass through behaviour control. In Proceedings SPIE conference on cooperative intelligent robotics in space III (Vol. 1829, pp. 472-475, 1992). Boston, MA. To address these problems, we have recently developed a system called BISMARC (Biologically Inspired System for Map-based Autonomous Rover Control) for planetary missions involving multiple small, lightweight surface rovers (Huntsberger, T. L. (1997). Autonomous multirover system for complex planetary retrieval operations. In P. S. Schenker, and G. T. McKee (Eds.), Proceedings SPIE symposium on sensor fusion and decentralized control in autonomous robotic systems (pp. 221-227). Pittsburgh, PA). BISMARC is capable of cooperative planetary surface retrieval operations such as a multiple cache recovery mission to Mars. The system employs autonomous navigation techniques, behavior-based control for surface retrieval operations, and an action selection mechanism based on a modified form of free flow hierarchy (Rosenblatt, J. K. and Payton, D. W. (1989). A fine-grained alternative to the subsumption architecture for mobile robot control. In Proceedings IEEE/INNS joint conference on neural networks (pp. 317-324). Washington, DC). This paper primarily describes the navigation and map-mapping subsystems of BISMARC. They are inspired by some recent studies of London taxi drivers indicating that the right hippocampal region of the brain is activated for path planning but not for landmark identification (Maguire, E. A. et al. (1997). Recalling routes around London: activation of the right hippocampus in taxi drivers. Journal of Neuroscience, 17(18), 7103-7110). We also report the results of some experimental studies of simulated navigation in planetary environments.\"],\n",
    "[48,5,0,\"Multiagent systems are powerful and flexible tools for modelling and regulating complex phenomena. In fact, a way to manage the complexity of a phenomenon is to decompose it in such a way that each agent embeds the control model for a portion of the phenomenon. In this perspective, the cooperative interaction among the agents results in the controller for the whole phenomenon. Since the portions in which the phenomenon is decomposed may overlap, the actions the single agents undertake to regulate these portions may conflict; hence a balanced negotiation is required. A class of complex phenomena that present several difficulties in their satisfactory modelling and controlling is the class of physiological processes. The purpose of this paper is to introduce a general multiagent architecture, called anthropic agency, for the modelling and the regulation of complex physiological phenomena.\"],\n",
    "[49,0,0,\"Benchmarks and design criteria previously used for planning consolidated laboratories such as bed size, staffing, and test volumes no longer apply. To achieve greater operational efficiencies, consolidated laboratories should be designed with open, flexible, and adaptable space using work flow/workstations, instrumentation requirements, and the degree of automation as the key design criteria. The primary objective of most consolidations is the reduction of staff with a substantial increase in workload. A critical factor when planning a consolidated laboratory is the ability of the space to accommodate the increase in testing and procedures to serve multiple facilities and growing outreach programs with fewer FTEs. Designing the laboratory starts with a thorough evaluation of work flow, testing procedures, desired adjacencies, and relationships within the laboratory. An area analysis should be developed describing in detail projected space requirements. Consideration should be given for the incorporation of automation/robotics and new, more efficient, and comprehensive instrumentation. Safety, noise, vibration control, lighting, and engineering support systems are all critical issues that also must be effectively addressed and incorporated into the design. Specific issues that will be discussed at this program include projected space requirements; review and development of existing and projected workstations; equipment requirements; lighting options; workload and procedures review; staffing procedures; flexibility/adaptability; relationships and adjacencies; flow diagrams; plan development; cost implications, on-site versus off-site facilities; and new construction versus renovation construction cost comparisons. Using specific examples from consolidated laboratory projects, we have designed a case study presentation by the laboratory director from a recently completed laboratory consolidation project serving a multihospital system. We will discuss the new design criteria and benchmarks that must be established to create a functional, operationally efficient, and profitable laboratory consolidation.\"],\n",
    "[50,0,0,\"This paper presents STARS (Simulation and Transfer Architecture for Robotic Surgery), a versatile system that aims at enhancing minimally invasive robotic surgery through patient-dependent optimized planning, realistic simulation, safe supervision, and augmented reality. The underlying architecture of the proposed approach is presented, then each component is detailed. An experimental validation is conducted on a dog for a coronary bypass intervention using the Da Vinci(TM) surgical system focusing on planing, registration, and augmented reality trials.\"],\n",
    "[51,5,0,\"In this paper we proposed an unsupervised neural architecture, called Temporal Parametrized Self Organizing Map (TEPSOM), capable of learning and reproducing complex robot trajectories and interpolating new states between the learned ones. The TEPSOM combines the Self-Organizing NARX (SONARX) network, responsible for coding the temporal associations of the robotic trajectory, with the Parametrized Self-Organizing (PSOM) network, responsible for an efficient interpolation mechanism acting on the SONARX neurons. The TEPSOM network is used to model the inverse kinematics of the PUMA 560 robot during the execution of trajectories with repeated states. Simulation results show that the TEPSOM is more accurate than the SONARX in the reproduction of the learned trajectories.\"],\n",
    "[52,0,0,\"We argue that direct experimental approaches to elucidate the architecture of higher brains may benefit from insights gained from exploring the possibilities and limits of artificial control architectures for robot systems. We present some of our recent work that has been motivated by that view and that is centered around the study of various aspects of hand actions since these are intimately linked with many higher cognitive abilities. As examples, we report on the development of a modular system for the recognition of continuous hand postures based on neural nets, the use of vision and tactile sensing for guiding prehensile movements of a multifingered hand, and the recognition and use of hand gestures for robot teaching. Regarding the issue of learning, we propose to view real-world learning from the perspective of data-mining and to focus more strongly on the imitation of observed actions instead of purely reinforcement-based exploration. As a concrete example of such an effort we report on the status of an ongoing project in our laboratory in which a robot equipped with an attention system with a neurally inspired architecture is taught actions by using hand gestures in conjunction with speech commands. We point out some of the lessons learnt from this system, and discuss how systems of this kind can contribute to the study of issues at the junction between natural and artificial cognitive systems.\"],\n",
    "[53,0,0,\"\"],\n",
    "[54,0,0,\"The use of backpropagation for training artificial neural networks (ANNs) is usually associated with a long training process. The user needs to experiment with a number of network architectures; with larger networks, more computational cost in terms of training time is required. The objective of this letter is to present an optimization algorithm, comprising a multiobjective evolutionary algorithm and a gradient-based local search. In the rest of the letter, this is referred to as the memetic Pareto artificial neural network algorithm for training ANNs. The evolutionary approach is used to train the network and simultaneously optimize its architecture. The result is a set of networks, with each network in the set attempting to optimize both the training error and the architecture. We also present a self-adaptive version with lower computational cost. We show empirically that the proposed method is capable of reducing the training time compared to gradient-based techniques.\"],\n",
    "[55,5,0,\"Adaptive Resonance Theory (ART) networks are employed in robot behavior learning. Two of the difficulties in online robot behavior learning, namely, (1) exponential memory increases with time, (2) difficulty for operators to specify learning tasks accuracy and control learning attention before learning. In order to remedy the aforementioned difficulties, an adaptive categorization mechanism is introduced in ART networks for perceptual and action patterns categorization in this paper. A game-theoretic formulation of adaptive categorization for ART networks is proposed for vigilance parameter adaptation for category size control on the categories formed. The proposed vigilance parameter update rule can help improving categorization performance in the aspect of category number stability and solve the problem of selecting initial vigilance parameter prior to pattern categorization in traditional ART networks. Behavior learning using physical robot is conducted to demonstrate the effectiveness of the proposed adaptive categorization mechanism in ART networks.\"],\n",
    "[56,0,0,\"Automation and Robotics (A&R) systems are a key technology for Mars exploration. All over the world initiatives in this field aim at developing new A&R systems and technologies for planetary surface exploration. From December 2000 to February 2002 Kayser-Threde GmbH, Munich, Germany lead a study called AROMA (Automation and Robotics for Human Mars Exploration) under ESA contract in order to define a reference architecture of A&R elements in support of a human Mars exploration program. One of the goals of this effort is to initiate new developments and to maintain the competitiveness of European industry within this field.\"],\n",
    "[57,0,0,\"As a high throughput technique, microarray experiments produce large data sets, consisting of measured data, laboratory protocols, and experimental settings. We have implemented the open source platform EMMA to store and analyze these data. The system provides automated pipelines for data processing and has a modular architecture that can be easily extended. EMMA features detailed reports about spots and their corresponding measurements. In addition to routine data analysis algorithms, the system can be integrated with other components that contain additional data sources (e.g. genome annotation systems).\"],\n",
    "[58,0,0,\"This paper presents a master-slave robotized system enabling a remote echographic diagnosis. The expert holds a virtual probe placed on a haptic device; he moves this virtual probe in order to control the motion of the real probe positioned on the body of the patient located remotely. The real probe is placed on a lightweight and user-friendly slave robot and moved by it. The contact force between the probe and the patient is fed back to the operator allowing him to have a haptic virtual environment. The aim of this haptic control is to preserve the medical expert proprioception in order to the facilitate hand-eye coordination necessary to echographic examination. In this paper we present the architecture of the system and experimental results.\"],\n",
    "[59,9,1,\"A new hybrid event based control architecture for tele-robotic systems controlled through the Internet is proposed in this paper. Different from the traditional event based control method, the new framework does not require every part of the system to be strictly event synchronized. Instead, it allows time referenced control components to be integrated into this framework, which makes it more convenient to develop Internet based control systems. Since there are two reference variables, time and event, in this architecture, how to coordinate these components with different references to keep the stability of the whole system is discussed in detail in this paper. To verify this new idea, an experiment was conducted to control the end effector of a PUMA robot tracking a continuous state trajectory given on-line by the remote operator. Experimental results confirmed the stability of such systems being controlled through the Internet in real-time.\"],\n",
    "[60,0,0,\"The benefits of a robotics system for waste disposal and cage sanitation in an animal care facility include a reduction of ergonomic concerns and an increase in production capability. A modular approach can further provide an ability to relocate the unit to new building construction. There are numerous considerations that can affect the design and operation of a robotic cagewash system. These include facility layout, existing animal husbandry procedures, equipment selection, and employee involvement. The implementation of the complete system in an animal facility requires communication and insight from all members of the animal care staff as well as novel solutions to attain full production and operation. The system itself contains many complex technical and mechanical functions, but a successful installation can only be fully achieved with teamwork and proper training.\"],\n",
    "[61,0,0,\"A mathematical simulation model was used to assist 5 farmers in developing design criteria for inclusion of robotic milking systems in each farm situation. The barn layout influences arrivals of cows to the milking robot as well as other cow traffic and must be carefully planned. Each farmer had individual objectives and consequently unique design criteria that determined the optimal solution. Planning factors addressed by simulations on these farms included: 1) optimal cow cooling locations; 2) optimal facility allocation in expanding dairies; 3) concentrate feeder locations and feeding management; 4) number of feeders--based on expected rations; 5) use of a robot in an open cowshed without free stalls; 6) number of robots needed, currently and in the future; 7) eight robots working in harmony; 8) robot locations that allow for expansion; 9) floor space needed in each barn section including maternity and veterinary treatment areas; 10) location of bottlenecks that limit efficiency or expansion; and 11) cow traffic routine as affected by management practices, feed allocation, and farm layout. The simulation allowed farmers to receive a course in managing a 'virtual robotic milking farm' before installation of the barn. Therefore, each could be more confident that his future barn would work properly under his unique local conditions and management practices. One farm checked 2 yr after construction achieved an average daily robot utilization of 84%, nearly matching the 85% projected before the barn was built. Important variables considered in the simulations were facility allocation, cow space needed in each farm area, robot utilization, number of cows, milk yield, milk flow rate, feeding method and timing, robot location and orientation, and farm physical layout.\"],\n",
    "[62,5,0,\"The Brain-Computer is a physical analogue of a real organism which uses both a brain-inspired memory-based architecture and an output-driven learning algorithm. This system can be realized by creating a scaled-down model car that learns how to drive by heuristically connecting image processing with behavior control. This study proves that learning efficiency progresses rapidly when the acquired behaviors are prioritized. We develop a small real-world device that moves about purposefully in an artificial environment. The robot uses imaging information acquired through its random actions to make a mental map. This map, then, provides the cognitive structure for acquiring necessary information for autonomous behavior.\"],\n",
    "[63,0,0,\"Social free energy has been recently introduced as a measure of social action obtainable in a given social system, without changes in its structure. The authors of this paper argue that social free energy surpasses the gap between the verbally formulated value sets of social systems and the quantitatively based predictions. This point is further developed by analyzing the relation between the social and the physical free energy. Generically, this is done for a particular type of social dynamics. The extracted type of social dynamics is one of many realistic types of the differing proportion of social and economic elements. Numerically, this has been done for a toy model of interacting agents. The values of the social and physical free energies are, within the numerical accuracy, equivalent in the class of nontrivial, quasistationary model states.\"],\n",
    "[64,5,0,\"This paper proposes an alternative approach to address the problem of coordinating behaviors in mobile robot navigation: fusion of control signals. Such approach is based on a set of two decentralized information filters, which accomplish the data fusion involved. Besides these two fusion engines, control architectures designed according to this approach also embed a set of different controllers that generate reference signals for the robot linear and angular speeds. Such signals are delivered to the two decentralized information filters, which estimate suitable overall reference signals for the robot linear and angular speeds, respectively. Thus, the background for designing such control architectures is provided by the nonlinear systems theory, which makes this approach different from any other yet proposed. This background also allows checking control architectures designed according to the proposed approach for stability. Such analysis is carried out in the paper, and shows that the robot always reaches its final destination, in spite of either obstacles along its path or the environment layout. As an example, a control architecture is designed to guide a mobile robot in an experiment, whose results allows checking the good performance of the control architecture and validating the design approach proposed as well.\"],\n",
    "[65,1,0,\"The structure classification of proteins plays a very important role in bioinformatics, since the relationships and characteristics among those known proteins can be exploited to predict the structure of new proteins. The success of a classification system depends heavily on two things: the tools being used and the features considered. For the bioinformatics applications, the role of appropriate features has not been paid adequate importance. In this investigation we use three novel ideas for multiclass protein fold classification. First, we use the gating neural network, where each input node is associated with a gate. This network can select important features in an online manner when the learning goes on. At the beginning of the training, all gates are almost closed, i.e., no feature is allowed to enter the network. Through the training, gates corresponding to good features are completely opened while gates corresponding to bad features are closed more tightly, and some gates may be partially open. The second novel idea is to use a hierarchical learning architecture (HLA). The classifier in the first level of HLA classifies the protein features into four major classes: all alpha, all beta, alpha + beta, and alpha/beta. And in the next level we have another set of classifiers, which further classifies the protein features into 27 folds. The third novel idea is to induce the indirect coding features from the amino-acid composition sequence of proteins based on the N-gram concept. This provides us with more representative and discriminative new local features of protein sequences for multiclass protein fold classification. The proposed HLA with new indirect coding features increases the protein fold classification accuracy by about 12%. Moreover, the gating neural network is found to reduce the number of features drastically. Using only half of the original features selected by the gating neural network can reach comparable test accuracy as that using all the original features. The gating mechanism also helps us to get a better insight into the folding process of proteins. For example, tracking the evolution of different gates we can find which characteristics (features) of the data are more important for the folding process. And, of course, it also reduces the computation time.\"],\n",
    "[66,0,0,\"In this paper, we present an approach to automatic detection and recognition of signs from natural scenes, and its application to a sign translation task. The proposed approach embeds multiresolution and multiscale edge detection, adaptive searching, color analysis, and affine rectification in a hierarchical framework for sign detection, with different emphases at each phase to handle the text in different sizes, orientations, color distributions and backgrounds. We use affine rectification to recover deformation of the text regions caused by an inappropriate camera view angle. The procedure can significantly improve text detection rate and optical character recognition (OCR) accuracy. Instead of using binary information for OCR, we extract features from an intensity image directly. We propose a local intensity normalization method to effectively handle lighting variations, followed by a Gabor transform to obtain local features, and finally a linear discriminant analysis (LDA) method for feature selection. We have applied the approach in developing a Chinese sign translation system, which can automatically detect and recognize Chinese signs as input from a camera, and translate the recognized text into English.\"],\n",
    "[67,5,0,\"This paper present an architecture for combining a mixture of experts. The architecture has two unique features: 1) it assumes no prior knowledge of the size or structure of the mixture and allows the number of experts to dynamically expand during training, and 2) reinforcement feedback is used to guide the combining/expansion operation. The architecture is particularly suitable for applications when there is a need to approximate a many-to-many mapping. An example of such a problem is the task of training a robot to grasp arbitrarily shaped objects. This task requires the approximation of a many-to-many mapping, since various configurations can be used to grasp an object, and several objects can share the same grasping configuration. Experiments in a simulated environment using a 28-object database showed how the algorithm dynamically combined and expanded a mixture of neural networks to achieve the learning task. The paper also presents a comparison with two other nonlearning approaches.\"],\n",
    "[68,0,0,\"One of the main stumbling blocks encountered when attempting to express foreign proteins in Escherichia coli is the occurrence of amorphous aggregates of misfolded proteins, called inclusion bodies (IB). Developing efficient protein native structure recovery procedures based on IB refolding is therefore an important challenge. Unfortunately, there is no 'universal' refolding buffer: Experience shows that refolding buffer composition varies from one protein to another. In addition, the methods developed so far for finding a suitable refolding buffer suffer from a number of weaknesses. These include the small number of refolding formulations, which often leads to negative results, solubility assays incompatible with high-throughput, and experiment formatting not suitable for automation. To overcome these problems, it was proposed in the present study to address some of these limitations. This resulted in the first completely automated IB refolding screening procedure to be developed using a 96-well format. The 96 refolding buffers were obtained using a fractional factorial approach. The screening procedure is potentially applicable to any nonmembrane protein, and was validated with 24 proteins in the framework of two Structural Genomics projects. The tests used for this purpose included the use of quality control methods such as circular dichroism, dynamic light scattering, and crystallogenesis. Out of the 24 proteins, 17 remained soluble in at least one of the 96 refolding buffers, 15 passed large-scale purification tests, and five gave crystals.\"],\n",
    "[69,0,0,\"We have developed a data fusion system for the robotics surgery system 'da Vinci'. The data fusion system is composed of an optical 3D location sensor and a digital video processing system. The 3D location sensor is attached to the da Vinci's laparoscope and measures its location and direction. The digital video processing system captures the laparoscope's view and superimposes 3D patient's organ models onto the captured view in real-time. We applied the system to 'da Vinci' and examined this system during a cholecystectomy. In this experiment, the surgeon was able to observe the inner conditions of the organs with a stereo view.\"],\n",
    "[70,9,1,\"We are developing a novel robot concept called the wearable robot. Wearable robots are mobile information devices capable of supporting remote communication and intelligent interaction between networked entities. In this paper, we explore the possible functions of such a robotic network and will present a distributed network architecture based on service components. In order to support the interaction and communication between the components in the wearable robot system, we have developed an intelligent network architecture. This service-based architecture involves three major mechanisms. The first mechanism involves the use of a task coordinator service such that the execution of the services can be managed using a priority queue. The second mechanism enables the system to automatically push the required service proxy to the client intelligently based on certain system-related conditions. In the third mechanism, we allow the system to automatically deliver services based on contextual information. Using a fuzzy-logic-based decision making system, the matching service can determine whether the service should be automatically delivered utilizing the information provided by the service, client, lookup service, and context sensors. An application scenario has been implemented to demonstrate the feasibility of this distributed service-based robot architecture. The architecture is implemented as extensions to the Jini network model.\"],\n",
    "[71,0,0,\"We present a distributed vision-based architecture for smart robotics that is composed of multiple control loops, each with a specialized level of competence. Our architecture is subsumptive and hierarchical, in the sense that each control loop can add to the competence level of the loops below, and in the sense that the loops can present a coarse-to-fine gradation with respect to vision sensing. At the coarsest level, the processing of sensory information enables a robot to become aware of the approximate location of an object in its field of view. On the other hand, at the finest end, the processing of stereo information enables a robot to determine more precisely the position and orientation of an object in the coordinate frame of the robot. The processing in each module of the control loops is completely independent and it can be performed at its own rate. A control Arbitrator ranks the results of each loop according to certain confidence indices, which are derived solely from the sensory information. This architecture has clear advantages regarding overall performance of the system, which is not affected by the 'slowest link,' and regarding fault tolerance, since faults in one module does not affect the other modules. At this time we are able to demonstrate the utility of the architecture for stereoscopic visual servoing. The architecture has also been applied to mobile robot navigation and can easily be extended to tasks such as 'assembly-on-the-fly.'\"],\n",
    "[72,1,0,\"In order to rapidly follow unexpected environmental changes, we propose a parameter control method in reinforcement learning that changes each of learning parameters in appropriate directions. We determine each appropriate direction on the basis of relationships between behaviors and neuromodulators by considering an emergency as a key word. Computer experiments show that the agents using our proposed method could rapidly respond to unexpected environmental changes, not depending on either two reinforcement learning algorithms (Q-learning and actor-critic (AC) architecture) or two learning problems (discontinuous and continuous state-action problems).\"],\n",
    "[73,9,1,\"Behavior selection is typically a 'built-in' feature of behavior-based architectures and hence, not amenable to change. There are, however, circumstances where changing behavior selection strategies is useful and can lead to better performance. In this paper, we demonstrate that such dynamic changes of behavior selection mechanisms are beneficial in several circumstances. We first categorize existing behavior selection mechanisms along three dimensions and then discuss seven possible circumstances where dynamically switching among them can be beneficial. Using the agent architecture framework activation, priority, observer, and component (APOC), we show how instances of all (nonempty) categories can be captured and how additional architectural mechanisms can be added to allow for dynamic switching among them. In particular, we propose a generic architecture for dynamic behavior selection, which can integrate existing behavior selection mechanisms in a unified way. Based on this generic architecture, we then verify that dynamic behavior selection is beneficial in the seven cases by defining architectures for simulated and robotic agents and performing experiments with them. The quantitative and qualitative analyzes of the results obtained from extensive simulation studies and experimental runs with robots verify the utility of the proposed mechanisms.\"],\n",
    "[74,0,0,\"This project aimed to construct an operating room to implement high dimensional (3D, 4D) medical imaging and medical virtual reality techniques that would enable clinical tests for new surgical procedures. We designed and constructed such an operating room at Dai-san Hospital, the Jikei Univ. School of Medicine, Tokyo, Japan. The room was equipped with various facilities for image-guided, robot and tele- surgery. In this report, we describe an outline of our 'high-tech operating room' and future plans.\"],\n",
    "[75,5,0,\"Mesoscopic level neurodynamics study the collective dynamical behavior of neural populations. Such models are becoming increasingly important in understanding large-scale brain processes. Brains exhibit aperiodic oscillations with a much more rich dynamical behavior than fixed-point and limit-cycle approximation allow. Here we present a discretized model inspired by Freeman's K-set mesoscopic level population model. We show that this version is capable of replicating the important principles of aperiodic/chaotic neurodynamics while being fast enough for use in real-time autonomous agent applications. This simplification of the K model provides many advantages not only in terms of efficiency but in simplicity and its ability to be analyzed in terms of its dynamical properties. We study the discrete version using a multilayer, highly recurrent model of the neural architecture of perceptual brain areas. We use this architecture to develop example action selection mechanisms in an autonomous agent.\"],\n",
    "[76,5,0,\"Motivated by the human autonomous development process from infancy to adulthood, we have built a robot that develops its cognitive and behavioral skills through real-time interactions with the environment. We call such a robot a developmental robot. In this paper, we present the theory and the architecture to implement a developmental robot and discuss the related techniques that address an array of challenging technical issues. As an application, experimental results on a real robot, self-organizing, autonomous, incremental learner (SAIL), are presented with emphasis on its audition perception and audition-related action generation. In particular, the SAIL robot conducts the auditory learning from unsegmented and unlabeled speech streams without any prior knowledge about the auditory signals, such as the designated language or the phoneme models. Neither available before learning starts are the actions that the robot is expected to perform. SAIL learns the auditory commands and the desired actions from physical contacts with the environment including the trainers.\"],\n",
    "[77,0,0,\"Scaffold based tissue engineering strategies use cells, biomolecules and a scaffold to promote the repair and regeneration of tissues. Although scaffold-based tissue engineering approaches are being actively developed, most are still experimental, and it is not yet clear what defines an ideal scaffold/cell construct. Solid free form fabrication (SFF) techniques can precisely control matrix architecture (size, shape, interconnectivity, branching, geometry and orientation). The SFF methods enable the fabrication of scaffolds with various designs and material compositions, thus providing a control of mechanical properties, biological effects and degradation kinetics. This paper reviews the application of micro-robotics and MEMS-based fabrication techniques for scaffold design and fabrication. It also presents a novel robotic technique to fabricate scaffold/cell constructs for tissue engineering by the assembly of microscopic building blocks.\"],\n",
    "[78,0,0,\"We propose a general architecture for action (mimicking) and program (gesture) level visual imitation. Action-level imitation involves two modules. The viewpoint Transformation (VPT) performs a 'rotation' to align the demonstrator's body to that of the learner. The Visuo-Motor Map (VMM) maps this visual information to motor data. For program-level (gesture) imitation, there is an additional module that allows the system to recognize and generate its own interpretation of observed gestures to produce similar gestures/goals at a later stage. Besides the holistic approach to the problem, our approach differs from traditional work in i) the use of motor information for gesture recognition; ii) usage of context (e.g., object affordances) to focus the attention of the recognition system and reduce ambiguities, and iii) use iconic image representations for the hand, as opposed to fitting kinematic models to the video sequence. This approach is motivated by the finding of visuomotor neurons in the F5 area of the macaque brain that suggest that gesture recognition/imitation is performed in motor terms (mirror) and rely on the use of object affordances (canonical) to handle ambiguous actions. Our results show that this approach can outperform more conventional (e.g., pure visual) methods.\"],\n",
    "[79,0,0,\"The paper addresses the evolution of the Canadian Space Station Program between 1981 and 2003. Discussions with potential international partners, aimed at jointly developing the current International Space Station program, were initiated by NASA in 1982. Canada chose, through the further development of the technologies of Canadarm on the space shuttle, to provide and operate an advanced and comprehensive external robotics system for space station, and to use the space station for scientific and commercial purposes. The program was to become a corner-stone of the new Canadian Space Agency. The development phase of the Canadian Space Station Program has been completed and two of the three major elements are currently operational in space.\"],\n",
    "[80,0,0,\"This paper describes the development of an electrically powered wheelchair-mounted manipulator for use by severely disabled persons. A detailed review is given explaining the specification. It describes the construction of the device and its control architecture. The prototype robot used several gesture recognition and other input systems. The system has been tested on disabled and non-disabled users. They observed that it was easy to use but about 50% slower than comparable systems before design modifications were incorporated. The robot has a payload of greater than 1 kg with a maximum reach of 0.7-0.9 m.\"],\n",
    "[81,1,0,\"Due to their distributed architecture, artificial neural networks often show a graceful performance degradation to the loss of few units or connections. Living systems also display an additional source of fault-tolerance obtained through distributed processes of self-healing: defective components are actively regenerated. In this paper, we present results obtained with a model of development for spiking neural networks undergoing sustained levels of cell loss. To test their resistance to faults, networks are subjected to random faults during development and mutilated several times during operation. Results show that, evolved to control simulated Khepera robots in a simple navigation task, plastic and non-plastic networks develop fault-tolerant structures which can recover normal operation to various degrees.\"],\n",
    "[82,9,1,\"Internal models and adaptive controls are empirical and mathematical paradigms that have evolved separately to describe learning control processes in brain systems and engineering systems, respectively. This paper presents a comprehensive appraisal of the correlation between these paradigms with a view to forging a unified theoretical framework that may benefit both disciplines. It is suggested that the classic equilibrium-point theory of impedance control of arm movement is analogous to continuous gain-scheduling or high-gain adaptive control within or across movement trials, respectively, and that the recently proposed inverse internal model is akin to adaptive sliding control originally for robotic manipulator applications. Modular internal models' architecture for multiple motor tasks is a form of multi-model adaptive control. Stochastic methods, such as generalized predictive control, reinforcement learning, Bayesian learning and Hebbian feedback covariance learning, are reviewed and their possible relevance to motor control is discussed. Possible applicability of a Luenberger observer and an extended Kalman filter to state estimation problems-such as sensorimotor prediction or the resolution of vestibular sensory ambiguity-is also discussed. The important role played by vestibular system identification in postural control suggests an indirect adaptive control scheme whereby system states or parameters are explicitly estimated prior to the implementation of control. This interdisciplinary framework should facilitate the experimental elucidation of the mechanisms of internal models in sensorimotor systems and the reverse engineering of such neural mechanisms into novel brain-inspired adaptive control paradigms in future.\"],\n",
    "[83,9,1,\"The existence of multiple parallel loops connecting sensorimotor systems to the basal ganglia has given rise to proposals that these nuclei serve as a selection mechanism resolving competitions between the alternative actions available in a given context. A strong test of this hypothesis is to require a computational model of the basal ganglia to generate integrated selection sequences in an autonomous agent, we therefore describe a robot architecture into which such a model is embedded, and require it to control action selection in a robotic task inspired by animal observations. Our results demonstrate effective action selection by the embedded model under a wide range of sensory and motivational conditions. When confronted with multiple, high salience alternatives, the robot also exhibits forms of behavioral disintegration that show similarities to animal behavior in conflict situations. The model is shown to cast light on recent neurobiological findings concerning behavioral switching and sequencing.\"],\n",
    "[84,0,0,\"BACKGROUND: By means of a prospective, nonrandomized investigation, we evaluated the feasibility of performing endo-robotic resection of the submandibular gland in a cadaver model and compared the results of robotically enhanced endoscopic surgery with those from a conventional endoscopic technique. METHODS: Procedural times were recorded in a consecutive series of 11 endoscopic submandibular gland resections using the daVinci Surgical System (Intuitive Surgical, Sunnyvale, CA) and a modified endoscopic surgical approach previously developed in a porcine model. The presence of neurovascular injury was assessed postoperatively, and the specimens were examined histologically. RESULTS: Eleven endo-robotic submandibular gland resections were successfully performed in six cadavers (no conversions to open resection were necessary). The median duration of the procedures was 48 minutes (range, 33-82 minutes). Creation of the operative pocket took an average (+/-SD) of 12.2 +/- 5.3 minutes, assembly of the robot required 9.3 +/- 4.1 minutes, and the mean time for submandibular gland resection was 29.4 +/- 8.9 minutes. The time required for robotic assembly was offset by the reduced operative time necessary compared with conventional endoscopic resection. Histologic examination confirmed the presence of normal glandular architecture, without evidence of excessive mechanical or thermal injury. There were no cases of apparent neurovascular injury. CONCLUSIONS: Robotically enhanced endoscopic surgery in the neck is feasible and offers a number of compelling advantages over conventional endoscopic neck surgery. Clinical trials will be necessary to determine whether these advantages can be achieved in clinical practice.\"],\n",
    "[85,0,0,\"A growing need for sensitive and high-throughput methods for screening the expression and solubility of recombinant proteins exists in structural genomics. Originally, the emergency solution was to use immediately available techniques such as manual lysis of expression cells followed by analysis of protein expression by gel electrophoresis. However, these handmade methods quickly proved to be unfit for the high-throughput demand of postgenomics, and it is now generally accepted that the long-term solution to this problem will be based on automation, on industrial standard-formatted experiments, and on downsizing samples and consumables. In agreement with this consensus, we have set up a fully automated method based on a dot-blot technology and using 96-well format consumables for assessing by immunodetection the amount of total and soluble recombinant histidine (His)-tagged proteins expressed in Escherichia coli. The method starts with the harvest of expression cells and ends with the display of solubility/expression results in milligrams of recombinant protein per liter of culture using a three-color code to assist analysis. The program autonomously processes 160 independent cultures at a time.\"],\n",
    "[86,0,0,\"A new method to realize stable and realistic cutting simulation using an impedance display haptic device and microcomputer is presented in this paper. Material removal or cutting simulation is a critical task in dental preparation surgery simulation. In this paper, a piecewise contact force model is proposed to approximately describe the cutting process. Challenging issues of minimizing the difference between the cutting simulation and haptic contact simulation are analyzed. The proposed contact-based simulation method is developed for a one-dimensional cutting task and can be expanded to three-dimensional cases. Local model-based multirate simulation cutting architecture is proposed and force control of the haptic device is decoupled from the cutting simulation loop, which can both ensure high fidelity of dynamical simulation as well as maintain stability of the haptic device. The cutting operation is realized using spherical and cylindrical shaped tools. An experiment based on the Phantom desktop proves that fidelity in one-dimensional cutting can be realized and stability in three-dimensional cutting can be ensured using the force-filtering method.\"],\n",
    "[87,0,0,\"Recently, there has been a lot of interest in building anthropomorphic robots. Research on humanoid robotics has focused on the control of manipulators and walking machines. The contributions of the torso towards ordinary movements (such as walking, dancing, attracting mates, and maintaining balance) have been neglected by almost all humanoid robotic researchers. We believe that the next generation of humanoid robots will incorporate a flexible spine in the torso. To meet the challenge of controlling this kind of high-degree-of-freedom robot, a new control architecture is necessary. Inspired by the rhythmic movements commonly exhibited in lamprey locomotion as well as belly dancing, we designed a controller for a simulated belly-dancing robot using the lamprey central pattern generator. Experimental results show that the proposed lamprey central pattern generator module could potentially generate plausible output patterns, which could be used for all the possible spine motions with minimized control parameters. For instance, in the case of planar spine motions, only three input parameters are required. Using our controller, the simulated robot is able to perform complex torso movements commonly seen in belly dancing as well. Our work suggests that the proposed controller can potentially be a suitable controller for a high-degree-of-freedom, flexible spine humanoid robot. Furthermore, it allows us to gain a better understanding of belly dancing by synthesis.\"],\n",
    "[88,0,0,\"This work describes an integrated system for planning and performing percutaneous procedures-such as prostate biopsy-with robotic assistance under MRI-guidance. The physician interacts with a planning interface in order to specify the set of desired needle trajectories, based on anatomical structures and lesions observed in the patient's MR images. All image-space coordinates are automatically computed, and used to position a needle guide by means of an MRI-compatible robotic manipulator, thus avoiding the limitations of the traditional fixed needle template. Direct control of real-time imaging aids visualization of the needle as it is manually inserted through the guide. Results from in-scanner phantom experiments are provided.\"],\n",
    "[89,0,0,\"As the field of surgical robotics continues to evolve, it is important to keep patient safety in mind. This paper describes a safety control architecture aimed at moving an experimental system in the direction of intrinsically safe operation. The system includes safety features such as: a small number of states, Programmable Logic Controller (PLC) state transition control, active enable, brakes, E-STOP, and a surgeon foot pedal.\"],\n",
    "[90,0,0,\"Operating-room design has not changed significantly since the modern era of surgery began. Minimal invasive, endoscopic, procedures, and evolution of technology will affect operating-room design in the near future. Poor ergonomics has always been one of the major drawbacks of endoscopic surgery. Use of retractable arms and monitors will improve ergonomics of the operating team. Developments in telecommunication will allow surgeons to communicate with colleagues and experts during the procedure in virtually any location around the world, which increases teaching possibilities and procedural safety. Introduction and further development of intraoperative imaging, including real-time, three-dimensional (3-D) reconstructions of patient, and computer-aided surgery offer surgeons the opportunity to train the planned surgical procedure. Moreover, they will improve control and supervision of the procedure in learning situations. The last decade's robotics have made their introduction into the operating rooms. They improve control over the operating-room environment and will facilitate the performance of more complex procedures. However, high costs and lack of force feedback remain its major drawbacks. Improvements of robotic techniques and its implementation into the operating rooms will further guide their design into highly specialized operating units.\"],\n",
    "[91,0,0,\"The design clue for the remote control of a mobile robot is inspired by the Talwar's brain-machine interface technology for remotely training and controlling rats. Our biologically inspired autonomous robot control consciousness-based architecture (CBA) is used for the remote control of a robot as a substitute for a rat. CBA is a developmental hierarchy model of the relationship between consciousness and behavior, including a training algorithm. This training algorithm computes a shortcut path to a goal using a cognitive map created based on behavior obstructions during a single successful trial. However, failures in reaching the goal due to errors of the vision and dead reckoning sensors require human intervention to improve autonomous navigation. A human operator remotely intervenes in autonomous behaviors in two ways: low-level intervention in reflexive actions and high-level ones in the cognitive map. Experiments are conducted to test CBA functions for intervention with a joystick for a Khepera robot navigating from the center of a square obstacle with an open side toward a goal. Their statistical results show that both human interventions, especially high-level ones, are effective in drastically improving the success rate of autonomous detours.\"],\n",
    "[92,0,0,\"In this study, we present a constructive algorithm for training cooperative support vector machine ensembles (CSVMEs). CSVME combines ensemble architecture design with cooperative training for individual SVMs in ensembles. Unlike most previous studies on training ensembles, CSVME puts emphasis on both accuracy and collaboration among individual SVMs in an ensemble. A group of SVMs selected on the basis of recursive classifier elimination is used in CSVME, and the number of the individual SVMs selected to construct CSVME is determined by 10-fold cross-validation. This kind of SVME has been tested on two ovarian cancer datasets previously obtained by proteomic mass spectrometry. By combining several individual SVMs, the proposed method achieves better performance than the SVME of all base SVMs.\"],\n",
    "[93,0,0,\"Laparoscopic pyeloplasty as a treatment for ureteropelvic junction obstruction has shown comparable success rates with open pyeloplasty techniques. The use of robotic technology to assist during laparoscopic pyeloplasty procedures has been encouraged by the steep learning curve for laparoscopic surgical skills, and the complexity of laparoscopic suturing. Robotic technology provides the surgeon with the ability to filter out any physiologic hand tremor, more degrees of freedom of movement than traditional laparoscopic instruments, the ability to scale movement to provide better control for microsurgery, better ergonomics during surgery, and three-dimensional vision. Details of the procedure and specific nursing care of the patient undergoing robotic-assisted laparoscopic pyeloplasty at the University of Iowa Hospital and Clinics are described.\"],\n",
    "[94,0,0,\"Radical cystectomy or cystoprostatectomy with urinary diversion is the gold standard for the treatment of muscle-invasive bladder cancer. Cystectomy can be through an open or robotic-assisted laparoscopic approach. Advances in laparoscopy, robotic surgery, and urological oncology have made it possible for select surgeons to perform nerve-sparing robotic-assisted laparoscopic radical cystoprostatectomy. Advantages of robotic surgery may be minimal blood loss, shorter hospital stay, quicker recovery, and possibly more precise and rapid removal of the bladder depending on the experience and expertise of the surgeon. Appropriate patient selection and thorough pre-operative evaluation, however, are key in maximizing positive surgical outcomes. The experience at the University of Virginia with robotic-assisted laparoscopic radical cystectomy will be discussed.\"],\n",
    "[95,0,0,\"Prostate cancer has many treatment options. In addition to open retropubic and perineal approaches to radical prostatectomy, laparoscopic robotic prostatectomy is available as a newer surgical option. Potential advantages of robotic surgery include reduced pain and trauma, less blood loss, reduced infection risk, shorter hospital stay, faster recovery, and less scarring (Intuitive Surgical, 2005). A variety of nursing care considerations involving pre-operative education and preparation, intra-operative and immediate postoperative care issues, and long-term followup must be understood to meet the needs of a robotic surgical patient. Patient selection is very important to optimize a positive surgical outcome. Just as certain criteria make a good surgical candidate, there are factors that could complicate the surgery or adversely affect recovery.\"],\n",
    "[96,0,0,\"A fundamental task performed by many visual systems is to distinguish apparent motion caused by eye movements from real motion occurring within the environment. During saccadic eye movements, this task is achieved by inhibitory signals of central and retinal origin that suppress the output of motion-detecting neurons. To investigate the retinally-generated component of this suppression, we used a computational model of a locust looming-detecting pathway that experiences saccadic suppression. This model received input from the camera of a mobile robot that performed simple saccade-like movements, allowing the model's response to simplified real stimuli to be tested. Retinally-generated saccadic suppression resulted from two inhibitory mechanisms within the looming-detector's input architecture. One mechanism fed inhibition forward through the network, inhibiting the looming-detector's initial response to movement. The second spread inhibition laterally within the network, suppressing the looming-detector's maintained response to movement. These mechanisms prevent a looming-detector model response to whole-field visual stimuli. In the locust, this mechanism of saccadic suppression may operate in addition to centrally-generated suppression. Because lateral inhibition is a common feature of early visual processing in many organisms, we discuss whether the mechanism of retinally-generated saccadic suppression found in the locust looming-detector model may also operate in these species.\"],\n",
    "[97,5,0,\"For artificial entities to achieve true autonomy and display complex lifelike behavior, they will need to exploit appropriate adaptable learning algorithms. In this context adaptability implies flexibility guided by the environment at any given time and an open-ended ability to learn appropriate behaviors. This article examines the use of constructivism-inspired mechanisms within a neural learning classifier system architecture that exploits parameter self-adaptation as an approach to realize such behavior. The system uses a rule structure in which each rule is represented by an artificial neural network. It is shown that appropriate internal rule complexity emerges during learning at a rate controlled by the learner and that the structure indicates underlying features of the task. Results are presented in simulated mazes before moving to a mobile robot platform.\"],\n",
    "[98,0,0,\"OBJECTIVE: To review the neural architecture around the prostate gland, as it is relevant for nerve-sparing robotic prostatectomy, including in particular the anatomy of the proximal neurovascular tissue, the neurovascular bundle (NVB), and accessory neural pathways (ANPs). MATERIALS AND METHODS: The aims of this study were achieved in collaboration between the Cornell Institute of Robotic Surgery, New York, NY, USA and the Institute of Urology at the University of Innsbruck, Austria. The broad steps were: (i) anatomical studies of 10 fresh and two fixed male cadavers; and (ii) collection of videotape and still image data from 200 men undergoing radical prostatectomy by the athermal robotic technique at the Cornell Institute. RESULTS: From a surgical standpoint there was a tri-zonal neural architecture including the proximal neurovascular plate (PNP), the predominant NVB (PNB) and ANPs. The PNP was a mean (range) of 5 (3-10) mm lateral to the seminal vesicles, was 3 (2-7) mm thick, 7 (5-25) mm wide and 9 (4-30) mm long. It was within 6 (4-15) mm of the bladder neck, 5 (2-7) mm of the endopelvic fascia and overlapped 5 (0-7) mm of the proximal prostate. The PNB varied in shape and size from the proximal to distal end, was thickest at the base and most variable near the apex. In eight of 12 cases, there was a medial extension behind the prostate, which converged medially at the apex in four cases. ANPs were noted within the layers of levator fascia and/or lateral pelvic fascia on the anterolateral aspect in five cases and in three on the posterior aspect of the prostate. In nine cadavers, the proximal third of the prostate was covered by the PNP where these ANPs were most prominent. The ANPs formed a plexus on the posterolateral aspect of the apex in four cases. CONCLUSION: We have created an anatomical map of neurovascular tissue relevant to robotic prostatectomy. A tri-zonal neural architecture is described which has helped in standardizing the steps of robotic prostatectomy.\"],\n",
    "[99,0,0,\"This paper describes the hierarchical architecture for a rhythmic coordination between robots, which suits juggling-like tasks involving sensory-motor coordination. The authors' approach, which is interpreted as a 'bidirectional weak coupling' to the environment, does not require either the environmental model or continuously monitoring the environment but can adapt the robots to a change in the environment, owing to the interaction between the robots and the environment at the ball contact. The proposed architecture contains two passive-control mechanisms, the 'open-loop stable mechanism' and the 'entrainment mechanism,' that lead to the emergence of self-organized temporal structure for rhythmic movement. This dynamic pattern in the whole system realizes the stable coordinated motion between robots. The authors demonstrate two motion patterns between two robots passing two balls, and confirm the effectiveness of the approach.\"],\n",
    "[100,0,0,\"This paper uses a novel discrete-event controller (DEC) for the coordination of cooperating heterogeneous wireless sensor networks (WSNs) containing both unattended ground sensors (UGSs) and mobile sensor robots. The DEC sequences the most suitable tasks for each agent and assigns sensor resources according to the current perception of the environment. A matrix formulation makes this DEC particularly useful for WSN, where missions change and sensor agents may be added or may fail. WSN have peculiarities that complicate their supervisory control. Therefore, this paper introduces several new tools for DEC design and operation, including methods for generating the required supervisory matrices based on mission planning, methods for modifying the matrices in the event of failed nodes, or nodes entering the network, and a novel dynamic priority assignment weighting approach for selecting the most appropriate and useful sensors for a given mission task. The resulting DEC represents a complete dynamical description of the WSN system, which allows a fast programming of deployable WSN, a computer simulation analysis, and an efficient implementation. The DEC is actually implemented on an experimental wireless-sensor-network prototyping system. Both simulation and experimental results are presented to show the effectiveness and versatility of the developed control architecture.\"],\n",
    "[101,5,0,\"This tutorial presents an architecture for autonomous robots to generate behavior in joint action tasks. To efficiently interact with another agent in solving a mutual task, a robot should be endowed with cognitive skills such as memory, decision making, action understanding and prediction. The proposed architecture is strongly inspired by our current understanding of the processing principles and the neuronal circuitry underlying these functionalities in the primate brain. As a mathematical framework, we use a coupled system of dynamic neural fields, each representing the basic functionality of neuronal populations in different brain areas. It implements goal-directed behavior in joint action as a continuous process that builds on the interpretation of observed movements in terms of the partner's action goal. We validate the architecture in two experimental paradigms: (1) a joint search task; (2) a reproduction of an observed or inferred end state of a grasping-placing sequence. We also review some of the mathematical results about dynamic neural fields that are important for the implementation work.\"],\n",
    "[102,9,1,\"Mobile robots must be able to build their own maps to navigate in unknown worlds. Expanding a previously proposed method based on the fuzzy ART neural architecture (FARTNA), this paper introduces a new online method for learning maps of unknown dynamic worlds. For this purpose the new Prune-able fuzzy adaptive resonance theory neural architecture (PAFARTNA) is introduced. It extends the FARTNA self-organizing neural network with novel mechanisms that provide important dynamic adaptation capabilities. Relevant PAFARTNA properties are formulated and demonstrated. A method is proposed for the perception of object removals, and then integrated with PAFARTNA. The proposed methods are integrated into a navigation architecture. With the new navigation architecture the mobile robot is able to navigate in changing worlds, and a degree of optimality is maintained, associated to a shortest path planning approach implemented in real-time over the underlying global world model. Experimental results obtained with a Nomad 200 robot are presented demonstrating the feasibility and effectiveness of the proposed methods.\"],\n",
    "[103,0,0,\"Completely autonomous performance of a mobile robot within noncontrolled and dynamic environments is not possible yet due to different reasons including environment uncertainty, sensor/software robustness, limited robotic abilities, etc. But in assistant applications in which a human is always present, she/he can make up for the lack of robot autonomy by helping it when needed. In this paper, the authors propose human-robot integration as a mechanism to augment/improve the robot autonomy in daily scenarios. Through the human-robot-integration concept, the authors take a further step in the typical human-robot relation, since they consider her/him as a constituent part of the human-robot system, which takes full advantage of the sum of their abilities. In order to materialize this human integration into the system, they present a control architecture, called architecture for human-robot integration, which enables her/him from a high decisional level, i.e., deliberating a plan, to a physical low level, i.e., opening a door. The presented control architecture has been implemented to test the human-robot integration on a real robotic application. In particular, several real experiences have been conducted on a robotic wheelchair aimed to provide mobility to elderly people.\"],\n",
    "[104,0,0,\"This paper describes a novel image-guided system for precise automatic targeting in minimally invasive keyhole neurosurgery. The system consists of the MARS miniature robot fitted with a mechanical guide for needle, probe or catheter insertion. Intraoperatively, the robot is directly affixed to a head clamp or to the patient's skull. It automatically positions itself with respect to predefined targets in a preoperative CT/MRI image following an anatomical registration with an intraoperative 3D surface scan of the patient's facial features and registration jig. We present the system architecture, surgical protocol, custom hardware (targeting and registration jig), and software modules (preoperative planning, intraoperative execution, 3D surface scan processing, and three-way registration). We also describe a prototype implementation of the system and in vitro registration experiments. Our results indicate a system-wide target registration error of 1.7 mm (standard deviation = 0.7 mm), which is close to the required 1.0-1.5 mm clinical accuracy in many keyhole neurosurgical procedures.\"],\n",
    "[105,9,1,\"Biological organisms continuously select and sample information used by their neural structures for perception and action, and for creating coherent cognitive states guiding their autonomous behavior. Information processing, however, is not solely an internal function of the nervous system. Here we show, instead, how sensorimotor interaction and body morphology can induce statistical regularities and information structure in sensory inputs and within the neural control architecture, and how the flow of information between sensors, neural units, and effectors is actively shaped by the interaction with the environment. We analyze sensory and motor data collected from real and simulated robots and reveal the presence of information structure and directed information flow induced by dynamically coupled sensorimotor activity, including effects of motor outputs on sensory inputs. We find that information structure and information flow in sensorimotor networks (a) is spatially and temporally specific; (b) can be affected by learning, and (c) can be affected by changes in body morphology. Our results suggest a fundamental link between physical embeddedness and information, highlighting the effects of embodied interactions on internal (neural) information processing, and illuminating the role of various system components on the generation of behavior.\"],\n",
    "[106,5,0,\"We have described elsewhere an adaptive filter model of cerebellar learning in which the cerebellar microcircuit acts to decorrelate motor commands from their sensory consequences (Dean, Porrill, & Stone, 2002). Learning stability required the cerebellar microcircuit to be embedded in a recurrent loop, and this has been shown to lead to a simple and modular adaptive control architecture when applied to the linearized 3D vestibular ocular reflex (Porrill, Dean, & Stone, 2004). Here we investigate the properties of recurrent loop connectivity in the case of redundant and nonlinear motor systems and illustrate them using the example of kinematic control of a simulated two-joint robot arm. We demonstrate that (1) the learning rule does not require unavailable motor error signals or complex neural reference structures to estimate such signals (i.e., it solves the motor error problem) and (2) control of redundant systems is not subject to the nonconvexity problem in which incorrect average motor commands are learned for end-effector positions that can be accessed in more than one arm configuration. These properties suggest a central functional role for the closed cerebellar loops, which have been shown to be ubiquitous in motor systems (e.g., Kelly & Strick, 2003).\"],\n",
    "[107,0,0,\"This paper gives an overview of the humanoid robot 'H7', which was developed over several years as an experimental platform for walking, autonomous behaviour and human interaction research at the University of Tokyo. H7 was designed to be a human-sized robot capable of operating autonomously in indoor environments designed for humans. The hardware is relatively simple to operate and conduct research on, particularly with respect to the hierarchical design of its control architecture. We describe the overall design goals and methodology, along with a summary of its online walking capabilities, autonomous vision-based behaviours and automatic motion planning. We show experimental results obtained by implementations running within a simulation environment as well as on the actual robot hardware.\"],\n",
    "[108,0,0,\"This article presents a set of methods used to support the design and control of biologically inspired walking machines. Starting with a description of the general system design idea, an example for the design of the mechanical construction, a computer supported design procedure for the control architecture and the description of a three-dimensional world model to be used as knowledge base is given. The focus of this paper is on the engineering and integration process and the interrelation between the different phases of the design process.\"],\n",
    "[109,0,0,\"At present there exists a large gap in size, performance, adaptability and robustness between natural and artificial information processors for performing coherent perception-action tasks under real-time constraints. Even the simplest organisms have an enviable capability of coping with an unknown dynamic environment. Robots, in contrast, are still clumsy if confronted with such complexity. This paper presents a bio-hybrid architecture developed for exploring an alternate approach to the control of autonomous robots. Circuits prepared from amoeboid plasmodia of the slime mold Physarum polycephalum are interfaced with an omnidirectional hexapod robot. Sensory signals from the macro-physical environment of the robot are transduced to cellular scale and processed using the unique micro-physical features of intracellular information processing. Conversely, the response form the cellular computation is amplified to yield a macroscopic output action in the environment mediated through the robot's actuators.\"],\n",
    "[110,0,0,\"This work describes an innovative medical nanorobot architecture based on important discoveries in nanotechnology, integrated circuit patents, and some publications, directly or indirectly related to one of the most challenging new fields of science: molecular machines. Thus, the architecture described in this paper reflects, and is supported by, some remarkable recent achievements and patents in nanoelectronics, wireless communication and power transmission techniques, nanotubes, lithography, biomedical instrumentation, genetics, and photonics. We also describe how medicine can benefit from the joint development of nanodevices which are derived, and which integrate techniques, from artificial intelligence, nanotechnology, and embedded smart sensors. Teleoperated surgical procedures, early disease diagnosis, and pervasive patient monitoring are some possible applications of nanorobots, reflecting progress along a roadmap for the gradual and practical development of nanorobots. To illustrate the described nanorobot architecture, a computational 3D approach with the application of nanorobots for diabetes is simulated using clinical data. Theoretical and practical analysis of system integration modeling is one important aspect for supporting the rapid development in the emerging field of nanotechnology. This provides useful directions for further research and development of medical nanorobotics and suggests a time frame in which nanorobots may be expected to be available for common utilization in therapeutic and medical procedures.\"],\n",
    "[111,0,0,\"Previous experiments have shown that when domestic chicks (Gallus gallus) are first trained to locate food elements hidden at the centre of a closed square arena and then are tested in a square arena of double the size, they search for food both at its centre and at a distance from walls similar to the distance of the centre from the walls experienced during training. This paper presents a computational model that successfully reproduces these behaviours. The model is based on a neural-network implementation of the reinforcement-learning actor - critic architecture (in this architecture the 'critic' learns to evaluate perceived states in terms of predicted future rewards, while the 'actor' learns to increase the probability of selecting the actions that lead to higher evaluations). The analysis of the model suggests which type of information and cognitive mechanisms might underlie chicks' behaviours: (i) the tendency to explore the area at a specific distance from walls might be based on the processing of the height of walls' horizontal edges, (ii) the capacity to generalize the search at the centre of square arenas independently of their size might be based on the processing of the relative position of walls' vertical edges on the horizontal plane (equalization of walls' width), and (iii) the whole behaviour exhibited in the large square arena can be reproduced by assuming the existence of an attention process that, at each time, focuses chicks' internal processing on either one of the two previously discussed information sources. The model also produces testable predictions regarding the generalization capabilities that real chicks should exhibit if trained in circular arenas of varying size. The paper also highlights the potentialities of the model to address other experiments on animals' navigation and analyses its strengths and weaknesses in comparison to other models.\"],\n",
    "[112,0,0,\"Joysticks meet scalpels in a new computer-enhanced surgery system. A new robotic surgical system is taking laparoscopic surgery to new horizons. With the potential for greater surgical precision, shorter hospital stays, and better patient outcomes, this minimally invasive surgical technique offers an exciting new option for many patients undergoing various surgical procedures. Read on to learn more about robotic surgery, including your role in patient care.\"],\n",
    "[113,0,0,\"Wearable sensing networks offer a multitude of benefits for the user. One field that can benefit from such technologies is in-home robotics. Much work has been dedicated to the general area of interaction between robots and humans, and more specifically to gesture recognition. We propose a wearable monitoring network composed of conductive fabrics that can more easily facilitate robot interaction. It creates additional interaction by visual indication, and electronically by way of a local PC. This system creates a more natural human-robot interface and makes feasible many new forms of gesture recognition. Finally, we can address safety concerns; the garment gives us a method of locating the human and minimizing the possibility for robots to strike the user. In this paper, we lay out the architecture for such a system, and perform some of the initial characterization.\"],\n",
    "[114,0,0,\"OBJECTIVE: To develop a method enabling human-like, flexible supervisory control via delegation to automation. BACKGROUND: Real-time supervisory relationships with automation are rarely as flexible as human task delegation to other humans. Flexibility in human-adaptable automation can provide important benefits, including improved situation awareness, more accurate automation usage, more balanced mental workload, increased user acceptance, and improved overall performance. METHOD: We review problems with static and adaptive (as opposed to 'adaptable') automation; contrast these approaches with human-human task delegation, which can mitigate many of the problems; and revise the concept of a 'level of automation' as a pattern of task-based roles and authorizations. We argue that delegation requires a shared hierarchical task model between supervisor and subordinates, used to delegate tasks at various levels, and offer instruction on performing them. A prototype implementation called Playbook is described. RESULTS: On the basis of these analyses, we propose methods for supporting human-machine delegation interactions that parallel human-human delegation in important respects. We develop an architecture for machine-based delegation systems based on the metaphor of a sports team's 'playbook.' Finally, we describe a prototype implementation of this architecture, with an accompanying user interface and usage scenario, for mission planning for uninhabited air vehicles. CONCLUSION: Delegation offers a viable method for flexible, multilevel human-automation interaction to enhance system performance while maintaining user workload at a manageable level. APPLICATION: Most applications of adaptive automation (aviation, air traffic control, robotics, process control, etc.) are potential avenues for the adaptable, delegation approach we advocate. We present an extended example for uninhabited air vehicle mission planning.\"],\n",
    "[115,0,0,\"In prostate cancer treatment, there is a move toward targeted interventions for biopsy and therapy, which has precipitated the need for precise image-guided methods for needle placement. This paper describes an integrated system for planning and performing percutaneous procedures with robotic assistance under MRI guidance. A graphical planning interface allows the physician to specify the set of desired needle trajectories, based on anatomical structures and lesions observed in the patient's registered pre-operative and pre-procedural MR images, immediately prior to the intervention in an open-bore MRI scanner. All image-space coordinates are automatically computed, and are used to position a needle guide by means of an MRI-compatible robotic manipulator, thus avoiding the limitations of the traditional fixed needle template. Automatic alignment of real-time intra-operative images aids visualization of the needle as it is manually inserted through the guide. Results from in-scanner phantom experiments are provided.\"],\n",
    "[116,5,0,\"Animals' rhythmic movements, such as locomotion, are considered to be controlled by neural circuits called central pattern generators (CPGs), which generate oscillatory signals. Motivated by this biological mechanism, studies have been conducted on the rhythmic movements controlled by CPG. As an autonomous learning framework for a CPG controller, we propose in this article a reinforcement learning method we call the 'CPG-actor-critic' method. This method introduces a new architecture to the actor, and its training is roughly based on a stochastic policy gradient algorithm presented recently. We apply this method to an automatic acquisition problem of control for a biped robot. Computer simulations show that training of the CPG can be successfully performed by our method, thus allowing the biped robot to not only walk stably but also adapt to environmental changes.\"],\n",
    "[117,0,0,\"We present a programming-by-demonstration framework for generically extracting the relevant features of a given task and for addressing the problem of generalizing the acquired knowledge to different contexts. We validate the architecture through a series of experiments, in which a human demonstrator teaches a humanoid robot simple manipulatory tasks. A probability-based estimation of the relevance is suggested by first projecting the motion data onto a generic latent space using principal component analysis. The resulting signals are encoded using a mixture of Gaussian/Bernoulli distributions (Gaussian mixture model/Bernoulli mixture model). This provides a measure of the spatio-temporal correlations across the different modalities collected from the robot, which can be used to determine a metric of the imitation performance. The trajectories are then generalized using Gaussian mixture regression. Finally, we analytically compute the trajectory which optimizes the imitation metric and use this to generalize the skill to different contexts.\"],\n",
    "[118,0,0,\"In this paper, we present a strategy whereby a robot acquires the capability to learn by imitation following a developmental pathway consisting on three levels: 1) sensory-motor coordination; 2) world interaction; and 3) imitation. With these stages, the system is able to learn tasks by imitating human demonstrators. We describe results of the different developmental stages, involving perceptual and motor skills, implemented in our humanoid robot, Baltazar. At each stage, the system's attention is drawn toward different entities: its own body and, later on, objects and people. Our main contributions are the general architecture and the implementation of all the necessary modules until imitation capabilities are eventually acquired by the robot. Also, several other contributions are made at each level: learning of sensory-motor maps for redundant robots, a novel method for learning how to grasp objects, and a framework for learning task description from observation for program-level imitation. Finally, vision is used extensively as the sole sensing modality (sometimes in a simplified setting) avoiding the need for special data-acquisition hardware.\"],\n",
    "[119,0,0,\"The ROBODOC system has provided better fit and fill of the stem and less destruction of the bony architecture than with manual surgery. These benefits might affect femoral periprosthetic bone remodeling. We evaluated the effects of robotic milling in cementless total hip arthroplasty (THA) in a longitudinal 24-month follow-up study using dual energy X-ray absorptiometry (DEXA) and plain radiographs of 29 patients (31 hips) after ROBODOC THA and 24 patients (27 hips) after manual THA with the same stem design. To minimize the influence of other factors on bone remodeling, only female osteoarthritis patients, who had no drugs that might affect bone metabolism were enrolled. Significantly less bone loss occurred at the proximal periprosthetic areas in the ROBODOC group. In zone 1, the decrease was 15.5 versus 29.9% using conventional rasping; in zone 7, the loss was 17.0% with ROBODOC compared to 30.5% with conventional rasping (p < 0.05). On radiographs, endosteal spot welds in the proximal medial portion were more pronounced in the ROBODOC group (48 vs. 11% in the conventional group, p < 0.05). Our results suggest that robotic milling is effective in facilitating proximal load transfer around the femoral component and minimizing bone loss after cementless THA.\"],\n",
    "[120,0,0,\"We have been working to develop a compact, accurate, safe, and easy-to-use surgical robot for minimally invasive total knee arthroplasty (TKA). The goal of our bone-mounted robot, named Praxiteles, is to precisely position a surgical bone-cutting guide in the appropriate planes surrounding the knee, so that the surgeon can perform the planar cuts manually using the guide. The robot architecture is comprised of 2 motorized degrees of freedom (DoF) whose axes of rotation are arranged in parallel, and are precisely aligned to the implant cutting planes with a 2 DoF adjustment mechanism. Two prototypes have been developed and tested on saw bones and cadavers--an initial one for open TKA surgery and a new version for MIS TKA, which mounts on the side of the knee. A novel bone-milling technique is also presented that uses passive guide and a side milling tool.\"],\n",
    "[121,5,0,\"Human walking is a dynamic, partly self-stabilizing process relying on the interaction of the biomechanical design with its neuronal control. The coordination of this process is a very difficult problem, and it has been suggested that it involves a hierarchy of levels, where the lower ones, e.g., interactions between muscles and the spinal cord, are largely autonomous, and where higher level control (e.g., cortical) arises only pointwise, as needed. This requires an architecture of several nested, sensori-motor loops where the walking process provides feedback signals to the walker's sensory systems, which can be used to coordinate its movements. To complicate the situation, at a maximal walking speed of more than four leg-lengths per second, the cycle period available to coordinate all these loops is rather short. In this study we present a planar biped robot, which uses the design principle of nested loops to combine the self-stabilizing properties of its biomechanical design with several levels of neuronal control. Specifically, we show how to adapt control by including online learning mechanisms based on simulated synaptic plasticity. This robot can walk with a high speed (>3.0 leg length/s), self-adapting to minor disturbances, and reacting in a robust way to abruptly induced gait changes. At the same time, it can learn walking on different terrains, requiring only few learning experiences. This study shows that the tight coupling of physical with neuronal control, guided by sensory feedback from the walking pattern itself, combined with synaptic learning may be a way forward to better understand and solve coordination problems in other complex motor tasks.\"],\n",
    "[122,1,0,\"Although a variety of basic insect behaviours have inspired successful robot implementations, more complex capabilities in these 'simple' animals are often overlooked. By reviewing the general architecture of their nervous systems, we gain insight into how they are able to integrate behaviours, perform pattern recognition, context-dependent learning, and combine many sensory inputs in tasks such as navigation. We review in particular what is known about two specific 'higher' areas in the insect brain, the mushroom bodies and the central complex, and how they are involved in controlling an insect's behaviour. While much of the functional interpretation of this information is still speculative, it nevertheless suggests some promising new approaches to obtaining adaptive behaviour in robots.\"],\n",
    "[123,0,0,\"Unlike a purely reactive system where the motor output is exclusively controlled by the actual sensory input, a cognitive system must be capable of running mental processes which virtually simulate action sequences aimed at achieving a goal. The mental process either attempts to find a feasible course of action compatible with a number of constraints (Internal, Environmental, Task Specific etc) or selects it from a repertoire of previously learned actions, according to the parameters of the task. If neither reasoning process succeeds, a typical backup strategy is to look for a tool that might allow the operator to match all the task constraints. This further necessitates having the capability to alter ones own goal structures to generate sub-goals which must be successfully accomplished in order to achieve the primary goal. In this paper, we introduce a forward/inverse motor control architecture (FMC/IMC) that relaxes an internal model of the overall kinematic chain to a virtual force field applied to the end effector, in the intended direction of movement. This is analogous to the mechanism of coordinating the motion of a wooden marionette by means of attached strings. The relaxation of the FMC/IMC pair provides a general solution for mentally simulating an action of reaching a target position taking into consideration a range of geometric constraints (range of motion in the joint space, internal and external constraints in the workspace) as well as effort-related constraints (range of torque of the actuators, etc.). In case, the forward simulation is successful, the movement is executed; otherwise the residual 'error' or measure of inconsistency is taken as a starting point for breaking the action plan into a sequence of sub actions. This process is achieved using a recurrent neural network (RNN) which coordinates the overall reasoning process of framing and issuing goals to the forward inverse models, searching for alternatives tools in solution space and formation of sub-goals based on past context knowledge and present inputs. The RNN + FMC/IMC system is able to successfully reason and coordinate a diverse range of reaching and grasping sequences with/without tools. Using a simple robotic platform (5 DOF Scorbot arm + Stereo vision) we present results of reasoning and coordination of arm/tool movements (real and mental simulation) specifically directed towards solving the classical 2-stick paradigm from animal reasoning at a non linguistic level.\"],\n",
    "[124,0,0,\"Technology integration is an enabling technological prerequisite to achieve a major breakthrough in sophisticated intra-operative imaging, navigation and robotics in minimally invasive and/or emergency diagnosis and therapy. Without a high degree of integration and reliability comparable to that achieved in the aircraft industry image guidance in its different facets will not ultimately succeed. As of today technology integration in the field of image-guidance is close to nonexistent. Technology integration requires inter-departmental integration of human and financial resources and of medical processes in a dialectic way. This expanded techno-socio-economic integration has profound consequences for the administration and working conditions in hospitals. At the university hospital of Basel, Switzerland, a multimodality multifunction sterile suite was put into operation after a substantial pre-run. We report the lessons learned during our venture into the world of medical technology integration and describe new possibilities for similar integration projects in the future.\"],\n",
    "[125,0,0,\"We demonstrate the assembly of biohybrid materials from engineered tissues and synthetic polymer thin films. The constructs were built by culturing neonatal rat ventricular cardiomyocytes on polydimethylsiloxane thin films micropatterned with extracellular matrix proteins to promote spatially ordered, two-dimensional myogenesis. The constructs, termed muscular thin films, adopted functional, three-dimensional conformations when released from a thermally sensitive polymer substrate and were designed to perform biomimetic tasks by varying tissue architecture, thin-film shape, and electrical-pacing protocol. These centimeter-scale constructs perform functions as diverse as gripping, pumping, walking, and swimming with fine spatial and temporal control and generating specific forces as high as 4 millinewtons per square millimeter.\"],\n",
    "[126,0,0,\"This paper describes a novel two-degree-of-freedom robotic interface to train opening/closing of the hand and knob manipulation. The mechanical design, based on two parallelogram structures holding an exchangeable button, offers the possibility to adapt the interface to various hand sizes and finger orientations, as well as to right-handed or left-handed subjects. The interaction with the subject is measured by means of position encoders and four force sensors located close to the output measuring grasping and insertion forces. Various knobs can be mounted on the interface, including a cone mechanism to train a complete opening movement from a strongly contracted and closed hand to a large opened position. We describe the design based on measured biomechanics, the redundant safety mechanisms as well as the actuation and control architecture. Preliminary experiments show the performance of this interface and some of the possibilities it offers for the rehabilitation of hand function.\"],\n",
    "[127,0,0,\"Assistive technologies have recently emerged to improve the quality of life of severely disabled people by enhancing their independence in daily activities. Since many of those individuals have limited or non-existing control from the neck downward, alternative hands-free input modalities have become very important for these people to access assistive devices. In hands-free control, head movement has been proved to be a very effective user interface as it can provide a comfortable, reliable and natural way to access the device. Recently, neural networks have been shown to be useful not only for real-time pattern recognition but also for creating user-adaptive models. Since multi-layer perceptron neural networks trained using standard back-propagation may cause poor generalisation, the Bayesian technique has been proposed to improve the generalisation and robustness of these networks. This paper describes the use of Bayesian neural networks in developing a hands-free wheelchair control system. The experimental results show that with the optimised architecture, classification Bayesian neural networks can detect head commands of wheelchair users accurately irrespective to their levels of injuries.\"],\n",
    "[128,0,0,\"Software architecture for the navigation of a ferromagnetic untethered device in a 1D and 2D phantom environment is briefly described. Navigation is achieved using the real-time capabilities of a Siemens 1.5 T Avanto MRI system coupled with a dedicated software environment and a specially developed 3D tracking pulse sequence. Real-time control of the magnetic core is executed through the implementation of a simple PID controller. 1D and 2D experimental results are presented.\"],\n",
    "[129,0,0,\"Fuzzy Cognitive Maps (FCMs) are an efficient modeling method providing flexibility on the simulated system's design. They consist of nodes-concepts and weighted edges that connect the nodes and represent the cause and effect relationships among them. The performance of FCMs is dependent on the initial weight setting and architecture. This shortcoming can be alleviated and the FCM model can be enhanced if a fuzzy rule base (IF-THEN rules) is available. This research proposes a successful attempt to combine fuzzy cognitive maps with decision tree generators. A combined Decision Tree-Fuzzy Cognitive Map (DT-FCM) model is proposed when different types of input data are available and the behavior of this model is studied. In this research work, we introduce a new hybrid modeling methodology for decision making tasks and we implement the proposed methodology at a medical problem.\"],\n",
    "[130,0,0,\"Dividing an artificial muscle material into a network of small cells could provide performance benefits and eliminate unwanted behaviors such as hysteresis. This paper presents a scheme for the position control or compliance control of an artificial muscle having this kind of cellular structure. Each cell contracts or relaxes probabilistically in response to a global feedback control loop, which measures only the aggregate force and displacement of the muscle. The stochastic nature of the cells produces smooth, reliable global behavior in the artificial muscle. By choosing a control law such that the expected response of the artificial muscle is equal to the desired response, good tracking control is achieved.\"],\n",
    "[131,0,0,\"We envision cobotic infinitely-variable transmissions (IVTs) as an enabling technology for haptics and prosthetics that will allow for increases in the dynamic range of these devices while simultaneously permitting reductions in actuator size and power requirements. Use of cobotic IVTs eliminates the need to make compromises on output flow and effort, which are inherent to choosing a fixed transmission ratio drivetrain. The result is a mechanism with enhanced dynamic range that extends continuously from a completely clutched state to a highly backdrivable state. This high dynamic range allows cobotic devices to control impedance with a high level of fidelity. In this paper, we discuss these and other motivations for using parallel cobotic transmission architecture in prosthetic devices.\"],\n",
    "[132,0,0,\"Medical problems involve different types of variables and data, which have to be processed, analyzed and synthesized in order to reach a decision and/or conclude to a diagnosis. Usually, information and data set are both symbolic and numeric but most of the well-known data analysis methods deal with only one kind of data. Even when fuzzy approaches are considered, which are not depended on the scales of variables, usually only numeric data is considered. The medical decision support methods usually are accessed in only one type of available data. Thus, sophisticated methods have been proposed such as integrated hybrid learning approaches to process symbolic and numeric data for the decision support tasks. Fuzzy Cognitive Maps (FCM) is an efficient modelling method, which is based on human knowledge and experience and it can handle with uncertainty and it is constructed by extracted knowledge in the form of fuzzy rules. The FCM model can be enhanced if a fuzzy rule base (IF-THEN rules) is available. This rule base could be derived by a number of machine learning and knowledge extraction methods. Here it is introduced a hybrid attempt to handle situations with different types of available medical and/or clinical data and with difficulty to handle them for decision support tasks using soft computing techniques.\"],\n",
    "[133,0,0,\"In this study, a biologically inspired control structure to control the sit-to-stand (STS) transfer from a chair is developed and simulated. STS movement is consisted of two main phases. First phase of the movement is before leaving the seat (seat-off moment). In this phase seat reactions forces act on the body parts which are in contact with the seat. The second phase is after seat-off, where the only external forces acting on the body are ground reaction forces. A proper control algorithm of the STS transfer needs to consider switching between these two phases, which correspond to two different dynamical structures. The control structure developed and discussed in this work is based on the MOSAIC structure, proposed first by Wolpert and Kawato [1]. Original MOSAIC structure has a modular architecture which is based on multiple pairs of forward and inverse models of the dynamical system to be controlled, and each module is trained separately to learn one part of a given task. The number of effective modules is predetermined. We have developed a new method to train all modules simultaneously. This method is based on reinforcement and cooperative competitive learning, and the number of effective modules is determined automatically. In this study, the simulation was begun with four modules. Our results showed that only two modules out of four were selected to control the STS task. Responsibility of controlling the task was switched between the two modules around the seat-off moment.\"],\n",
    "[134,0,0,\"This work improves recent results concerning the adaptive control of mobile robots via neural and wavelet networks, in the sense that the stability proof, based on the second method of Lyapunov, encompasses (1) unmodeled dynamics and disturbances in the robot model; (2) adaptation of all parameters in the wavelet networks; and (3) a flexible procedure for automatically adjusting the wavelet architecture. Prior knowledge of dynamic of the mobile robot and network training is not necessary because the controller learns the dynamics online. The wavelet network's parameters and structure are also adapted online. Simulation results are presented by using parameters of the Magellan mobile robot from IS Robotics, Inc.\"],\n",
    "[135,0,0,\"In this paper, we present the use of stochastic learning automata (SLA) in multiagent robotics. In order to fully utilize and implement learning control algorithms in the control of multiagent robotics, an environment for simulation has to be first created. A virtual laboratory for simulation of autonomous agents, called V-Lab is described. The V-Lab architecture can incorporate various models of the environment as well as the agent being trained. A case study to demonstrate the use of SLA is presented.\"],\n",
    "[136,0,0,\"In this paper, we address the problem of navigating an autonomous mobile robot in an unknown indoor environment. The parti-game multiresolution learning approach is applied for simultaneous and cooperative construction of a world model, and learning to navigate through an obstacle-free path from a starting position to a known goal region. The paper introduces a new approach, based on the application of the fuzzy ART neural architecture, for on-line map building from actual sensor data. This method is then integrated, as a complement, on the parti-game world model, allowing the system to make a more efficient use of collected sensor information. Then, a predictive on-line trajectory filtering method, is introduced in the learning approach. Instead of having a mechanical device moving to search the world, the idea is to have the system analyzing trajectories in a predictive mode, by taking advantage of the improved world model. The real robot will only move to try trajectories that have been predicted to be successful, allowing lower exploration costs. This results in an overall improved new method for goal-oriented navigation. It is assumed that the robot knows its own current world location-a simple dead-reckoning method is used for localization in our experiments. It is also assumed that the robot is able to perform sensor-based obstacle detection (not avoidance) and straight-line motions. Results of experiments with a real Nomad 200 mobile robot are presented, demonstrating the effectiveness of the discussed methods.\"],\n",
    "[137,0,0,\"OBJECTIVE: To present early functional and oncological data for the athermal trizonal nerve-sparing technique of robotic radical prostatectomy (RP), that addresses the concerns about deviations from the principles of open RP and revisits the anatomical foundations of this surgery from the robotic perspective. PATIENTS AND METHODS: The study involved close collaboration between the Cornell Institute of Robotic Surgery in New York, USA, and the Institute of Urology at the University of Innsbruck in Austria. The cadaveric studies and standardization of the athermal technique were conducted at Innsbruck, and the technique was used in 215 patients in New York. RESULTS: The athermal technique addresses concerns about the use of thermal energy and bulldog clamps during nerve sparing, and emphasizes the importance of the trizonal neural architecture. We analysed the surgical outcomes of 215 consecutive patients from January 2005. The operative duration was 120-240 min and the mean blood loss was 150 mL. In patients potent before RP the potency rate at 1 year after bilateral nerve-sparing was 87%. The overall surgical margin rate was 6.5% and positive margin rates for organ-confined cancer were 4.7%. CONCLUSION: We describe the athermal technique of robotic RP and introduce the concept of trizonal nerve preservation. The immediate oncological and sexual outcomes were encouraging.\"],\n",
    "[138,0,0,\"Homotypic and heterotypic protein interactions are crucial for all levels of cellular function, including architecture, regulation, metabolism, and signaling. Therefore, protein interaction maps represent essential components of post-genomic toolkits needed for understanding biological processes at a systems level. Over the past decade, a wide variety of methods have been developed to detect, analyze, and quantify protein interactions, including surface plasmon resonance spectroscopy, NMR, yeast two-hybrid screens, peptide tagging combined with mass spectrometry and fluorescence-based technologies. Fluorescence techniques range from co-localization of tags, which may be limited by the optical resolution of the microscope, to fluorescence resonance energy transfer-based methods that have molecular resolution and can also report on the dynamics and localization of the interactions within a cell. Proteins interact via highly evolved complementary surfaces with affinities that can vary over many orders of magnitude. Some of the techniques described in this review, such as surface plasmon resonance, provide detailed information on physical properties of these interactions, while others, such as two-hybrid techniques and mass spectrometry, are amenable to high-throughput analysis using robotics. In addition to providing an overview of these methods, this review emphasizes techniques that can be applied to determine interactions involving membrane proteins, including the split ubiquitin system and fluorescence-based technologies for characterizing hits obtained with high-throughput approaches. Mass spectrometry-based methods are covered by a review by Miernyk and Thelen (2008; this issue, pp. 597-609). In addition, we discuss the use of interaction data to construct interaction networks and as the basis for the exciting possibility of using to predict interaction surfaces.\"],\n",
    "[139,0,0,\"We designed a VLSI binocular vision system that emulates the disparity computation in the primary visual cortex (V1). The system consists of two silicon retinas, orientation chips, and field programmable gate array (FPGA), mimicking a hierarchical architecture of visual information processing in the disparity energy model. The silicon retinas emulate a Laplacian-Gaussian-like receptive field of the vertebrate retina. The orientation chips generate an orientation-selective receptive field by aggregating multiple pixels of the silicon retina, mimicking the Hubel-Wiesel-type feed-forward model in order to emulate a Gabor-like receptive field of simple cells. The FPGA receives outputs from the orientation chips corresponding to the left and right eyes and calculates the responses of the complex cells based on the disparity energy model. The system can provide the responses of complex cells tuned to five different disparities and a disparity map obtained by comparing these energy outputs. Owing to the combination of spatial filtering by analog parallel circuits and pixel-wise computation by hard-wired digital circuits, the present system can execute the disparity computation in real time using compact hardware.\"],\n",
    "[140,0,0,\"A closed kinematic chain, like an arm that operates a crank, has a constrained movement space. A meaningful movement of the chain's endpoint is only possible along the free movement directions which are given implicitly by the contour of the object that confines the movement of the chain. Many technical solutions for such a movement task, in particular those used in robotics, use central controllers and force-torque sensors in the arm's wrist or a leg's ankle to construct a coordinate system (task frame formalism) at the local point of contact the axes of which coincide with the free and constrained movement directions. Motivated by examples from biology, we introduce a new control system that solves a constrained movement task. The control system is inspired by the control architecture that is found in stick insects like Carausius morosus. It consists of decentral joint controllers that work on elastic joints (compliant manipulator). The decentral controllers are based on local positive velocity feedback (LPVF). It has been shown earlier that LPVF enables contour following of a limb in a compliant motion task without a central controller. In this paper we extend LPVF in such a way that it is even able to follow a contour if a considerable counter force drags the limb away along the contour in a direction opposite to the desired. The controller extension is based on the measurement of the local mechanical power generated in the elastic joint and is called power-controlled relaxation LPVF. The new control approach has the following advantages. First, it still uses local joint controllers without knowledge of the kinematics. Second, it does not need a force or torque measurement at the end of the limb. In this paper we test power-controlled relaxation LPVF on a crank turning task in which a weight has to be winched up by a two-joint compliant manipulator.\"],\n",
    "[141,0,0,\"This work presents a new approach with details on the integrated platform and hardware architecture for nanorobots application in epidemic control, which should enable real time in vivo prognosis of biohazard infection. The recent developments in the field of nanoelectronics, with transducers progressively shrinking down to smaller sizes through nanotechnology and carbon nanotubes, are expected to result in innovative biomedical instrumentation possibilities, with new therapies and efficient diagnosis methodologies. The use of integrated systems, smart biosensors, and programmable nanodevices are advancing nanoelectronics, enabling the progressive research and development of molecular machines. It should provide high precision pervasive biomedical monitoring with real time data transmission. The use of nanobioelectronics as embedded systems is the natural pathway towards manufacturing methodology to achieve nanorobot applications out of laboratories sooner as possible. To demonstrate the practical application of medical nanorobotics, a 3D simulation based on clinical data addresses how to integrate communication with nanorobots using RFID, mobile phones, and satellites, applied to long distance ubiquitous surveillance and health monitoring for troops in conflict zones. Therefore, the current model can also be used to prevent and save a population against the case of some targeted epidemic disease.\"],\n",
    "[142,0,0,\"This work presents an innovative nanorobot architecture based on nanobioelectronics for diabetes. The progressive development toward the therapeutic use of nanorobots should be observed as the natural result from some ongoing and future achievements in biomedical instrumentation, wireless communication, remote power transmission, nanoelectronics, new materials engineering, chemistry, proteomics, and photonics. To illustrate the nanorobot integrated circuit architecture and layout described here, a computational approach with the application of medical nanorobotics for diabetes is simulated using clinical data. Integrated simulation can provide interactive tools for addressing nanorobot choices on sensing, hardware design specification, manufacturing analysis, and methodology for control investigation. In the proposed 3D prototyping, a physician can help the patient to avoid hyperglycemia by means of a handheld device, like a cell phone enclosed with cloth, that is used as a smart portable device to communicate with nanorobots. Therefore, this architecture provides a suitable choice to establish a practical medical nanorobotics platform for in vivo health monitoring.\"],\n",
    "[143,5,0,\"Action selection, the problem of choosing what to do next, is central to any autonomous agent architecture. We use here a multi-disciplinary approach at the convergence of neuroscience, dynamical system theory and autonomous robotics, in order to propose an efficient action selection mechanism based on a new model of the basal ganglia. We first describe new developments of contraction theory regarding locally projected dynamical systems. We exploit these results to design a stable computational model of the cortico-baso-thalamo-cortical loops. Based on recent anatomical data, we include usually neglected neural projections, which participate in performing accurate selection. Finally, the efficiency of this model as an autonomous robot action selection mechanism is assessed in a standard survival task. The model exhibits valuable dithering avoidance and energy-saving properties, when compared with a simple if-then-else decision rule.\"],\n",
    "[144,0,0,\"Autonomous robots interacting with human users need to build and continuously update scene representations. This entails the problem of rapidly learning to recognize new objects under user guidance. Based on analogies with human visual working memory, we propose a dynamical field architecture, in which localized peaks of activation represent objects over a small number of simple feature dimensions. Learning consists of laying down memory traces of such peaks. We implement the dynamical field model on a service robot and demonstrate how it learns 30 objects from a very small number of views (about 5 per object are sufficient). We also illustrate how properties of feature binding emerge from this framework.\"],\n",
    "[145,0,0,\"To support large numbers of model neurons, neuromorphic vision systems are increasingly adopting a distributed architecture, where different arrays of neurons are located on different chips or processors. Spike-based protocols are used to communicate activity between processors. The spike activity in the arrays depends on the input statistics as well as internal parameters such as time constants and gains. In this paper, we investigate strategies for automatically adapting these parameters to maintain a constant firing rate in response to changes in the input statistics. We find that under the constraint of maintaining a fixed firing rate, a strategy based upon updating the gain alone performs as well as an optimal strategy where both the gain and the time constant are allowed to vary. We discuss how to choose the time constant and propose an adaptive gain control mechanism whose operation is robust to changes in the input statistics. Our experimental results on a mobile robotic platform validate the analysis and efficacy of the proposed strategy.\"],\n",
    "[146,1,0,\"The vestibulo-ocular reflex stabilizes vision in many vertebrates. It integrates inertial and visual information to drive the eyes in the opposite direction to head movement and thereby stabilizes the image on the retina. Its adaptive nature guarantees stable vision even when the biological system undergoes dynamic changes (due to disease, growth or fatigue etc), a characteristic especially desirable in autonomous robotic systems. Based on novel, biologically plausible neurological models, we have developed a robotic testbed to qualitatively evaluate the performance of these algorithms. We show how the adaptive controller can adapt to a time varying plant and elaborate how this biologically inspired control architecture can be employed in general engineering applications where sensory feedback is very noisy and/or delayed.\"],\n",
    "[147,0,0,\"Recent research in rehabilitation indicates that tasks that focus on activities of daily living (ADL) are likely to show significant increase in motor recovery after stroke. Most ADL tasks require patients to coordinate their arm and hand movements to complete these tasks. This paper presents a new control approach for robot-assisted rehabilitation of stroke patients that enables them to perform ADL by providing controlled and coordinated assistance to both arm and hand movement. The control architecture is represented in terms of a hybrid system model combining a high-level controller for decision-making and two low-level assistive controllers (arm and hand controllers) for arm and hand motion assistance. The presented controller is implemented on a test-bed and the results of this implementation are presented to demonstrate the feasibility of the proposed control architecture.\"],\n",
    "[148,1,0,\"We describe a neural network model of the cerebellum based on integrate-and-fire spiking neurons with conductance-based synapses. The neuron characteristics are derived from our earlier detailed models of the different cerebellar neurons. We tested the cerebellum model in a real-time control application with a robotic platform. Delays were introduced in the different sensorimotor pathways according to the biological system. The main plasticity in the cerebellar model is a spike-timing dependent plasticity (STDP) at the parallel fiber to Purkinje cell connections. This STDP is driven by the inferior olive (IO) activity, which encodes an error signal using a novel probabilistic low frequency model. We demonstrate the cerebellar model in a robot control system using a target-reaching task. We test whether the system learns to reach different target positions in a non-destructive way, therefore abstracting a general dynamics model. To test the system's ability to self-adapt to different dynamical situations, we present results obtained after changing the dynamics of the robotic platform significantly (its friction and load). The experimental results show that the cerebellar-based system is able to adapt dynamically to different contexts.\"],\n",
    "[149,0,0,\"BACKGROUND: Computer-assisted surgery (CAS) systems are currently used in only a few surgical specialties: ear, nose and throat (ENT), neurosurgery and orthopaedics. Almost all of these systems have been developed as dedicated platforms and work on rigid anatomical structures. The development of augmented reality systems for intra-abdominal organs remains problematic because of the anatomical complexity of the human peritoneal cavity and especially because of the deformability of its organs. The aim of the present work was to develop and implement a highly modular platform (targeted for minimally invasive laparoscopic surgery) generally suitable for CAS, and to produce a prototype for demonstration of its potential clinical application and use in laparoscopic surgery. METHODS: In this paper we outline details of a platform integrating several aspects of CAS and medical robotics into a modular open architecture: the EndoCAS navigator platform, which integrates all the functionalities necessary for provision of computer-based assistance to surgeons during all the management phases (diagnostic work-up, planning and intervention). A specific application for computer-assisted laparoscopic procedures has been developed on the basic modules of the platform. The system provides capabilities for three-dimensional (3D) surface model generation, 3D visualization, intra-operative registration, surgical guidance and robotic assistance during laparoscopic surgery. The description of specific modules and an account of the initial clinical experience with the system are reported. RESULTS: We developed a common platform for computer assisted surgery and implemented a system for intraoperative laparoscopic navigation. The preliminary clinical trials and feedback from the surgeons on its use in laparoscopic surgery have been positive, although experience has been limited to date. CONCLUSIONS: We have successfully developed a system for computer-assisted technologies for use in laparoscopic surgery and demonstrated, by early clinical trials, that the introduction of these technologies in operative laparoscopy, even though they are not yet sufficiently accurate (from an engineering viewpoint) for surgical treatment of intra-abdominal disease, brings added benefits to the execution of interventions by surgeons and hence represents concrete on-going progress in interventional technology.\"],\n",
    "[150,9,1,\"OBJECTIVE: One of the major topics towards robot consciousness is to give a robot the capabilities of self-consciousness. We propose that robot self-consciousness is based on higher order perception of the robot, in the sense that first-order robot perception is the immediate perception of the outer world, while higher order perception is the perception of the inner world of the robot. METHODS AND MATERIAL: We refer to a robot cognitive architecture that has been developed during almost 10 years at the RoboticsLab of the University of Palermo. The architecture is organized in three computational areas. The subconceptual area is concerned with the low level processing of perceptual data coming from the sensors. In the linguistic area, representation and processing are based on a logic formalism. In the conceptual area, the data coming from the subconceptual area are organized in conceptual categories. RESULTS: To model higher order perceptions in self-reflective agents, we introduce the notion of second-order points in conceptual space. Each point in this space corresponds to a self-reflective agent, i.e., the robot itself, persons, and other robots with introspective capabilities. CONCLUSIONS: The described model of robot self-consciousness, although effective, highlights open problems from the point of view of the computational requirements of the current state-of-art computer systems. Some future works that lets the robot to summarize its own past experiences should be investigated.\"],\n",
    "[151,0,0,\"Off-pump Coronary Artery Bypass Grafting (CABG) is still a technically difficult procedure. The mechanical stabilizers used for local suppression of the heart excursion have been demonstrated to exhibit significant residual motion, which could lead to a lack of accuracy in performing the surgical task, particularly when using a minimally invasive surgery (MIS) approach. We therefore propose a novel active stabilizer to compensate for the residual motion whose architecture is compatible with MIS. An experimental evaluation of a commercially available totally endoscopic stabilizer is first presented to demonstrate the unsatisfactory behavior of this device. Then, the interaction between the heart and a mechanical stabilizer is assessed in vivo using an animal model. Finally, the principle of active stabilization, based on the high-speed vision-based control of a piezo-actuated compliant mechanism, is presented, along with in vivo experimental results obtained using a prototype to demonstrate its efficiency.\"],\n",
    "[152,0,0,\"Traditional research in artificial intelligence and machine learning has viewed the brain as a specially adapted information-processing system. More recently the field of social robotics has been advanced to capture the important dynamics of human cognition and interaction. An overarching societal goal of this research is to incorporate the resultant knowledge about intelligence into technology for prosthetic, assistive, security, and decision support applications. However, despite many decades of investment in learning and classification systems, this paradigm has yet to yield truly 'intelligent' systems. For this reason, many investigators are now attempting to incorporate more realistic neuromorphic properties into machine learning systems, encouraged by over two decades of neuroscience research that has provided parameters that characterize the brain's interdependent genomic, proteomic, metabolomic, anatomic, and electrophysiological networks. Given the complexity of neural systems, developing tenable models to capture the essence of natural intelligence for real-time application requires that we discriminate features underlying information processing and intrinsic motivation from those reflecting biological constraints (such as maintaining structural integrity and transporting metabolic products). We propose herein a conceptual framework and an iterative method of virtual neurorobotics (VNR) intended to rapidly forward-engineer and test progressively more complex putative neuromorphic brain prototypes for their ability to support intrinsically intelligent, intentional interaction with humans. The VNR system is based on the viewpoint that a truly intelligent system must be driven by emotion rather than programmed tasking, incorporating intrinsic motivation and intentionality. We report pilot results of a closed-loop, real-time interactive VNR system with a spiking neural brain, and provide a video demonstration as online supplemental material.\"],\n",
    "[153,0,0,\"This paper presents a novel parameter adjustment scheme to improve the robustness of fuzzy sliding-mode control achieved by the use of an adaptive neuro-fuzzy inference system (ANFIS) architecture. The proposed scheme utilizes fractional-order integration in the parameter tuning stage. The controller parameters are tuned such that the system under control is driven toward the sliding regime in the traditional sense. After a comparison with the classical integer-order counterpart, it is seen that the control system with the proposed adaptation scheme displays better tracking performance, and a very high degree of robustness and insensitivity to disturbances are observed. The claims are justified through some simulations utilizing the dynamic model of a 2-DOF direct-drive robot arm. Overall, the contribution of this paper is to demonstrate that the response of the system under control is significantly better for the fractional-order integration exploited in the parameter adaptation stage than that for the classical integer-order integration.\"],\n",
    "[154,5,0,\"We propose a technique to speedup the learning of the inverse kinematics of a robot manipulator by decomposing it into two or more virtual robot arms. Unlike previous decomposition approaches, this one does not place any requirement on the robot architecture, and thus, it is completely general. Parametrized self-organizing maps are particularly adequate for this type of learning, and permit comparing results directly obtained and through the decomposition. Experimentation shows that time reductions of up to two orders of magnitude are easily attained.\"],\n",
    "[155,0,0,\"In this paper we present an improved model for line and edge detection in cortical area V1. This model is based on responses of simple and complex cells, and it is multi-scale with no free parameters. We illustrate the use of the multi-scale line/edge representation in different processes: visual reconstruction or brightness perception, automatic scale selection and object segregation. A two-level object categorization scenario is tested in which pre-categorization is based on coarse scales only and final categorization on coarse plus fine scales. We also present a multi-scale object and face recognition model. Processing schemes are discussed in the framework of a complete cortical architecture. The fact that brightness perception and object recognition may be based on the same symbolic image representation is an indication that the entire (visual) cortex is involved in consciousness.\"],\n",
    "[156,5,0,\"We have designed a visually guided collision warning system with a neuromorphic architecture, employing an algorithm inspired by the visual nervous system of locusts. The system was implemented with mixed analog-digital integrated circuits consisting of an analog resistive network and field-programmable gate array (FPGA) circuits. The resistive network processes the interaction between the laterally spreading excitatory and inhibitory signals instantaneously, which is essential for real-time computation of collision avoidance with a low power consumption and a compact hardware. The system responded selectively to approaching objects of simulated movie images at close range. The system was, however, confronted with serious noise problems due to the vibratory ego-motion, when it was installed in a mobile miniature car. To overcome this problem, we developed the algorithm, which is also installable in FPGA circuits, in order for the system to respond robustly during the ego-motion.\"],\n",
    "[157,1,0,\"The capability of grasping and lifting an object in a suitable, stable and controlled way is an outstanding feature for a robot, and thus far, one of the major problems to be solved in robotics. No robotic tools able to perform an advanced control of the grasp as, for instance, the human hand does, have been demonstrated to date. Due to its capital importance in science and in many applications, namely from biomedics to manufacturing, the issue has been matter of deep scientific investigations in both the field of neurophysiology and robotics. While the former is contributing with a profound understanding of the dynamics of real-time control of the slippage and grasp force in the human hand, the latter tries more and more to reproduce, or take inspiration by, the nature's approach, by means of hardware and software technology. On this regard, one of the major constraints robotics has to overcome is the real-time processing of a large amounts of data generated by the tactile sensors while grasping, which poses serious problems to the available computational power. In this paper a bio-inspired approach to tactile data processing has been followed in order to design and test a hardware-software robotic architecture that works on the parallel processing of a large amount of tactile sensing signals. The working principle of the architecture bases on the cellular nonlinear/neural network (CNN) paradigm, while using both hand shape and spatial-temporal features obtained from an array of microfabricated force sensors, in order to control the sensory-motor coordination of the robotic system. Prototypical grasping tasks were selected to measure the system performances applied to a computer-interfaced robotic hand. Successful grasps of several objects, completely unknown to the robot, e.g. soft and deformable objects like plastic bottles, soft balls, and Japanese tofu, have been demonstrated.\"],\n",
    "[158,0,0,\"We report an experimental and theoretical investigation into mass transport between individual carbon nanotubes (CNTs) via their central cores. These CNT fluidic junctions can serve as basic elements for more complex nanofluidic systems and can also provide a structure for testing theories of fluid flow at the nanoscale. Controlled melting, evaporation, and flowing of copper and tin within and between nanotube shells are investigated experimentally. Cap-to-wall and wall-to-cap mass flow are realized by electric current driven heating, diffusion, and electromigration under low bias voltages between 1.5 and 1.8 V. A comparison shows that the mass loss for the cap-to-wall architecture is much smaller than that for the wall-to-cap junction. A molecular dynamics simulation is presented that provides further insight into the transport mechanism.\"],\n",
    "[159,0,0,\"This paper presents design, hardware, software, and parameter optimization for a novel robotic automation system. RABiT is a Rapid Automated Biodosimetry Tool for high throughput radiological triage. The design considerations guiding the hardware and software architecture are presented with focus on methods of communication, ease of implementation, and need for real-time control versus soft time control cycles. The design and parameter determination for a non-contact PVC capillary laser cutting system is presented. A novel approach for lymphocyte concentration estimation based on computer vision is reported. Experimental evaluations of the system components validate the success of our prototype system in achieving a throughput of 6,000 samples in a period of 18 hours.\"],\n",
    "[160,5,0,\"In this paper a new technique for action-oriented perception in robots is presented. The paper starts from exploiting the successful implementation of the basic idea that perceptual states can be embedded into chaotic attractors whose dynamical evolution can be associated with sensorial stimuli. In this way, it can be possible to encode, into the chaotic dynamics, environment-dependent patterns. These have to be suitably linked to an action, executed by the robot, to fulfill an assigned mission. This task is addressed here: the action-oriented perception loop is closed by introducing a simple unsupervised learning stage, implemented via a bio-inspired structure based on the motor map paradigm. In this way, perceptual meanings, useful for solving a given task, can be autonomously learned, based on the environment-dependent patterns embedded into the controlled chaotic dynamics. The presented framework has been tested on a simulated robot and the performance have been successfully compared with other traditional navigation control paradigms. Moreover an implementation of the proposed architecture on a Field Programmable Gate Array is briefly outlined and preliminary experimental results on a roving robot are also reported.\"],\n",
    "[161,0,0,\"Body undulation used by snakes and the physical architecture of a snake body may offer significant benefits over typical legged or wheeled locomotion designs in certain types of scenarios. A large number of research groups have developed snake-inspired robots to exploit these benefits. The purpose of this review is to report different types of snake-inspired robot designs and categorize them based on their main characteristics. For each category, we discuss their relative advantages and disadvantages. This review will assist in familiarizing a newcomer to the field with the existing designs and their distinguishing features. We hope that by studying existing robots, future designers will be able to create new designs by adopting features from successful robots. The review also summarizes the design challenges associated with the further advancement of the field and deploying snake-inspired robots in practice.\"],\n",
    "[162,0,0,\"Tumor mobility poses significant difficulty in obtaining tissue samples during ultrasound guided breast biopsy. In this work, we present a new concept for coordinated real-time tumor manipulation and ultrasound imaging using a hybrid control architecture. The idea here is to demonstrate that it is possible to (1) manipulate a tumor in real-time by applying controlled external force, (2) control the position of the ultrasound probe for tracking out-of-plane target movement, and (3) coordinate the above systems in an automated way such that the tumor does not deviate from the path of the needle. Experiments are performed on breast tissue mimicking phantoms to demonstrate the efficacy of this technique. The success of this approach has the potential to reduce the number of attempts a surgeon makes to capture the desired tissue specimen, minimize tissue damage, improve speed of biopsy, and reduce patient discomfort.\"],\n",
    "[163,0,0,\"This paper introduces and demonstrates a novel brain-machine interface (BMI) architecture based on the concepts of reinforcement learning (RL), coadaptation, and shaping. RL allows the BMI control algorithm to learn to complete tasks from interactions with the environment, rather than an explicit training signal. Coadaption enables continuous, synergistic adaptation between the BMI control algorithm and BMI user working in changing environments. Shaping is designed to reduce the learning curve for BMI users attempting to control a prosthetic. Here, we present the theory and in vivo experimental paradigm to illustrate how this BMI learns to complete a reaching task using a prosthetic arm in a 3-D workspace based on the user's neuronal activity. This semisupervised learning framework does not require user movements. We quantify BMI performance in closed-loop brain control over six to ten days for three rats as a function of increasing task difficulty. All three subjects coadapted with their BMI control algorithms to control the prosthetic significantly above chance at each level of difficulty.\"],\n",
    "[164,0,0,\"In this paper we present a sound-source model for localising and tracking an acoustic source of interest along the azimuth plane in acoustically cluttered environments, for a mobile service robot. The model we present is a hybrid architecture using cross-correlation and recurrent neural networks to develop a robotic model accurate and robust enough to perform within an acoustically cluttered environment. This model has been developed with considerations of both processing power and physical robot size, allowing for this model to be deployed on to a wide variety of robotic systems where power consumption and size is a limitation. The development of the system we present has its inspiration taken from the central auditory system (CAS) of the mammalian brain. In this paper we describe experimental results of the proposed model including the experimental methodology for testing sound-source localisation systems. The results of the system are shown in both restricted test environments and in real-world conditions. This paper shows how a hybrid architecture using band pass filtering, cross-correlation and recurrent neural networks can be used to develop a robust, accurate and fast sound-source localisation model for a mobile robot.\"],\n",
    "[165,0,0,\"This paper proposes an extension of the self-organizing map (SOM), in which the mapping objects themselves are self-organizing maps. Thus a 'SOM of SOMs' is presented, which we refer to as a SOM(2). A SOM(2) has a hierarchical structure consisting of a single parent SOM and a set of child SOMs. Each child SOM is trained to represent the distribution of a data class in a manifold, while the parent SOM generates a self-organizing map of the group of manifolds modeled by the child SOMs. Thus a SOM(2) is an architecture that organizes a product manifold represented as (child SOM) x (parent SOM). Such a product manifold is called a fiber bundle in terms of the topology. This extension of a SOM is easily generalized to any combination of SOM families, including cases of neural gas (NG) in which, for example, ' NG(2) (=NG x NG) as an NG of NGs' and 'NG x SOM as a SOM of NGs' are possible. Furthermore, a SOM(2) can be extended to a SOM(n), such as SOM(3)=SOM x SOM x SOM defined as a 'SOM of SOM(2)'. In this paper, the algorithms for the SOM(2) and its variations are introduced, and some simulation results are reported.\"],\n",
    "[166,5,0,\"Humans have the ability to learn novel motor tasks while manipulating the environment. Several models of motor learning have been proposed in the literature, but few of them address the problem of retention and interference of motor memory. The modular selection and identification for control (MOSAIC) model, originally proposed by Wolpert and Kawato, is one of the most relevant contributions; it suggests a possible strategy on how the human motor control system learns and adapts to novel environments. MOSAIC employs the concept of forward and inverse models. The same group later proposed the hidden Markov model (HMM) MOSAIC, which affords learning multiple tasks. The significant drawback of this second approach is that the HMM must be trained with a complete data set that includes all contexts. Since the number of contexts or modules is fixed from the onset, this approach does not afford incremental learning of new tasks. In this letter, we present an alternative architecture to overcome this problem, based on a nonparametric regression algorithm, named locally weighted projection regression (LWPR). This network structure develops according to the contexts allowing incremental training. Of notice, interaction force is used to disambiguate among different contexts. We demonstrate the capability of this alternative architecture with a simulated 2 degree-of-freedom representation of the human arm that learns to interact with three distinct objects, reproducing the same test paradigm of the HMM MOSAIC. After learning the dynamics of the three objects, the LWPR network successfully learns to compensate for a novel velocity-dependent force field. Equally important, it retains previously acquired knowledge on the interaction with the three objects. Thus, this architecture allows both incremental learning of new tasks and retention of previously acquired knowledge, a feature of human motor learning and memory.\"],\n",
    "[167,5,0,\"BACKGROUND: Several authors suggested that gravitational forces are centrally represented in the brain for planning, control and sensorimotor predictions of movements. Furthermore, some studies proposed that the cerebellum computes the inverse dynamics (internal inverse model) whereas others suggested that it computes sensorimotor predictions (internal forward model). METHODOLOGY/PRINCIPAL FINDINGS: This study proposes a model of cerebellar pathways deduced from both biological and physical constraints. The model learns the dynamic inverse computation of the effect of gravitational torques from its sensorimotor predictions without calculating an explicit inverse computation. By using supervised learning, this model learns to control an anthropomorphic robot arm actuated by two antagonists McKibben artificial muscles. This was achieved by using internal parallel feedback loops containing neural networks which anticipate the sensorimotor consequences of the neural commands. The artificial neural networks architecture was similar to the large-scale connectivity of the cerebellar cortex. Movements in the sagittal plane were performed during three sessions combining different initial positions, amplitudes and directions of movements to vary the effects of the gravitational torques applied to the robotic arm. The results show that this model acquired an internal representation of the gravitational effects during vertical arm pointing movements. CONCLUSIONS/SIGNIFICANCE: This is consistent with the proposal that the cerebellar cortex contains an internal representation of gravitational torques which is encoded through a learning process. Furthermore, this model suggests that the cerebellum performs the inverse dynamics computation based on sensorimotor predictions. This highlights the importance of sensorimotor predictions of gravitational torques acting on upper limb movements performed in the gravitational field.\"],\n",
    "[168,0,0,\"This paper presents the results of modeling of an inverted pendulum system driven by a linear pneumatic motor and equipped with relatively low-cost potentiometer-based position measurement system. Based on the nonlinear model of the overall pendulum system, which also includes notable friction effects, a linearized model is derived. The linearized model is used as a basis for the design of state feedback controller based on LQ and LQG optimization procedures. The linear state feedback controllers are augmented by a compensator of nonlinear friction effects whose design is based on the results of experimental identification of an appropriate static friction model. The proposed pendulum controller structures have been verified by means of computer simulations and experimentally on the experimental setup of a pneumatically actuated inverted pendulum.\"],\n",
    "[169,0,0,\"We report the creation of collagen films having a cholesteric banding structure with an orientation that can be systematically controlled. The action of hydrodynamic flow and rapid desiccation was used to influence the orientation of collagen fibrils, producing a film with a twisted plywood architecture. Adult human fibroblasts cultured on these substrates orient in the direction of the flow deposition, and filopodia are extended onto individual bands. Atomic force microscopy reveals the assembly of 30 nm collagen fibrils into the uniform cholesteric collagen films with a periodic surface relief. The generation of collagen with a reticular, 'basket-weave' morphology when using lower concentrations is also discussed.\"],\n",
    "[170,0,0,\"In this paper we present a new model for invariant object categorization and recognition. It is based on explicit multi-scale features: lines, edges and keypoints are extracted from responses of simple, complex and end-stopped cells in cortical area V1, and keypoints are used to construct saliency maps for Focus-of-Attention. The model is a functional but dichotomous one, because keypoints are employed to model the 'where' data stream, with dynamic routing of features from V1 to higher areas to obtain translation, rotation and size invariance, whereas lines and edges are employed in the 'what' stream for object categorization and recognition. Furthermore, both the 'where' and 'what' pathways are dynamic in that information at coarse scales is employed first, after which information at progressively finer scales is added in order to refine the processes, i.e., both the dynamic feature routing and the categorization level. The construction of group and object templates, which are thought to be available in the prefrontal cortex with 'what' and 'where' components in PF46d and PF46v, is also illustrated. The model was tested in the framework of an integrated and biologically plausible architecture.\"],\n",
    "[171,9,1,\"This paper examines the cognitive architecture of human action, showing how it is organized over several levels and how it is built up. Basic action concepts (BACs) are identified as major building blocks on a representation level. These BACs are cognitive tools for mastering the functional demands of movement tasks. Results from different lines of research showed that not only the structure formation of mental representations in long-term memory but also chunk formation in working memory are built up on BACs and relate systematically to movement structures. It is concluded that such movement representations might provide the basis for action implementation and action control in skilled voluntary movements in the form of cognitive reference structures. To simulate action implementation we discuss challenges and issues that arise when we try to replicate complex movement abilities in robots. Among the key issues to be addressed is the question how structured representations can arise during skill acquisition and how the underlying processes can be understood sufficiently succinctly to replicate them on robot platforms. Working towards this goal, we translate our findings in studies of motor control in humans into models that can guide the implementation of cognitive robot architectures. Focusing on the issue of manual action control, we illustrate some results in the context of grasping with a five-fingered anthropomorphic robot hand.\"],\n",
    "[172,0,0,\"The development of materials to support bone regeneration requires flexible fabrication technologies able to tailor chemistry and architecture for specific applications. In this work we describe the preparation of ceramic-based inks for robotic-assisted deposition (robocasting) using Pluronic F-127 solutions. This approach allows the preparation of pseudoplastic inks with solid contents ranging between 30 and 50 vol.%, enabling them to flow through a narrow printing nozzle while supporting the weight of the printed structure. Ink formulation does not require manipulation of the pH or the use of highly volatile organic components. Therefore, the approach can be used to prepare materials with a wide range of compositions, and here we use it to build hydroxyapatite (HA), beta-tricalcium phosphate (beta-TCP) and biphasic (HA/beta-TCP) structures. The flow of the inks is controlled by the Pluronic content and the particle size distribution of the ceramic powders. The use of wide size distributions favors flow through the narrow printing nozzles and we have been able to use printing nozzles as narrow as 100 microm in diameter, applying relatively low printing pressures. The microporosity of the printed lines increases with increasing Pluronic content and lower sintering temperatures. Microporosity can play a key role in determining the biological response to the materials, but it also affects the strength of the structure.\"],\n",
    "[173,5,0,\"How should robotic or prosthetic arms be programmed to move? Copying human smooth movements is popular in synthetic systems, but what does this really achieve? We cannot address these biomimetic issues without a deep understanding of why natural movements are so stereotyped. In this article, we distinguish between 'functional' and 'aesthetic' biomimetics. Functional biomimetics requires insight into the problem that nature has solved and recognition that a similar problem exists in the synthetic system. In aesthetic biomimetics, nature is copied for its own sake and no insight is needed. We examine the popular minimum jerk (MJ) model that has often been used to generate smooth human-like point-to-point movements in synthetic arms. The MJ model was originally justified as maximizing 'smoothness'; however, it is also the limiting optimal trajectory for a wide range of cost functions for brief movements, including the minimum variance (MV) model, where smoothness is a by-product of optimizing the speed-accuracy trade-off imposed by proportional noise (PN: signal-dependent noise with the standard deviation proportional to mean). PN is unlikely to be dominant in synthetic systems, and the control objectives of natural movements (speed and accuracy) would not be optimized in synthetic systems by human-like movements. Thus, employing MJ or MV controllers in robotic arms is just aesthetic biomimetics. For prosthetic arms, the goal is aesthetic by definition, but it is still crucial to recognize that MV trajectories and PN are deeply embedded in the human motor system. Thus, PN arises at the neural level, as a recruitment strategy of motor units and probably optimizes motor neuron noise. Human reaching is under continuous adaptive control. For prosthetic devices that do not have this natural architecture, natural plasticity would drive the system towards unnatural movements. We propose that a truly neuromorphic system with parallel force generators (muscle fibres) and noisy drivers (motor neurons) would permit plasticity to adapt the control of a prosthetic limb towards human-like movement.\"],\n",
    "[174,0,0,\"In this paper a new general purpose perceptual control architecture, based on nonlinear neural lattices, is presented and applied to solve robot navigation tasks. Insects show the ability to react to certain stimuli with simple reflexes, using direct sensory-motor pathways, which can be considered as basic behaviors, inherited and pre-wired. Relevant brain centres, known as Mushroom Bodies (MB) and Central Complex (CX) were recently identified in insects: though their functional details are not yet fully understood, it is known that they provide secondary pathways allowing the emergence of cognitive behaviors. These are gained through the coordination of the basic abilities to satisfy the insect's needs. Taking inspiration from this evidence, our architecture modulates, through a reinforcement learning, a set of competitive and concurrent basic behaviors in order to accomplish the task assigned through a reward function. The core of the architecture is constituted by the so-called Representation layer, used to create a concise picture of the current environment situation, fusing together different stimuli for the emergence of perceptual states. These perceptual states are steady state solutions of lattices of Reaction-Diffusion Cellular Nonlinear Networks (RD-CNN), designed to show Turing patterns. The exploitation of the dynamics of the multiple equilibria of the network is emphasized through the adaptive shaping of the basins of attraction for each emerged pattern. New experimental campaigns on standard robotic platforms are reported to demonstrate the potentiality and the effectiveness of the approach.\"],\n",
    "[175,0,0,\"Insects exhibit remarkable navigation capabilities that current control architectures are still far from successfully mimic and reproduce. In this chapter, we present the results of a study on conceptualizing insect/machine hybrid controllers for improving autonomy of exploratory vehicles. First, the different principally possible levels of interfacing between insect and machine are examined followed by a review of current approaches towards hybridity and enabling technologies. Based on the insights of this activity, we propose a double hybrid control architecture which hinges around the concept of 'insect-in-a-cockpit.' It integrates both biological/artificial (insect/robot) modules and deliberative/reactive behavior. The basic assumption is that 'low-level' tasks are managed by the robot, while the 'insect intelligence' is exploited whenever high-level problem solving and decision making is required. Both neural and natural interfacing have been considered to achieve robustness and redundancy of exchanged information.\"],\n",
    "[176,0,0,\"A brain-inspired computational system is presented that allows sequential selection and processing of objects from a visual scene. The system is comprised of three modules. The selective attention module is designed as a network of spiking neurons of the Hodgkin-Huxley type with star-like connections between the central unit and peripheral elements. The attention focus is represented by those peripheral neurons that generate spikes synchronously with the central neuron while the activity of other peripheral neurons is suppressed. Such dynamics corresponds to the partial synchronization mode. It is shown that peripheral neurons with higher firing rates are preferentially drawn into partial synchronization. We show that local excitatory connections facilitate synchronization, while local inhibitory connections help distinguishing between two groups of peripheral neurons with similar intrinsic frequencies. The module automatically scans a visual scene and sequentially selects regions of interest for detailed processing and object segmentation. The contour extraction module implements standard image processing algorithms for contour extraction. The module computes raw contours of objects accompanied by noise and some spurious inclusions. At the next stage, the object segmentation module designed as a network of phase oscillators is used for precise determination of object boundaries and noise suppression. This module has a star-like architecture of connections. The segmented object is represented by a group of peripheral oscillators working in the regime of partial synchronization with the central oscillator. The functioning of each module is illustrated by an example of processing of the visual scene taken from a visual stream of a robot camera.\"],\n",
    "[177,0,0,\"OBJECTIVE: There has been a growth of home healthcare technology in rural areas. However, a significant limitation has been the need for costly and repetitive training in order for patients to efficiently use their home telemedicine unit (HTU). This research describes the evaluation of an architecture for remote training of patients in a telemedicine environment. This work examines the viability of a remote training architecture called REmote Patient Education in a Telemedicine Environment (REPETE). REPETE was implemented and evaluated in the context of the IDEATel project, a large-scale telemedicine project, focusing on Medicare beneficiaries with diabetes in New York State. METHODS: A number of qualitative and quantitative evaluation tools were developed and used to study the effectiveness of the remote training sessions evaluating: (a) task complexity, (b) changes in patient performance and (c) the communication between trainer and patient. Specifically, the effectiveness of the training was evaluated using a measure of web skills competency, a user satisfaction survey, a cognitive task analysis and an interaction analysis. RESULTS: Patients not only reported that the training was beneficial, but also showed significant improvements in their ability to effectively perform tasks. Our qualitative evaluations scrutinizing the interaction between the trainer and patient showed that while there was a learning curve for both the patient and trainer when negotiating the shared workspace, the mutually visible pointer used in REPETE enhanced the computer-mediated instruction. CONCLUSIONS: REPETE is an effective remote training tool for older adults in the telemedicine environment. Patients demonstrated significant improvements in their ability to perform tasks on their home telemedicine unit.\"],\n",
    "[178,0,0,\"In this paper we present the humanoid robot LOLA, its mechatronic hardware design, simulation and real-time walking control. The goal of the LOLA-project is to build a machine capable of stable, autonomous, fast and human-like walking. LOLA is characterized by a redundant kinematic configuration with 7-DoF legs, an extremely lightweight design, joint actuators with brushless motors and an electronics architecture using decentralized joint control. Special emphasis was put on an improved mass distribution of the legs to achieve good dynamic performance. Trajectory generation and control aim at faster, more flexible and robust walking. Center of mass trajectories are calculated in real-time from footstep locations using quadratic programming and spline collocation methods. Stabilizing control uses hybrid position/force control in task space with an inner joint position control loop. Inertial stabilization is achieved by modifying the contact force trajectories.\"],\n",
    "[179,0,0,\"We report on the electromechanical actuation and switching performance of nanoconstructs involving doubly clamped, individual multiwalled carbon nanotubes. Batch-fabricated, three-state switches with low ON-state voltages (6.7 V average) are demonstrated. A nanoassembly architecture that permits individual probing of one device at a time without crosstalk from other nanotubes, which are originally assembled in parallel, is presented. Experimental investigations into device performance metrics such as hysteresis, repeatability and failure modes are presented. Furthermore, current-driven shell etching is demonstrated as a tool to tune the nanomechanical clamping configuration, stiffness, and actuation voltage of fabricated devices. Computational models, which take into account the nonlinearities induced by stress-stiffening of 1-D nanowires at large deformations, are presented. Apart from providing accurate estimates of device performance, these models provide new insights into the extension of stable travel range in electrostatically actuated nanowire-based constructs as compared to their microscale counterparts.\"],\n",
    "[180,0,0,\"Protein X-ray crystallography recently celebrated its 50th anniversary. The structures of myoglobin and hemoglobin determined by Kendrew and Perutz provided the first glimpses into the complex protein architecture and chemistry. Since then, the field of structural molecular biology has experienced extraordinary progress and now more than 55000 protein structures have been deposited into the Protein Data Bank. In the past decade many advances in macromolecular crystallography have been driven by world-wide structural genomics efforts. This was made possible because of third-generation synchrotron sources, structure phasing approaches using anomalous signal, and cryo-crystallography. Complementary progress in molecular biology, proteomics, hardware and software for crystallographic data collection, structure determination and refinement, computer science, databases, robotics and automation improved and accelerated many processes. These advancements provide the robust foundation for structural molecular biology and assure strong contribution to science in the future. In this report we focus mainly on reviewing structural genomics high-throughput X-ray crystallography technologies and their impact.\"],\n",
    "[181,0,0,\"Quantification of shape fidelity of complex geometries for tissue-engineered constructs has not been thoroughly investigated. The objective of this study was to quantitatively describe geometric fidelities of various approaches to the fabrication of anatomically shaped meniscal constructs. Ovine menisci (n = 4) were imaged using magnetic resonance imaging (MRI) and microcomputed tomography (microCT). Acrylonitrile butadiene styrene plastic molds were designed from each imaging modality and three-dimensional printed on a Stratasys FDM 3000. Silastic impression molds were fabricated directly from ovine menisci. These molds were used to generate shaped constructs using 2% alginate with 2% CaSO(4). Solid freeform fabrication was conducted on a custom open-architecture three-dimensional printing platform. Printed samples were made using 2% alginate with 0.75% CaSO(4). Hydrogel constructs were scanned via laser triangulation distance sensor. The point cloud images were analyzed to acquire computational measurements for key points of interest (e.g., height, width, and volume). Silastic molds were within + or - 10% error with respect to the native tissue for seven key measurements, microCT molds for six of seven, microCT prints for four of seven, MRI molds for five of seven, and MRI prints for four of seven. This work shows the ability to generate and quantify anatomically shaped meniscal constructs of high geometric fidelity and lends insight into the relative geometric fidelities of several tissue engineering techniques.\"],\n",
    "[182,0,0,\"For artificial intelligence research to progress beyond the highly specialized task-dependent implementations achievable today, researchers may need to incorporate aspects of biological behavior that have not traditionally been associated with intelligence. Affective processes such as emotions may be crucial to the generalized intelligence possessed by humans and animals. A number of robots and autonomous agents have been created that can emulate human emotions, but the majority of this research focuses on the social domain. In contrast, we have developed a hybrid reactive/deliberative architecture that incorporates artificial emotions to improve the general adaptive performance of a mobile robot for a navigation task. Emotions are active on multiple architectural levels, modulating the robot's decisions and actions to suit the context of its situation. Reactive emotions interact with the robot's control system, altering its parameters in response to appraisals from short-term sensor data. Deliberative emotions are learned associations that bias path planning in response to eliciting objects or events. Quantitative results are presented that demonstrate situations in which each artificial emotion can be beneficial to performance.\"],\n",
    "[183,0,0,\"This paper describes a control architecture and intent recognition approach for the real-time supervisory control of a powered lower limb prosthesis. The approach infers user intent to stand, sit, or walk, by recognizing patterns in prosthesis sensor data in real time, without the need for instrumentation of the sound-side leg. Specifically, the intent recognizer utilizes time-based features extracted from frames of prosthesis signals, which are subsequently reduced to a lower dimensionality (for computational efficiency). These data are initially used to train intent models, which classify the patterns as standing, sitting, or walking. The trained models are subsequently used to infer the user's intent in real time. In addition to describing the generalized control approach, this paper describes the implementation of this approach on a single unilateral transfemoral amputee subject and demonstrates via experiments the effectiveness of the approach. In the real-time supervisory control experiments, the intent recognizer identified all 90 activity-mode transitions, switching the underlying middle-level controllers without any perceivable delay by the user. The intent recognizer also identified six activity-mode transitions, which were not intended by the user. Due to the intentional overlapping functionality of the middle-level controllers, the incorrect classifications neither caused problems in functionality, nor were perceived by the user.\"],\n",
    "[184,0,0,\"Medical nanorobotics exploits nanometer-scale components and phenomena with robotics to provide new medical diagnostic and interventional tools. Here, the architecture and main specifications of a novel medical interventional platform based on nanorobotics and nanomedicine, and suited to target regions inaccessible to catheterization are described. The robotic platform uses magnetic resonance imaging (MRI) for feeding back information to a controller responsible for the real-time control and navigation along pre-planned paths in the blood vessels of untethered magnetic carriers, nanorobots, and/or magnetotactic bacteria (MTB) loaded with sensory or therapeutic agents acting like a wireless robotic arm, manipulator, or other extensions necessary to perform specific remote tasks. Unlike known magnetic targeting methods, the present platform allows us to reach locations deep in the human body while enhancing targeting efficacy using real-time navigational or trajectory control. The paper describes several versions of the platform upgraded through additional software and hardware modules allowing enhanced targeting efficacy and operations in very difficult locations such as tumoral lesions only accessible through complex microvasculature networks.\"],\n",
    "[185,0,0,\"We describe a cognitive architecture for creating more robust intelligent systems. Our approach is to enable hybrids of algorithms based on different computational formalisms to be executed. The architecture is motivated by some features of human cognitive architecture and the following beliefs: 1) Most existing computational methods often exhibit some of the characteristics desired of intelligent systems at the cost of other desired characteristics and 2) a system exhibiting robust intelligence can be designed by implementing hybrids of these computational methods. The main obstacle to this approach is that the various relevant computational methods are based on data structures and algorithms that are difficult to integrate into one system. We describe a new method of executing hybrids of algorithms using the focus of attention of multiple modules. The key to this approach is the following two principles: 1) Algorithms based on very different computational frameworks (e.g., logical reasoning, probabilistic inference, and case-based reasoning) can be implemented using the same set of five common functions and 2) each of these common functions can be executed using multiple data structures and algorithms. This approach has been embodied in the Polyscheme cognitive architecture. Systems based on Polyscheme in planning, spatial reasoning, robotics, and information retrieval illustrate that this approach to hybridizing algorithms enables qualitative and measurable quantitative advances in the abilities of intelligent systems.\"],\n",
    "[186,0,0,\"BACKGROUND: Recent research in orthopaedic surgery indicates that computer-assisted robotic systems improve the precision and accuracy of the surgery, which in turn leads to better long-term outcomes. Increasing demand for minimally invasive bone-cutting operations has been encouraging surgical robot developments in orthopaedics. An orthopaedic robotic system and an intelligent control architecture that will be used in bone-cutting operations were developed. METHODS: An orthopaedic surgical robotic system called OrthoRoby was developed. A computed-torque low-level control method was used for OrthoRoby to track a desired bone-cutting trajectory. Kinematic and dynamic analysis of OrthoRoby was derived for control purposes. An intelligent control architecture was designed that systematically combines a high-level controller with a computed-torque low-level controller to complete bone-cutting operations in a desired and safe manner. RESULTS: A series of experimental tests were conducted on a bone model to evaluate the performance of the intelligent control architecture. Experimental results demonstrated that the intelligent control architecture could monitor the progress and the safety of the cutting operation, such that necessary dynamic modifications could be made to complete the bone-cutting operation in a safe manner. CONCLUSIONS: The experiments performed on the OrthoRoby robotic system and its intelligent control architecture yielded promising results. Although minor problems still exist at the prototype stage, minor modifications of the OrthoRoby and intelligent control architecture would be a significant step towards the use of the OrthoRoby and its intelligent control architecture in a surgical operation.\"],\n",
    "[187,0,0,\"The need for greater capacity in automotive transportation (in the midst of constrained resources) and the convergence of key technologies from multiple domains may eventually produce the emergence of a 'swarm' concept of operations. The swarm, which is a collection of vehicles traveling at high speeds and in close proximity, will require technology and management techniques to ensure safe, efficient, and reliable vehicle interactions. We propose a shared autonomy control approach, in which the strengths of both human drivers and machines are employed in concert for this management. Building from a fuzzy logic control implementation, optimal architectures for shared autonomy addressing differing classes of drivers (represented by the driver's response time) are developed through a genetic-algorithm-based search for preferred fuzzy rules. Additionally, a form of 'phase transition' from a safe to an unsafe swarm architecture as the amount of sensor capability is varied uncovers key insights on the required technology to enable successful shared autonomy for swarm operations.\"],\n",
    "[188,0,0,\"This paper introduces some issues related to the development of robotics for endoluminal surgery from control point of view. Endoluminal surgery are incisionless procedures performed through natural orifices within the natural pathways. New devices are then required to achieve these new surgical procedures. Besides the development of new devices, control issues arise in both technological and theoretical aspects. The paper presents some of them and we propose a teleoperation architecture that has already been tested for needle insertion that could be used for teleoperated endoluminal surgery especially for instance for biopsies or anastomoses.\"],\n",
    "[189,0,0,\"A teleoperated surgical robotic system allows surgical procedures to be conducted across long distances while utilizing wired and wireless communication with a wide spectrum of performance that may affect the outcome. An open architecture portable surgical robotic system (Raven) was developed for both open and minimally invasive surgery. The system has been the subject of an intensive telesurgical experimental protocol aimed at exploring the boundaries of the system and surgeon performance during a series of field experiments in extreme environments (desert and underwater) teleportation between US, Europe, and Japan as well as lab experiments under synthetic fixed time delay. One standard task (block transfer emulating tissue manipulation) of the Fundamentals of Laparoscopic Surgery (FLS) training kit was used for the experimental protocol. Network characterization indicated a typical time delay in the range of 16-172 ms in field experiments. The results of the lab experiments showed that the completion time of the task as well as the length of the tool tip trajectory significantly increased (alpha< 0.02) as time delay increased in the range of 0-0.5 sec increased. For teleoperation with a time delay of 0.25s and 0.5s the task completion time was lengthened by a factor of 1.45 and 2.04 with respect to no time delay, whereas the length of the tools' trajectory was increased by a factor of 1.28 and 1.53 with respect to no time delay. There were no statistical differences between experienced surgeons and non-surgeons in the number of errors (block drooping) as well as the completion time and the tool tip path length at different time delays.\"],\n",
    "[190,0,0,\"Traditionally, modeling of neurobiological systems has involved development of computer-based simulations. As opposed to physical experimentation, simulations tend to over-simplify environmental conditions. Yet, in many cases such environmental conditions are critical to experiment outcome. In the case of animal behavior, simulation-only arenas can serve as a preliminary platform for model experimentation. Realistic physical environments are required for final evaluation of model correctness. In this paper we present our work with physical robots as testbed for animal behavior experimentation under realistic environmental conditions.\"],\n",
    "[191,0,0,\"The paper discusses the self-consciousness of a robot as based on higher order perceptions of the robot itself. In this sense, the first order perceptions of the robot are the immediate perceptions of the outer world of the robot, while higher order perceptions are the robot perceptions of its own inner world. The resulting architecture based on higher order perceptions has been implemented and tested in a project regarding a robotic touristic guide acting in the Botanical Garden of the University of Palermo.\"],\n",
    "[192,0,0,\"PURPOSE: This paper describes the development and evaluation of a parallel prototype robot for vitreoretinal surgery where physiological hand tremor limits performance. METHODS: The manipulator was specifically designed to meet requirements such as size, precision, and sterilization; this has six-degree-of-freedom parallel architecture and provides positioning accuracy with micrometer resolution within the eye. The manipulator is controlled by an operator with a 'master manipulator' consisting of multiple joints. RESULTS: Results of the in vitro experiments revealed that when compared to the manual procedure, a higher stability and accuracy of tool positioning could be achieved using the prototype robot. CONCLUSIONS: This microsurgical system that we have developed has superior operability as compared to traditional manual procedure and has sufficient potential to be used clinically for vitreoretinal surgery.\"],\n",
    "[193,0,0,\"Ultrasonic signals coming from rotary sonar sensors in a robot gives us several features about the environment. This enables us to locate and classify the objects in the scenario of the robot. Each object and reflector produces a series of peaks in the amplitude of the signal. The radial and angular position of the sonar sensor gives information about location and their amplitudes offer information about the nature of the surface. Early works showed that the amplitude can be modeled and used to classify objects with very good results at short distances-80% average success in classifying both walls and corners at distances less than 1.5 m. In this paper, a new set of geometric features derived from the amplitude analysis of the echo is presented. These features constitute a set of characteristics that can be used to improve the results of classification at distances from 1.5 m to 4 m. Also, a comparative study on classification algorithms widely used in pattern recognition techniques has been carried out for sensor distances ranging between 0.5 to 4 m, and with incidence angles ranging between 20 degrees to 70 degrees . Experimental results show an enhancement on the success in classification rates when these geometric features are considered.\"],\n",
    "[194,0,0,\"The long time wish of endowing agricultural vehicles with an increasing degree of autonomy is becoming a reality thanks to two crucial facts: the broad diffusion of global positioning satellite systems and the inexorable progress of computers and electronics. Agricultural vehicles are currently the only self-propelled ground machines commonly integrating commercial automatic navigation systems. Farm equipment manufacturers and satellite-based navigation system providers, in a joint effort, have pushed this technology to unprecedented heights; yet there are many unresolved issues and an unlimited potential still to uncover. The complexity inherent to intelligent vehicles is rooted in the selection and coordination of the optimum sensors, the computer reasoning techniques to process the acquired data, and the resulting control strategies for automatic actuators. The advantageous design of the network of onboard sensors is necessary for the future deployment of advanced agricultural vehicles. This article analyzes a variety of typical environments and situations encountered in agricultural fields, and proposes a sensor architecture especially adapted to cope with them. The strategy proposed groups sensors into four specific subsystems: global localization, feedback control and vehicle pose, non-visual monitoring, and local perception. The designed architecture responds to vital vehicle tasks classified within three layers devoted to safety, operative information, and automatic actuation. The success of this architecture, implemented and tested in various agricultural vehicles over the last decade, rests on its capacity to integrate redundancy and incorporate new technologies in a practical way.\"],\n",
    "[195,0,0,\"In this paper we deal with the problem of map building and localization of a mobile robot in an environment using the information provided by an omnidirectional vision sensor that is mounted on the robot. Our main objective consists of studying the feasibility of the techniques based in the global appearance of a set of omnidirectional images captured by this vision sensor to solve this problem. First, we study how to describe globally the visual information so that it represents correctly locations and the geometrical relationships between these locations. Then, we integrate this information using an approach based on a spring-mass-damper model, to create a topological map of the environment. Once the map is built, we propose the use of a Monte Carlo localization approach to estimate the most probable pose of the vision system and its trajectory within the map. We perform a comparison in terms of computational cost and error in localization. The experimental results we present have been obtained with real indoor omnidirectional images.\"],\n",
    "[196,9,1,\"By combining a number of simple transducer modules, an arbitrarily complex sensing system may be produced to accommodate a wide range of applications. This work outlines a novel software architecture and knowledge representation scheme that has been developed to support this type of flexible and reconfigurable modular sensing system. Template algorithms are used to embed intelligence within each module. As modules are added or removed, the composite sensor is able to automatically determine its overall geometry and assume an appropriate collective identity. A virtual machine-based middleware layer runs on top of a real-time operating system with a pre-emptive kernel, enabling platform-independent template algorithms to be written once and run on any module, irrespective of its underlying hardware architecture. Applications that may benefit from easily reconfigurable modular sensing systems include flexible inspection, mobile robotics, surveillance, and space exploration.\"],\n",
    "[197,0,0,\"In this article we explain the architecture for the environment and sensors that has been built for the European project URUS (Ubiquitous Networking Robotics in Urban Sites), a project whose objective is to develop an adaptable network robot architecture for cooperation between network robots and human beings and/or the environment in urban areas. The project goal is to deploy a team of robots in an urban area to give a set of services to a user community. This paper addresses the sensor architecture devised for URUS and the type of robots and sensors used, including environment sensors and sensors onboard the robots. Furthermore, we also explain how sensor fusion takes place to achieve urban outdoor execution of robotic services. Finally some results of the project related to the sensor network are highlighted.\"],\n",
    "[198,0,0,\"BACKGROUND: The combination of robotic tools with assistance technology determines a slightly explored area of applications and advantages for disability or elder people in their daily tasks. Autonomous motorized wheelchair navigation inside an environment, behaviour based control of orthopaedic arms or user's preference learning from a friendly interface are some examples of this new field. In this paper, a Simultaneous Localization and Mapping (SLAM) algorithm is implemented to allow the environmental learning by a mobile robot while its navigation is governed by electromyographic signals. The entire system is part autonomous and part user-decision dependent (semi-autonomous). The environmental learning executed by the SLAM algorithm and the low level behaviour-based reactions of the mobile robot are robotic autonomous tasks, whereas the mobile robot navigation inside an environment is commanded by a Muscle-Computer Interface (MCI). METHODS: In this paper, a sequential Extended Kalman Filter (EKF) feature-based SLAM algorithm is implemented. The features correspond to lines and corners -concave and convex- of the environment. From the SLAM architecture, a global metric map of the environment is derived. The electromyographic signals that command the robot's movements can be adapted to the patient's disabilities. For mobile robot navigation purposes, five commands were obtained from the MCI: turn to the left, turn to the right, stop, start and exit. A kinematic controller to control the mobile robot was implemented. A low level behavior strategy was also implemented to avoid robot's collisions with the environment and moving agents. RESULTS: The entire system was tested in a population of seven volunteers: three elder, two below-elbow amputees and two young normally limbed patients. The experiments were performed within a closed low dynamic environment. Subjects took an average time of 35 minutes to navigate the environment and to learn how to use the MCI. The SLAM results have shown a consistent reconstruction of the environment. The obtained map was stored inside the Muscle-Computer Interface. CONCLUSIONS: The integration of a highly demanding processing algorithm (SLAM) with a MCI and the communication between both in real time have shown to be consistent and successful. The metric map generated by the mobile robot would allow possible future autonomous navigation without direct control of the user, whose function could be relegated to choose robot destinations. Also, the mobile robot shares the same kinematic model of a motorized wheelchair. This advantage can be exploited for wheelchair autonomous navigation.\"],\n",
    "[199,0,0,\"BACKGROUND: Although robot therapy is progressively becoming an accepted method of treatment for stroke survivors, few studies have investigated how to adapt the robot/subject interaction forces in an automatic way. The paper is a feasibility study of a novel self-adaptive robot controller to be applied with continuous tracking movements. METHODS: The haptic robot Braccio di Ferro is used, in relation with a tracking task. The proposed control architecture is based on three main modules: 1) a force field generator that combines a non linear attractive field and a viscous field; 2) a performance evaluation module; 3) an adaptive controller. The first module operates in a continuous time fashion; the other two modules operate in an intermittent way and are triggered at the end of the current block of trials. The controller progressively decreases the gain of the force field, within a session, but operates in a non monotonic way between sessions: it remembers the minimum gain achieved in a session and propagates it to the next one, which starts with a block whose gain is greater than the previous one. The initial assistance gains are chosen according to a minimal assistance strategy. The scheme can also be applied with closed eyes in order to enhance the role of proprioception in learning and control. RESULTS: The preliminary results with a small group of patients (10 chronic hemiplegic subjects) show that the scheme is robust and promotes a statistically significant improvement in performance indicators as well as a recalibration of the visual and proprioceptive channels. The results confirm that the minimally assistive, self-adaptive strategy is well tolerated by severely impaired subjects and is beneficial also for less severe patients. CONCLUSIONS: The experiments provide detailed information about the stability and robustness of the adaptive controller of robot assistance that could be quite relevant for the design of future large scale controlled clinical trials. Moreover, the study suggests that including continuous movement in the repertoire of training is acceptable also by rather severely impaired subjects and confirms the stabilizing effect of alternating vision/no vision trials already found in previous studies.\"],\n",
    "[200,1,0,\"A comparison of behavior-based and planning approaches of robot control is presented in this paper. We focus on miniature mobile robotic agents with limited sensory abilities. Two reactive control mechanisms for an agent are considered-a radial basis function neural network trained by evolutionary algorithm and a traditional reinforcement learning algorithm over a finite agent state space. The control architecture based on localization and planning is compared to the former method.\"],\n",
    "[201,0,0,\"Computer and robot assistance in craniotomy/craniectomy procedures is intended to increase precision and efficiency of the removal of calvarial tumours, enabling the preoperative design and manufacturing of the corresponding implant. In the framework of the CRANIO project, an active robotic system was developed to automate the milling processes based on a predefined resection planning. This approach allows for a very efficient milling process, but lacks feedback of the intra-operative process to the surgeon. To better integrate the surgeon into the process, a new teleoperated synergistic architecture was designed. This enables the surgeon to realize changes during the procedure and use their human cognitive capabilities. The preoperative planning information is used as guidance for the user interacting with the system through a master-slave architecture. In this article, the CRANIO system is presented together with this new synergistic approach. Experiments have been performed to evaluate the accuracy of the system in active and synergistic modes for the bone milling procedure. The laboratory studies showed the general feasibility of the new concept for the selected medical procedure and determined the accuracy of the system. Although the integration of the surgeon partially reduces the efficiency of the milling process compared with a purely active (automatic) milling, it provides more feedback and flexibility to the user during the intra-operative procedure.\"],\n",
    "[202,0,0,\"This paper presents real-time MRI-based control of a ferromagnetic microcapsule for endovascular navigation. The concept was studied for future development of microdevices designed to perform minimally invasive interventions in remote sites accessible through the human cardiovascular system. A system software architecture is presented illustrating the different software modules to allow 3-D navigation of a microdevice in blood vessels, namely: (i) vessel path planner, (ii) magnetic gradient steering, (iii) tracking and (iv) closed-loop navigation control. First, the position recognition of the microrobot into the blood vessel is extracted using Frangi vesselness filtering from the pre-operation images (3-D MRI imaging). Then, a set of minimal trajectories is predefined, using path-planning algorithms, to guide the microrobot from the injection point to the tumor area through the anarchic vessel network. Based on the pre-computed path, a Generalized Predictive Controller (GPC) is proposed for robust time-multiplexed navigation along a two-dimensional (2D) path in presence of pulsative flow.\"],\n",
    "[203,0,0,\"The brain is the most complex system we know of. Despite the wealth of data available in neuroscience, our understanding of this system is still very limited. Here we argue that an essential component in our arsenal of methods to advance our understanding of the brain is the construction of artificial brain-like systems. In this way we can encompass the multi-level organisation of the brain and its role in the context of the complete embodied real-world and real-time perceiving and behaving system. Hence, on the one hand, we must be able to develop and validate theories of brains as closing the loop between perception and action, and on the other hand as interacting with the real world. Evidence is growing that one of the sources of the computational power of neuronal systems lies in the massive and specific connectivity, rather than the complexity of single elements. To meet these challenges-multiple levels of organisation, sophisticated connectivity, and the interaction of neuronal models with the real-world-we have developed a multi-level neuronal simulation environment, iqr. This framework deals with these requirements by directly transforming them into the core elements of the simulation environment itself. iqr provides a means to design complex neuronal models graphically, and to visualise and analyse their properties on-line. In iqr connectivity is defined in a flexible, yet compact way, and simulations run at a high speed, which allows the control of real-world devices-robots in the broader sense-in real-time. The architecture of iqr is modular, providing the possibility to write new neuron, and synapse types, and custom interfaces to other hardware systems. The code of iqr is publicly accessible under the GNU General Public License (GPL). iqr has been in use since 1996 and has been the core tool for a large number of studies ranging from detailed models of neuronal systems like the cerebral cortex, and the cerebellum, to robot based models of perception, cognition and action to large-scale real-world systems. In addition, iqr has been widely used over many years to introduce students to neuronal simulation and neuromorphic control. In this paper we outline the conceptual and methodological background of iqr and its design philosophy. Thereafter we present iqr's main features and computational properties. Finally, we describe a number of projects using iqr, singling out how iqr is used for building a 'synthetic insect'.\"],\n",
    "[204,0,0,\"We are witnessing tremendous advances in our understanding of the organization of life. Complete genomes are being deciphered with ever increasing speed and accuracy, thereby setting the stage for addressing the entire gene product repertoire of cells, towards understanding whole biological systems. Advances in bioinformatics and mass spectrometric techniques have revealed the multitude of interactions present in the proteome. Multiprotein complexes are emerging as a paramount cornerstone of biological activity, as many proteins appear to participate, stably or transiently, in large multisubunit assemblies. Analysis of the architecture of these assemblies and their manifold interactions is imperative for understanding their function at the molecular level. Structural genomics efforts have fostered the development of many technologies towards achieving the throughput required for studying system-wide single proteins and small interaction motifs at high resolution. The present shift in focus towards large multiprotein complexes, in particular in eukaryotes, now calls for a likewise concerted effort to develop and provide new technologies that are urgently required to produce in quality and quantity the plethora of multiprotein assemblies that form the complexome, and to routinely study their structure and function at the molecular level. Current efforts towards this objective are summarized and reviewed in this contribution.\"],\n",
    "[205,0,0,\"Tensegrity, or tensional integrity, is a property of a structure indicating a reliance on a balance between components that are either in pure compression or pure tension for stability. Tensegrity structures exhibit extremely high strength-to-weight ratios and great resilience, and are therefore widely used in engineering, robotics and architecture. Here, we report nanoscale, prestressed, three-dimensional tensegrity structures in which rigid bundles of DNA double helices resist compressive forces exerted by segments of single-stranded DNA that act as tension-bearing cables. Our DNA tensegrity structures can self-assemble against forces up to 14 pN, which is twice the stall force of powerful molecular motors such as kinesin or myosin. The forces generated by this molecular prestressing mechanism can be used to bend the DNA bundles or to actuate the entire structure through enzymatic cleavage at specific sites. In addition to being building blocks for nanostructures, tensile structural elements made of single-stranded DNA could be used to study molecular forces, cellular mechanotransduction and other fundamental biological processes.\"],\n",
    "[206,0,0,\"BACKGROUND: To reduce the production cost of bioethanol obtained from fermentation of the sugars provided by degradation of lignocellulosic biomass (i.e., second generation bioethanol), it is necessary to screen for new enzymes endowed with more efficient biomass degrading properties. This demands the set-up of high-throughput screening methods. Several methods have been devised all using microplates in the industrial SBS format. Although this size reduction and standardization has greatly improved the screening process, the published methods comprise one or more manual steps that seriously decrease throughput. Therefore, we worked to devise a screening method devoid of any manual steps. RESULTS: We describe a fully automated assay for measuring the amount of reducing sugars released by biomass-degrading enzymes from wheat-straw and spruce. The method comprises two independent and automated steps. The first step is the making of 'substrate plates'. It consists of filling 96-well microplates with slurry suspensions of micronized substrate which are then stored frozen until use. The second step is an enzymatic activity assay. After thawing, the substrate plates are supplemented by the robot with cell-wall degrading enzymes where necessary, and the whole process from addition of enzymes to quantification of released sugars is autonomously performed by the robot. We describe how critical parameters (amount of substrate, amount of enzyme, incubation duration and temperature) were selected to fit with our specific use. The ability of this automated small-scale assay to discriminate among different enzymatic activities was validated using a set of commercial enzymes. CONCLUSIONS: Using an automatic microplate sealer solved three main problems generally encountered during the set-up of methods for measuring the sugar-releasing activity of plant cell wall-degrading enzymes: throughput, automation, and evaporation losses. In its present set-up, the robot can autonomously process 120 triplicate wheat-straw samples per day. This throughput can be doubled if the incubation time is reduced from 24 h to 4 h (for initial rates measurements, for instance). This method can potentially be used with any insoluble substrate that is micronizable. A video illustrating the method can be seen at the following URL: http://www.youtube.com/watch?v=NFg6TxjuMWU.\"],\n",
    "[207,0,0,\"BACKGROUND: The origins of telemedicine date back to the early 1970s, and combined with the concept of minimally invasive surgery, the idea of surgical robotics was born in the late 1980s based on the principle of providing active telepresence to surgeons. Many research projects were initiated, creating a set of instruments for endoscopic telesurgery, while visionary surgeons built networks for telesurgical patient care, demonstrated transcontinental surgery, and performed procedures in weightlessness. Long-distance telesurgery became the testbed for new medical support concepts of space missions. METHODS: This article provides a complete review of the milestone experiments in the field, and describes a feasible concept to extend telemedicine beyond Earth orbit. With a possible foundation of an extraplanetary human outpost either on the Moon or on Mars, space agencies are carefully looking for effective and affordable solutions for life-support and medical care. The major challenges of surgery in weightlessness are also discussed. RESULTS: Teleoperated surgical robots have the potential to shape the future of extreme health care both in space and on Earth. Besides the apparent advantages, there are some serious challenges, primarily the difficulty of latency with teleoperation over long distances. Advanced virtualization and augmented-reality techniques should help human operators to adapt better to the special conditions. To meet safety standards and requirements in space, a three-layered architecture is recommended to provide the highest quality of telepresence technically achievable for provisional exploration missions. CONCLUSION: Surgical robotic technology is an emerging interdisciplinary field, with a great potential impact on many areas of health care, including telemedicine. With the proposed three-layered concept-relying only on currently available technology-effective support of long-distance telesurgery and human space missions are both feasible.\"],\n",
    "[208,0,0,\"This paper focuses on the use of the techniques based on linear matrix inequalities for robust H(infinity) position control synthesis of an electro-hydraulic servo system. A nonlinear dynamic model of the hydraulic cylindrical actuator with a proportional valve has been developed. For the purpose of the feedback control an uncertain linearized mathematical model of the system has been derived. The structured (parametric) perturbations in the electro-hydraulic coefficients are taken into account. H(infinity) controller extended with an integral action is proposed. To estimate internal states of the electro-hydraulic servo system an observer is designed. Developed control algorithms have been tested experimentally in the laboratory model of an electro-hydraulic servo system.\"],\n",
    "[209,0,0,\"BACKGROUND: The advances in technology make possible the incorporation of sensors and actuators in rollators, building safer robots and extending the use of walkers to a more diverse population. This paper presents a new method for the extraction of navigation related components from upper-body force interaction data in walker assisted gait. A filtering architecture is designed to cancel: (i) the high-frequency noise caused by vibrations on the walker's structure due to irregularities on the terrain or walker's wheels and (ii) the cadence related force components caused by user's trunk oscillations during gait. As a result, a third component related to user's navigation commands is distinguished. RESULTS: For the cancelation of high-frequency noise, a Benedict-Bordner g-h filter was designed presenting very low values for Kinematic Tracking Error ((2.035 +/- 0.358).10(-2) kgf) and delay ((1.897 +/- 0.3697).10(1)ms). A Fourier Linear Combiner filtering architecture was implemented for the adaptive attenuation of about 80% of the cadence related components' energy from force data. This was done without compromising the information contained in the frequencies close to such notch filters. CONCLUSIONS: The presented methodology offers an effective cancelation of the undesired components from force data, allowing the system to extract in real-time voluntary user's navigation commands. Based on this real-time identification of voluntary user's commands, a classical approach to the control architecture of the robotic walker is being developed, in order to obtain stable and safe user assisted locomotion.\"],\n",
    "[210,0,0,\"The robot and sensors integration for computer-assisted surgery and therapy (ROBOCAST) project (FP7-ICT-2007-215190) is co-funded by the European Union within the Seventh Framework Programme in the field of information and communication technologies. The ROBOCAST project focuses on robot- and artificial-intelligence-assisted keyhole neurosurgery (tumour biopsy and local drug delivery along straight or turning paths). The goal of this project is to assist surgeons with a robotic system controlled by an intelligent high-level controller (HLC) able to gather and integrate information from the surgeon, from diagnostic images, and from an array of on-field sensors. The HLC integrates pre-operative and intra-operative diagnostics data and measurements, intelligence augmentation, multiple-robot dexterity, and multiple sensory inputs in a closed-loop cooperating scheme including a smart interface for improved haptic immersion and integration. This paper, after the overall architecture description, focuses on the intelligent trajectory planner based on risk estimation and human criticism. The current status of development is reported, and first tests on the planner are shown by using a real image stack and risk descriptor phantom. The advantages of using a fuzzy risk description are given by the possibility of upgrading the knowledge on-field without the intervention of a knowledge engineer.\"],\n",
    "[211,0,0,\"BACKGROUND: Current robotic orientation surgical devices used to be large, in order to cover the needed workspace and to be rigid enough to resist the forces that occur during surgery. The disadvantages of the large size of the devices are the ergonomics, collisions and interference with the surgeons. This paper presents the first steps that have been carried out on the development of a small spherical wrist for laparoscopic applications. METHODS: Screw theory for kinematic analysis and the design of parallel robots have been used for choosing the kinematic architecture of the first prototype of the laparoscopic wrist. The kinematic equations of the platform are described and the Jacobian matrix calculated. RESULTS: The kinematics of this device is a 3UPS-1S parallel architecture. The work presented here shows the concept of the device, its design, that it was made under intrinsic safety criteria, its kinematic analysis and the first results and images of the built prototype. The kinematic analysis is made using screw theory and it is used to verify the optimization of the design. CONCLUSIONS: A new design for a smart and small spherical wrist is developed. Ergonomics for the surgical team is a design criterion that should be introduced to the design process for an operating-room robotic tool. Parallel robots architecture can contribute to new devices that fit this criterion.\"],\n",
    "[212,0,0,\"We describe a humanoid robot platform--the iCub--which was designed to support collaborative research in cognitive development through autonomous exploration and social interaction. The motivation for this effort is the conviction that significantly greater impact can be leveraged by adopting an open systems policy for software and hardware development. This creates the need for a robust humanoid robot that offers rich perceptuo-motor capabilities with many degrees of freedom, a cognitive capacity for learning and development, a software architecture that encourages reuse & easy integration, and a support infrastructure that fosters collaboration and sharing of resources. The iCub satisfies all of these needs in the guise of an open-system platform which is freely available and which has attracted a growing community of users and developers. To date, twenty iCubs each comprising approximately 5000 mechanical and electrical parts have been delivered to several research labs in Europe and to one in the USA.\"],\n",
    "[213,1,0,\"In this paper a bio-inspired control architecture for a robotic hand is presented. It relies on the same mechanisms of learning inverse internal models studied in humans. The control is capable of developing an internal representation of the hand interacting with the environment and updating it by means of the interaction forces that arise during contact. The learning paradigm exploits LWPR networks, which allow efficient incremental online learning through the use of spatially localized linear regression models. Additionally this paradigm limits negative interference when learning multiple tasks. The architecture is validated on a simulated finger of the DLR-HIT-Hand II performing closing movements in presence of two different viscous force fields, perturbing its motion.\"],\n",
    "[214,0,0,\"Anticipation of sensory consequences of actions is critical for the predictive control of movement that explains most of our sensory-motor behaviors. Plenty of neuroscientific studies in humans suggest evidence of anticipatory mechanisms based on internal models. Several robotic implementations of predictive behaviors have been inspired on those biological mechanisms in order to achieve adaptive agents. This paper provides an overview of such neuroscientific and robotic evidences; a high-level architecture of sensory-motor coordination based on anticipatory visual perception and internal models is then introduced; and finally, the paper concludes by discussing the relevance of the proposed architecture within the context of current research in humanoid robotics.\"],\n",
    "[215,0,0,\"A disposable endoscopic platform with actuation motors inside the body of the endoscope is presented. This platform can enable new medical devices for diagnosis and for minimally invasive surgeries. This paper addresses mechanical and safety issues with existing endoscope technologies by incorporating disposability, safety modules, and lower cable forces. In order to produce path-independent cable forces, motors are incorporated in the body of the endoscope near the bending tip. Results for tip forces are shown accompanied by an analytical model describing the scaling laws for this type of robotic architecture. The system under development will provide a platform for research into haptic control and perceptual feedback.\"],\n",
    "[216,0,0,\"In this paper we discuss about the integration of Ambient-Assisted Living (AAL) with virtual worlds. The integration of sensors from the AAL environment (e.g. vital signs, motion sensors) in the Virtual World can enhance the provision of in-world eHealth services, such as tele-rehabilitation, and taking advance of the social nature of virtual worlds. An implementation of a virtual world integrated in an AAL environment for tele-rehabilitation is described in this paper. At this time, all of the system's modules have been developed and we are currently integrating them in a fully functional version. The system will be tested with real users during 2010 in the Sport Medical Unit of The University of Seville. This paper describes the architecture and functionalities of the system.\"],\n",
    "[217,9,1,\"This paper presents a Spiking Neural Network (SNN) architecture for mobile robot navigation. The SNN contains 4 layers where dynamic synapses route information to the appropriate neurons in each layer and the neurons are modeled using the Leaky Integrate and Fire (LIF) model. The SNN learns by self-organizing its connectivity as new environmental conditions are experienced and consequently knowledge about its environment is stored in the connectivity. Also a novel feature of the proposed SNN architecture is that it uses working memory, where present and previous sensor states are stored. Results are presented for a wall following application.\"],\n",
    "[218,0,0,\"Instead of using low-level neurophysiology mimicking and exploratory programming methods commonly used in the machine consciousness field, the hierarchical operational architectonics (OA) framework of brain and mind functioning proposes an alternative conceptual-theoretical framework as a new direction in the area of model-driven machine (robot) consciousness engineering. The unified brain-mind theoretical OA model explicitly captures (though in an informal way) the basic essence of brain functional architecture, which indeed constitutes a theory of consciousness. The OA describes the neurophysiological basis of the phenomenal level of brain organization. In this context the problem of producing man-made 'machine' consciousness and 'artificial' thought is a matter of duplicating all levels of the operational architectonics hierarchy (with its inherent rules and mechanisms) found in the brain electromagnetic field. We hope that the conceptual-theoretical framework described in this paper will stimulate the interest of mathematicians and/or computer scientists to abstract and formalize principles of hierarchy of brain operations which are the building blocks for phenomenal consciousness and thought.\"],\n",
    "[219,0,0,\"In this paper we present a model for action preparation and decision making in cooperative tasks that is inspired by recent experimental findings about the neuro-cognitive mechanisms supporting joint action in humans. It implements the coordination of actions and goals among the partners as a dynamic process that integrates contextual cues, shared task knowledge and predicted outcome of others' motor behavior. The control architecture is formalized by a system of coupled dynamic neural fields representing a distributed network of local but connected neural populations. Different pools of neurons encode task-relevant information about action means, task goals and context in the form of self-sustained activation patterns. These patterns are triggered by input from connected populations and evolve continuously in time under the influence of recurrent interactions. The dynamic model of joint action is evaluated in a task in which a robot and a human jointly construct a toy object. We show that the highly context sensitive mapping from action observation onto appropriate complementary actions allows coping with dynamically changing joint action situations.\"],\n",
    "[220,0,0,\"This paper deals with the locomotion control of quadruped robots inspired by the biological concept of central pattern generator (CPG). A control architecture is proposed with a 3-D workspace trajectory generator and a motion engine. The workspace trajectory generator generates adaptive workspace trajectories based on CPGs, and the motion engine realizes joint motion imputes. The proposed architecture is able to generate adaptive workspace trajectories online by tuning the parameters of the CPG network to adapt to various terrains. With feedback information, a quadruped robot can walk through various terrains with adaptive joint control signals. A quadruped platform AIBO is used to validate the proposed locomotion control system. The experimental results confirm the effectiveness of the proposed control architecture. A comparison by experiments shows the superiority of the proposed method against the traditional CPG-joint-space control method.\"],\n",
    "[221,5,0,\"The current study investigated the functional connectivity of the primary sensory system with resting state fMRI and applied such knowledge into the design of the neural architecture of autonomous humanoid robots. Correlation and Granger causality analyses were utilized to reveal the functional connectivity patterns. Dissociation was within the primary sensory system, in that the olfactory cortex and the somatosensory cortex were strongly connected to the amygdala whereas the visual cortex and the auditory cortex were strongly connected with the frontal cortex. The posterior cingulate cortex (PCC) and the anterior cingulate cortex (ACC) were found to maintain constant communication with the primary sensory system, the frontal cortex, and the amygdala. Such neural architecture inspired the design of dissociated emergent-response system and fine-processing system in autonomous humanoid robots, with separate processing units and another consolidation center to coordinate the two systems. Such design can help autonomous robots to detect and respond quickly to danger, so as to maintain their sustainability and independence.\"],\n",
    "[222,0,0,\"BACKGROUND: Image-guided robots are manipulators that operate based on medical images. Perhaps the most common class of image-guided robots are robots for needle interventions. Typically, these robots actively position and/or orient a needle guide, but needle insertion is still done by the physician. While this arrangement may have safety advantages and keep the physician in control of needle insertion, actuated needle drivers can incorporate other useful features. METHODS: We first present a new needle driver that can actively insert and rotate a needle. With this device we investigate the use of needle rotation in controlled in-vitro experiments performed with a specially developed revolving needle driver. RESULTS: These experiments show that needle rotation can improve targeting and may reduce errors by as much as 70%. CONCLUSION: The new needle driver provides a unique kinematic architecture that enables insertion with a compact mechanism. Perhaps the most interesting conclusion of the study is that lesions of soft tissue organs may not be perfectly targeted with a needle without using special techniques, either manually or with a robotic device. The results of this study show that needle rotation may be an effective method of reducing targeting errors.\"],\n",
    "[223,0,0,\"OBJECTIVE: Two studies were conducted to obtain an understanding of the types of items seniors keep in their nightstands and to understand how users feel about the possibility of 'smart' furniture. BACKGROUND: To enable aging in place and universal design, it is vital to understand the needs of a broad range of aging individuals, especially since there is little research on nightstand usage and design. METHODS: Study 1 allowed for the development of a structured inventory of nightstand use today in assisted living and rehabilitation facilities. Study 1 led to Study 2, demonstrating the need to conceptualize new ideas for smart nightstands. Feedback was obtained from intergenerational participants who could discuss their needs and preferences for a smart nightstand. RESULTS: In Study 1, more than 150 items were recorded and categorized into 25 different groups. The authors found that participants utilized the top portion of their nightstand as opposed to the lower sections; most items were found on top of the nightstand or in the top drawer. In Study 2, the authors found that the vast majority of participants are willing to consider the use of a smart nightstand. Participants discussed key functions and design preferences, which included carefully designed storage, the ability to move the nightstand up and down, contemporary design, and interaction through voice activation. CONCLUSION: Existing nightstands do not meet the needs of current users. This research provides greater understanding of the existing limitations associated with nightstands. Study 2 confirmed that user-centered design and the use of technology can be used to enhance daily living. Smart furniture may play a role in promoting the health and independence of diverse user groups.\"],\n",
    "[224,1,0,\"Emotions have long been seen as counteracting rational thought, but over the last decades, they have been viewed as adaptive processes to optimize human (but also animal) behaviour. In particular, positive affect appears to be a functional aspect of emotions closely related to that. We argue that positive affect as understood in Kuhl's PSI model of the human cognitive architecture appears to have an interpretation in state-of-the-art hybrid robot control architectures, which might help tackle some open questions in the field.\"],\n",
    "[225,9,1,\"Models are among the most essential tools in robotics, such as kinematics and dynamics models of the robot's own body and controllable external objects. It is widely believed that intelligent mammals also rely on internal models in order to generate their actions. However, while classical robotics relies on manually generated models that are based on human insights into physics, future autonomous, cognitive robots need to be able to automatically generate models that are based on information which is extracted from the data streams accessible to the robot. In this paper, we survey the progress in model learning with a strong focus on robot control on a kinematic as well as dynamical level. Here, a model describes essential information about the behavior of the environment and the influence of an agent on this environment. In the context of model-based learning control, we view the model from three different perspectives. First, we need to study the different possible model learning architectures for robotics. Second, we discuss what kind of problems these architecture and the domain of robotics imply for the applicable learning methods. From this discussion, we deduce future directions of real-time learning algorithms. Third, we show where these scenarios have been used successfully in several case studies.\"],\n",
    "[226,0,0,\"This review presents the state of the art of magnetic resonance imaging (MRI)-guided nanorobotic systems that can perform diagnostic, curative, and reconstructive treatments in the human body at the cellular and subcellular levels in a controllable manner. The concept of an MRI-guided nanorobotic system is based on the use of an MRI scanner to induce the required external driving forces to propel magnetic nanocapsules to a specific target. It is an active targeting mechanism that provides simultaneous propulsion and imaging capabilities, which allow the implementation of real-time feedback control of the targeting process. The architecture of the system comprises four main modules: (a) the nanocapsules, (b) the MRI propulsion module, (c) the MRI tracking module (for image processing), and (d) the controller module. A key concept is the nanocapsule technology, which is based on carriers such as liposomes, polymer micelles, gold nanoparticles, quantum dots, metallic nanoshells, and carbon nanotubes. Descriptions of the significant challenges faced by the MRI-guided nanorobotic system are presented, and promising solutions proposed by the involved research community are discussed. Emphasis is placed on reviewing the limitations imposed by the scaling effects that dominate within the blood vessels and also on reviewing the control algorithms and computational tools that have been developed for real-time propulsion and tracking of the nanocapsules.\"],\n",
    "[227,0,0,\"This paper presents how a simple cerebellumlike architecture can infer corrective models in the framework of a control task when manipulating objects that significantly affect the dynamics model of the system. The main motivation of this paper is to evaluate a simplified bio-mimetic approach in the framework of a manipulation task. More concretely, the paper focuses on how the model inference process takes place within a feedforward control loop based on the cerebellar structure and on how these internal models are built up by means of biologically plausible synaptic adaptation mechanisms. This kind of investigation may provide clues on how biology achieves accurate control of non-stiff-joint robot with low-power actuators which involve controlling systems with high inertial components. This paper studies how a basic temporal-correlation kernel including long-term depression (LTD) and a constant long-term potentiation (LTP) at parallel fiber-Purkinje cell synapses can effectively infer corrective models. We evaluate how this spike-timing-dependent plasticity correlates sensorimotor activity arriving through the parallel fibers with teaching signals (dependent on error estimates) arriving through the climbing fibers from the inferior olive. This paper addresses the study of how these LTD and LTP components need to be well balanced with each other to achieve accurate learning. This is of interest to evaluate the relevant role of homeostatic mechanisms in biological systems where adaptation occurs in a distributed manner. Furthermore, we illustrate how the temporal-correlation kernel can also work in the presence of transmission delays in sensorimotor pathways. We use a cerebellumlike spiking neural network which stores the corrective models as well-structured weight patterns distributed among the parallel fibers to Purkinje cell connections.\"],\n",
    "[228,5,0,\"BACKGROUND: Patients with pronounced spasticity reveal difficulties in hand opening during the approaching grasping phase. The general description and assessment procedures of reach-to-grasp movement for rehabilitation purposes is still not established. There is a necessity to develop a universal methodology to describe the approaching phase in grasping which would allow clinical evaluation of movement pathologies. METHODS: In the paper, the evaluation of approaching trajectories assessed during grasping by healthy subjects is described. The experiment, undertaken by 7 healthy volunteers, consisted of grasping three different stationary objects positioned in various poses by a robot. 3D recordings of the hand and fingertip trajectories were performed. The kinematic trajectories of the hand and finger markers were analysed in order to evaluate the reach-to-grasp movement. FINDINGS: The results of the kinematic analysis suggest that the reach-to-grasp movement of a healthy subject can be divided into 3 dominant phases (hand acceleration, hand deceleration, and final closure of the fingers). INTERPRETATION: The presented evaluation method can provide relevant information on the modalities the hand preshapes and approaches toward the object in order to obtain a stable grasp. The potential use of the approach for rehabilitation purposes is discussed.\"],\n",
    "[229,0,0,\"Naming is a powerful cognitive tool that facilitates categorization by forming an association between words and their referents. There is evidence in child development literature that strong links exist between early word-learning and conceptual development. A growing view is also emerging that language is a cultural product created and acquired through social interactions. Inspired by these studies, this paper presents a novel learning architecture for category formation and vocabulary acquisition in robots through active interaction with humans. This architecture is open-ended and is capable of acquiring new categories and category names incrementally. The process can be compared to language grounding in children at single-word stage. The robot is embodied with visual and auditory sensors for world perception. A human instructor uses speech to teach the robot the names of the objects present in a visually shared environment. The robot uses its perceptual input to ground these spoken words and dynamically form/organize category descriptions in order to achieve better categorization. To evaluate the learning system at word-learning and category formation tasks, two experiments were conducted using a simple language game involving naming and corrective feedback actions from the human user. The obtained results are presented and discussed in detail.\"],\n",
    "[230,0,0,\"Automated data acquisition expedites structural studies by electron microscopy and it allows to collect data sets of unprecedented size and consistent quality. In electron tomography it greatly facilitates the systematic exploration of large cellular landscapes and in single particle analysis it allows to generate data sets for an exhaustive classification of coexisting molecular states. Here we describe a novel software philosophy and architecture that can be used for a great variety of automated data acquisition scenarios. Based on our original software package TOM, the new TOM(2) package has been designed in an object-oriented way. The whole program can be seen as a collection of self-sufficient modules with defined relationships acting in a concerted manner. It subdivides data acquisition into a set of hierarchical tasks, bonding data structure and the operations to be performed tightly together. To demonstrate its capacity for high-throughput data acquisition it has been used in conjunction with instrumentation combining the latest technological achievements in electron optics, cryogenics and robotics. Its performance is demonstrated with a single particle analysis case study and with a batch tomography application.\"],\n",
    "[231,0,0,\"By adding an additional degree of freedom from multichannel flow, the parallel microfluidic cytometer (PMC) combines some of the best features of fluorescence-activated flow cytometry (FCM) and microscope-based high-content screening (HCS). The PMC (i) lends itself to fast processing of large numbers of samples, (ii) adds a 1D imaging capability for intracellular localization assays (HCS), (iii) has a high rare-cell sensitivity, and (iv) has an unusual capability for time-synchronized sampling. An inability to practically handle large sample numbers has restricted applications of conventional flow cytometers and microscopes in combinatorial cell assays, network biology, and drug discovery. The PMC promises to relieve a bottleneck in these previously constrained applications. The PMC may also be a powerful tool for finding rare primary cells in the clinic. The multichannel architecture of current PMC prototypes allows 384 unique samples for a cell-based screen to be read out in approximately 6-10 min, about 30 times the speed of most current FCM systems. In 1D intracellular imaging, the PMC can obtain protein localization using HCS marker strategies at many times for the sample throughput of charge-coupled device (CCD)-based microscopes or CCD-based single-channel flow cytometers. The PMC also permits the signal integration time to be varied over a larger range than is practical in conventional flow cytometers. The signal-to-noise advantages are useful, for example, in counting rare positive cells in the most difficult early stages of genome-wide screening. We review the status of parallel microfluidic cytometry and discuss some of the directions the new technology may take.\"],\n",
    "[232,0,0,\"It is widely assumed that the cerebellum is one of the main nervous centers involved in correcting and refining planned movement and accounting for disturbances occurring during movement, for instance, due to the manipulation of objects which affect the kinematics and dynamics of the robot-arm plant model. In this brief, we evaluate a way in which a cerebellar-like structure can store a model in the granular and molecular layers. Furthermore, we study how its microstructure and input representations (context labels and sensorimotor signals) can efficiently support model abstraction toward delivering accurate corrective torque values for increasing precision during different-object manipulation. We also describe how the explicit (object-related input labels) and implicit state input representations (sensorimotor signals) complement each other to better handle different models and allow interpolation between two already stored models. This facilitates accurate corrections during manipulations of new objects taking advantage of already stored models.\"],\n",
    "[233,0,0,\"We present a model which stems from a well-established model of object recognition, HMAX, and show how this feedforward system can include feedback, using a recently proposed architecture which reconciles biased competition and predictive coding approaches. Simulation results show successful feedforward object recognition, including cases of occluded and illusory images. Recognition is both position and size invariant. The model also provides a functional interpretation of the role of feedback connectivity in accounting for several observed effects such as enhancement, suppression and refinement of activity in lower areas. The model can qualitatively replicate responses in early visual cortex to occluded and illusory contours; and fMRI data showing that high-level object recognition reduces activity in lower areas. A Gestalt-like mechanism based on collinearity, co-orientation and good continuation principles is proposed to explain illusory contour formation which allows the system to adapt a single high-level object prototype to illusory Kanizsa figures of different sizes, shapes and positions. Overall the model provides a biophysiologically plausible interpretation, supported by current experimental evidence, of the interaction between top-down global feedback and bottom-up local evidence in the context of hierarchical object perception.\"],\n",
    "[234,0,0,\"This study introduces the concept design and analysis of a robotic system for the assistance and rehabilitation of disabled people. Based on the statistical data of the most common types of disabilities in Spain and other industrialized countries, the different tasks that the device must be able to perform have been determined. In this study, different robots for rehabilitation and assistance previously introduced have been reviewed. This survey is focused on those robots that assist with gait, balance and standing up. The structure of the ROAD robot presents various advantages over these robots, we discuss some of them. The performance of the proposed architecture is analyzed when it performs the sit to stand activity.\"],\n",
    "[235,0,0,\"As described in Part I, the Lapabot was developed considering telesurgery from the initial design stage. The robot configuration is based on the master-slave structure in which the operator can be separated spatially from the patient. The distributed control architecture communicating through high-speed network enables remote control of surgical robot manipulators. In this work, we added network communication modules using user datagram protocol/internet protocol for implementation of the telesurgical system. For a stable network environment, a dedicated research network was adopted. To characterize the network environment, a data packet sender and a repeater whose packet length and packet structure are similar to those of the real data packet were developed. The developed system was evaluated through in-vitro and in-vivo experiments. With the developed system, we have successfully performed remote control of the Lapabot. The roundtrip time delay for the control signal ranged from 1.4 to 4.1 ms. The total time delay for the operator including image signal acquisition and transmission delays was under 333 ms. It did not impede surgical procedures. Initial evaluation results demonstrate the feasibility of the developed telesurgical system.\"],\n",
    "[236,0,0,\"Advances in scaffold design and fabrication technology have brought the tissue engineering field stepping into a new era. Conventional techniques used to develop scaffolds inherit limitations, such as lack of control over the pore morphology and architecture as well as reproducibility. Rapid prototyping (RP) technology, a layer-by-layer additive approach offers a unique opportunity to build complex 3D architectures overcoming those limitations that could ultimately be tailored to cater for patient-specific applications. Using RP methods, researchers have been able to customize scaffolds to mimic the biomechanical properties (in terms of structural integrity, strength, and microenvironment) of the organ or tissue to be repaired/replaced quite closely. This article provides intensive description on various extrusion based scaffold fabrication techniques and review their potential utility for TE applications. The extrusion-based technique extrudes the molten polymer as a thin filament through a nozzle onto a platform layer-by-layer and thus building 3D scaffold. The technique allows full control over pore architecture and dimension in the x- and y- planes. However, the pore height in z-direction is predetermined by the extruding nozzle diameter rather than the technique itself. This review attempts to assess the current state and future prospects of this technology.\"],\n",
    "[237,0,0,\"This paper presents a novel teleoperation controller for a nonlinear master-slave robotic system with constant time delay in communication channel. The proposed controller enables the teleoperation system to compensate human and environmental disturbances, while achieving master and slave position coordination in both free motion and contact situation. The current work basically extends the passivity based architecture upon the earlier work of Lee and Spong (2006) [14] to improve position tracking and consequently transparency in the face of disturbances and environmental contacts. The proposed controller employs a PID controller in each side to overcome some limitations of a PD controller and guarantee an improved performance. Moreover, by using Fourier transform and Parseval's identity in the frequency domain, we demonstrate that this new PID controller preserves the passivity of the system. Simulation and semi-experimental results show that the PID controller tracking performance is superior to that of the PD controller tracking performance in slave/environmental contacts.\"],\n",
    "[238,0,0,\"When a humanoid robot moves in a dynamic environment, a simple process of planning and following a path may not guarantee competent performance for dynamic obstacle avoidance because the robot acquires limited information from the environment using a local vision sensor. Thus, it is essential to update its local map as frequently as possible to obtain more information through gaze control while walking. This paper proposes a fuzzy integral-based gaze control architecture incorporated with the modified-univector field-based navigation for humanoid robots. To determine the gaze direction, four criteria based on local map confidence, waypoint, self-localization, and obstacles, are defined along with their corresponding partial evaluation functions. Using the partial evaluation values and the degree of consideration for criteria, fuzzy integral is applied to each candidate gaze direction for global evaluation. For the effective dynamic obstacle avoidance, partial evaluation functions about self-localization error and surrounding obstacles are also used for generating virtual dynamic obstacle for the modified-univector field method which generates the path and velocity of robot toward the next waypoint. The proposed architecture is verified through the comparison with the conventional weighted sum-based approach with the simulations using a developed simulator for HanSaRam-IX (HSR-IX).\"],\n",
    "[239,0,0,\"This work proposes a hierarchical biologically-inspired architecture for learning sensor-based spatial representations of a robot environment in an unsupervised way. The first layer is comprised of a fixed randomly generated recurrent neural network, the reservoir, which projects the input into a high-dimensional, dynamic space. The second layer learns instantaneous slowly-varying signals from the reservoir states using Slow Feature Analysis (SFA), whereas the third layer learns a sparse coding on the SFA layer using Independent Component Analysis (ICA). While the SFA layer generates non-localized activations in space, the ICA layer presents high place selectivity, forming a localized spatial activation, characteristic of place cells found in the hippocampus area of the rodent's brain. We show that, using a limited number of noisy short-range distance sensors as input, the proposed system learns a spatial representation of the environment which can be used to predict the actual location of simulated and real robots, without the use of odometry. The results confirm that the reservoir layer is essential for learning spatial representations from low-dimensional input such as distance sensors. The main reason is that the reservoir state reflects the recent history of the input stream. Thus, this fading memory is essential for detecting locations, mainly when locations are ambiguous and characterized by similar sensor readings.\"],\n",
    "[240,0,0,\"We present a spatial system called Specialized Egocentrically Coordinated Spaces embedded in an embodied cognitive architecture (ACT-R Embodied). We show how the spatial system works by modeling two different developmental findings: gaze-following and Level 1 perspective taking. The gaze-following model is based on an experiment by Corkum and Moore (1998), whereas the Level 1 visual perspective-taking model is based on an experiment by Moll and Tomasello (2006). The models run on an embodied robotic system.\"],\n",
    "[241,0,0,\"This paper presents the rationale for the use of a component-based architecture for computer-assisted intervention (CAI) systems, including the ability to reuse components and to easily develop distributed systems. We introduce three additional capabilities, however, that we believe are especially important for research and development of CAI systems. The first is the ability to deploy components among different processes (as conventionally done) or within the same process (for optimal real-time performance), without requiring source-level modifications to the component. This is particularly relevant for real-time video processing, where the use of multiple processes could cause perceptible delays in the video stream. The second key feature is the ability to dynamically reconfigure the system. In a system composed of multiple processes on multiple computers, this allows one process to be restarted (e.g., after correcting a problem) and reconnected to the rest of the system, which is more convenient than restarting the entire distributed application and enables better fault recovery. The third key feature is the availability of run-time tools for data collection, interactive control, and introspection, and offline tools for data analysis and playback. The above features are provided by the open-source cisst software package, which forms the basis for the Surgical Assistant Workstation (SAW) framework. A complex computer-assisted intervention system for retinal microsurgery is presented as an example that relies on these features. This system integrates robotics, stereo microscopy, force sensing, and optical coherence tomography (OCT) imaging to transcend the current limitations of vitreoretinal surgery.\"],\n",
    "[242,1,0,\"This work evaluates the capability of a spiking cerebellar model embedded in different loop architectures (recurrent, forward, and forward&recurrent) to control a robotic arm (three degrees of freedom) using a biologically-inspired approach. The implemented spiking network relies on synaptic plasticity (long-term potentiation and long-term depression) to adapt and cope with perturbations in the manipulation scenario: changes in dynamics and kinematics of the simulated robot. Furthermore, the effect of several degrees of noise in the cerebellar input pathway (mossy fibers) was assessed depending on the employed control architecture. The implemented cerebellar model managed to adapt in the three control architectures to different dynamics and kinematics providing corrective actions for more accurate movements. According to the obtained results, coupling both control architectures (forward&recurrent) provides benefits of the two of them and leads to a higher robustness against noise.\"],\n",
    "[243,0,0,\"During a laparoscopic surgery, the endoscope can be manipulated by an assistant or a robot. Several teams have worked on the tracking of surgical instruments, based on methods ranging from the development of specific devices to image processing methods. We propose to exploit the instruments' insertion points, which are fixed on the patients abdominal cavity, as a geometric constraint for the localization of the instruments. A simple geometric model of a laparoscopic instrument is described, as well as a parametrization that exploits a spherical geometric grid, which offers attracting homogeneity and isotropy properties. The general architecture of our proposed approach is based on the probabilistic Condensation algorithm.\"],\n",
    "[244,0,0,\"Growing demand for a wide range of surgical procedures, coupled with a strong belief in the advantages--both to surgeons and patients--of minimally invasive robot-assisted surgery, have seen the Royal Wolverhampton Hospitals NHS Trust open a new twin operating theatre suite, equipped with the Midlands' first da Vinci surgical robot, at Wolverhampton's New Cross Hospital. The two theatres, together with accompanying 'preparation' and scrub facilities, and a separate five-bed recovery bay to serve several of the hospital's eight other existing main theatres, were completed to time and on budget recently by modular construction specialist, MTX Contracts, under a pound 2 million design and build contract, as HEJ editor Jonathan Baillie reports.\"],\n",
    "[245,0,0,\"The localization of persons in indoor environments is nowadays an open problem. There are partial solutions based on the deployment of a network of sensors (Local Positioning Systems or LPS). Other solutions only require the installation of an inertial sensor on the person's body (Pedestrian Dead-Reckoning or PDR). PDR solutions integrate the signals coming from an Inertial Measurement Unit (IMU), which usually contains 3 accelerometers and 3 gyroscopes. The main problem of PDR is the accumulation of positioning errors due to the drift caused by the noise in the sensors. This paper presents a PDR solution that incorporates a drift correction method based on detecting the access ramps usually found in buildings. The ramp correction method is implemented over a PDR framework that uses an Inertial Navigation algorithm (INS) and an IMU attached to the person's foot. Unlike other approaches that use external sensors to correct the drift error, we only use one IMU on the foot. To detect a ramp, the slope of the terrain on which the user is walking, and the change in height sensed when moving forward, are estimated from the IMU. After detection, the ramp is checked for association with one of the existing in a database. For each associated ramp, a position correction is fed into the Kalman Filter in order to refine the INS-PDR solution. Drift-free localization is achieved with positioning errors below 2 meters for 1,000-meter-long routes in a building with a few ramps.\"],\n",
    "[246,0,0,\"The control architecture is one of the most important part of agricultural robotics and other robotic systems. Furthermore its importance increases when the system involves a group of heterogeneous robots that should cooperate to achieve a global goal. A new control architecture is introduced in this paper for groups of robots in charge of doing maintenance tasks in agricultural environments. Some important features such as scalability, code reuse, hardware abstraction and data distribution have been considered in the design of the new architecture. Furthermore, coordination and cooperation among the different elements in the system is allowed in the proposed control system. By integrating a network oriented device server Player, Java Agent Development Framework (JADE) and High Level Architecture (HLA), the previous concepts have been considered in the new architecture presented in this paper. HLA can be considered the most important part because it not only allows the data distribution and implicit communication among the parts of the system but also allows to simultaneously operate with simulated and real entities, thus allowing the use of hybrid systems in the development of applications.\"],\n",
    "[247,5,0,\"Reinforcement learning (RL) can provide a basic framework for autonomous robots to learn to control and maximize future cumulative rewards in complex environments. To achieve high performance, RL controllers must consider the complex external dynamics for movements and task (reward function) and optimize control commands. For example, a robot playing tennis and squash needs to cope with the different dynamics of a tennis or squash racket and such dynamic environmental factors as the wind. In addition, this robot has to tailor its tactics simultaneously under the rules of either game. This double complexity of the external dynamics and reward function sometimes becomes more complex when both the multiple dynamics and multiple reward functions switch implicitly, as in the situation of a real (multi-agent) game of tennis where one player cannot observe the intention of her opponents or her partner. The robot must consider its opponent's and its partner's unobservable behavioral goals (reward function). In this article, we address how an RL agent should be designed to handle such double complexity of dynamics and reward. We have previously proposed modular selection and identification for control (MOSAIC) to cope with nonstationary dynamics where appropriate controllers are selected and learned among many candidates based on the error of its paired dynamics predictor: the forward model. Here we extend this framework for RL and propose MOSAIC-MR architecture. It resembles MOSAIC in spirit and selects and learns an appropriate RL controller based on the RL controller's TD error using the errors of the dynamics (the forward model) and the reward predictors. Furthermore, unlike other MOSAIC variants for RL, RL controllers are not a priori paired with the fixed predictors of dynamics and rewards. The simulation results demonstrate that MOSAIC-MR outperforms other counterparts because of this flexible association ability among RL controllers, forward models, and reward predictors.\"],\n",
    "[248,0,0,\"Transcranial magnetic stimulation is a noninvasive brain stimulation technique. It is based on current induction in the brain with a stimulation coil emitting a strong varying magnetic field. Its development is currently limited by the lack of accuracy and repeatability of manual coil positioning. A dedicated robotic system is proposed in this paper. Contrary to previous approaches in the field, a custom design is introduced to maximize the safety of the subject. Furthermore, the control of the force applied by the coil on the subject's head is implemented. The architecture is original and its experimental evaluation demonstrates its interest: the compensation of the head motion is combined with the force control to ensure accuracy and safety during the stimulation.\"],\n",
    "[249,0,0,\"In closed-loop systems, sensor feedback delays may have disastrous implications for performance and stability. Flies have evolved multiple specializations to reduce this latency, but the fastest feedback during flight involves a delay that is still significant on the timescale of body dynamics. We explored the effect of sensor delay on flight stability and performance for yaw turns using a dynamically scaled robotic model of the fruitfly, Drosophila. The robot was equipped with a real-time feedback system that performed active turns in response to measured torque about the functional yaw axis. We performed system response experiments for a proportional controller in yaw velocity for a range of feedback delays, similar in dimensionless timescale to those experienced by a fly. The results show a fundamental trade-off between sensor delay and permissible feedback gain, and suggest that fast mechanosensory feedback in flies, and most probably in other insects, provide a source of active damping which compliments that contributed by passive effects. Presented in the context of these findings, a control architecture whereby a haltere-mediated inner-loop proportional controller provides damping for slower visually mediated feedback is consistent with tethered-flight measurements, free-flight observations and engineering design principles.\"],\n",
    "[250,0,0,\"OBJECTIVES: To develop and test an interactive robot mounted computing device to support medication management as an example of a complex self-care task in older adults. METHOD: A Grounded Theory (GT), Participatory Design (PD) approach was used within three Action Research (AR) cycles to understand design requirements and test the design configuration addressing the unique task requirements. RESULTS: At the end of the first cycle a conceptual framework was evolved. The second cycle informed architecture and interface design. By the end of third cycle residents successfully interacted with the dialogue system and were generally satisfied with the robot. The results informed further refinement of the prototype. CONCLUSION: An interactive, touch screen based, robot-mounted information tool can be developed to support healthcare needs of older people. Qualitative methods such as the hybrid GT-PD-AR approach may be particularly helpful for innovating and articulating design requirements in challenging situations.\"],\n",
    "[251,5,0,\"IN THE LAST YEARS, OPTIMAL CONTROL THEORY (OCT) HAS EMERGED AS THE LEADING APPROACH FOR INVESTIGATING NEURAL CONTROL OF MOVEMENT AND MOTOR COGNITION FOR TWO COMPLEMENTARY RESEARCH LINES: behavioral neuroscience and humanoid robotics. In both cases, there are general problems that need to be addressed, such as the 'degrees of freedom (DoFs) problem,' the common core of production, observation, reasoning, and learning of 'actions.' OCT, directly derived from engineering design techniques of control systems quantifies task goals as 'cost functions' and uses the sophisticated formal tools of optimal control to obtain desired behavior (and predictions). We propose an alternative 'softer' approach passive motion paradigm (PMP) that we believe is closer to the biomechanics and cybernetics of action. The basic idea is that actions (overt as well as covert) are the consequences of an internal simulation process that 'animates' the body schema with the attractor dynamics of force fields induced by the goal and task-specific constraints. This internal simulation offers the brain a way to dynamically link motor redundancy with task-oriented constraints 'at runtime,' hence solving the 'DoFs problem' without explicit kinematic inversion and cost function computation. We argue that the function of such computational machinery is not only restricted to shaping motor output during action execution but also to provide the self with information on the feasibility, consequence, understanding and meaning of 'potential actions.' In this sense, taking into account recent developments in neuroscience (motor imagery, simulation theory of covert actions, mirror neuron system) and in embodied robotics, PMP offers a novel framework for understanding motor cognition that goes beyond the engineering control paradigm provided by OCT. Therefore, the paper is at the same time a review of the PMP rationale, as a computational theory, and a perspective presentation of how to develop it for designing better cognitive architectures.\"],\n",
    "[252,0,0,\"Cooperation among devices with different sensing, computing and communication capabilities provides interesting possibilities in a growing number of problems and applications including domotics (domestic robotics), environmental monitoring or intelligent cities, among others. Despite the increasing interest in academic and industrial communities, experimental tools for evaluation and comparison of cooperative algorithms for such heterogeneous technologies are still very scarce. This paper presents a remote testbed with mobile robots and Wireless Sensor Networks (WSN) equipped with a set of low-cost off-the-shelf sensors, commonly used in cooperative perception research and applications, that present high degree of heterogeneity in their technology, sensed magnitudes, features, output bandwidth, interfaces and power consumption, among others. Its open and modular architecture allows tight integration and interoperability between mobile robots and WSN through a bidirectional protocol that enables full interaction. Moreover, the integration of standard tools and interfaces increases usability, allowing an easy extension to new hardware and software components and the reuse of code. Different levels of decentralization are considered, supporting from totally distributed to centralized approaches. Developed for the EU-funded Cooperating Objects Network of Excellence (CONET) and currently available at the School of Engineering of Seville (Spain), the testbed provides full remote control through the Internet. Numerous experiments have been performed, some of which are described in the paper.\"],\n",
    "[253,0,0,\"The reliability and robustness of image-based visual servoing systems is still unsolved by the moment. In order to address this issue, a redundant and cooperative 2D visual servoing system based on the information provided by two cameras in eye-in-hand/eye-to-hand configurations is proposed. Its control law has been defined to assure that the whole system is stable if each subsystem is stable and to allow avoiding typical problems of image-based visual servoing systems like task singularities, features extraction errors, disappearance of image features, local minima, etc. Experimental results with an industrial robot manipulator based on Schunk modular motors to demonstrate the stability, performance and robustness of the proposed system are presented.\"],\n",
    "[254,0,0,\"This paper proposes a conceptual hybrid cognitive architecture for cognitive robots to learn behaviors from demonstrations in robotic aid situations. Unlike the current cognitive architectures, this architecture puts concentration on the requirements of the safety, the interaction, and the non-centralized processing in robotic aid situations. Imitation learning technologies for cognitive robots have been integrated into this architecture for rapidly transferring the knowledge and skills between human teachers and robots.\"],\n",
    "[255,0,0,\"Robot and computer-aided surgery platforms bring a variety of sensors into the operating room. These sensors generate information to be synchronized and merged for improving the accuracy and the safety of the surgical procedure for both patients and operators. In this paper, we present our work on the development of a sensor management architecture that is used is to gather and fuse data from localization systems, such as optical and electromagnetic trackers and ultrasound imaging devices. The architecture follows a modular client-server approach and was implemented within the EU-funded project ROBOCAST (FP7 ICT 215190). Furthermore it is based on very well-maintained open-source libraries such as OpenCV and Image-Guided Surgery Toolkit (IGSTK), which are supported from a worldwide community of developers and allow a significant reduction of software costs. We conducted experiments to evaluate the performance of the sensor manager module. We computed the response time needed for a client to receive tracking data or video images, and the time lag between synchronous acquisition with an optical tracker and ultrasound machine. Results showed a median delay of 1.9 ms for a client request of tracking data and about 40 ms for US images; these values are compatible with the data generation rate (20-30 Hz for tracking system and 25 fps for PAL video). Simultaneous acquisitions have been performed with an optical tracking system and US imaging device: data was aligned according to the timestamp associated with each sample and the delay was estimated with a cross-correlation study. A median value of 230 ms delay was calculated showing that realtime 3D reconstruction is not feasible (an offline temporal calibration is needed), although a slow exploration is possible. In conclusion, as far as asleep patient neurosurgery is concerned, the proposed setup is indeed useful for registration error correction because the brain shift occurs with a time constant of few tens of minutes.\"],\n",
    "[256,0,0,\"This paper presents the control architecture and the first performance evaluation results of a novel and highly-dexterous 18 degrees of freedom (DOF) miniature master/slave teleoperated robotic system called SPRINT (Single-Port la-paRoscopy bimaNual roboT). The system was evaluated in terms of positioning accuracy, repeatability, tracking error during local teleoperation and end-effector payload. Moreover, it was experimentally verified that the control architecture is real-time compliant at an operating frequency of 1 kHz and it is also reliable in terms of safety. The architecture accounts for cases when the robot is lead through singularities, and includes other safety mechanisms, such as supervision tasks and watchdog timers. Peliminary tests that were performed by surgeons in-vitro suggest that the SPRINT robot, along with its real-time control architecture, could become in the near future a reliable system in the field of Single Port Laparoscopy.\"],\n",
    "[257,0,0,\"An angular positioning methodology for a two-actuator robotic endoscope tip is presented. The actuators used to position the tip of the endoscope and tools in the tool channel are miniature rotary motors configured to pull mono-filament cables. The sensors used in this system are a camera at the tip and two three-axis gyroscopes. This paper discusses the electrical hardware and communications architecture of the system. A model to account for the dynamic nonlinearities in the system is introduced, experimental results are presented, and control schemes necessary to position the tip is outlined. It was found that the maximum rotational speed of the tip is 400 degrees per second and that the windup delay is around 50 ms which allows for fast angular positioning.\"],\n",
    "[258,0,0,\"A floor-washing robot has been acquired to assist physicists with decontamination of radioiodine therapy ward rooms after discharge of the patient at Sir Charles Gairdner Hospital. The effectiveness of the robot in decontaminating the ward has been evaluated. A controlled experiment was performed by deliberately contaminating a polyvinyl chloride flooring offcut with 131I followed by automated decontamination with the robot. The extent of fixed and removable contamination was assessed before and after decontamination by two methods: (1) direct Geiger-Mueller counting and (2) beta-counting wipe tests. Surface contamination was also assessed in situ on the ward by Geiger-Mueller counting and wipe testing. Contamination maps confirmed that contamination was removed rather than spread around by the robot. Wipe testing revealed that the robot was successful in clearing approximately 60-80% of removable contamination. The robotic floor-washing device was considered suitable to provide effective automated decontamination of the radioiodine ward. In addition, the robot affords other benefits: the time spent by the physicists decontaminating the room is greatly reduced offering financial and occupational safety and health benefits. The robot has also found utility in other decontamination applications in the healthcare environment.\"],\n",
    "[259,0,0,\"In the design of wearable robots that strictly interact with the human body and, in general, in any robotics application that involves the human component, the possibility of having modular joints able to produce a viscoelastic behaviour is very useful to achieve an efficient and safe human-robot interaction and to give rise to emergent dynamical behaviors. In this paper we propose the design of a compact, passive, rotary viscoelastic joint for assistive wearable robotics applications. The system integrates two functionally distinct sub-modules: one to render a desired torsional stiffness profile and the other to provide a desired torsional damping. Concepts and design choices regarding the overall architecture and the single components are presented and discussed. A viscoelastic model of the system has been developed and the design of the joint is presented.\"],\n",
    "[260,0,0,\"Rehabilitation therapy aiming at helping a person to regain or improve the ability to walk is a labour-intensive activity. In this context, the patient is often limited to very restricted walking spaces. This paper presents a device that can support the weight of a person walking freely over a large workspace. The device is based on an overhead gantry mechanism combined with a cable routing that decouples the vertical motion from the horizontal displacements of the person. The mechanical architecture is first presented and it is shown that the principle can be applied to the design of a completely passive device in which the portion of the weight to be supported can be adjusted. A simplified dynamic model is also derived in order to highlight the characteristics of the device. A powered version of the device is then discussed. Finally, a prototype of a passive device built at full scale is presented and discussed. A video accompanying the paper illustrates the experimental tests underway with the prototype.\"],\n",
    "[261,0,0,\"This paper presents design, implementation and control of a 3RPS-R exoskeleton, specifically built to impose targeted therapeutic exercises to forearm and wrist. Design of the exoskeleton features enhanced ergonomy, enlarged workspace and optimized device performance when compared to previous versions of the device. Passive velocity field control (PVFC) is implemented at the task space of the manipulator to provide assistance to the patients, such that the exoskeleton follows a desired velocity field asymptotically while maintaining passivity with respect to external applied torque inputs. PVFC is augmented with virtual tunnels and resulting control architecture is integrated into a virtual flight simulator with force-feedback. Experimental results are presented indicating the applicability and effectiveness of using PVFC on 3RPS-R exoskeleton to deliver therapeutic movement exercises.\"],\n",
    "[262,0,0,\"In recent years, robot-assisted rehabilitation systems have been an active research area that can quantitatively monitor and adapt to patient progress, and ensure consistency during rehabilitation. In this work, an exoskeleton type robot-assisted rehabilitation system called RehabRoby is developed. A control architecture, which contains a high level controller and a low level controller, is designed for RehabRoby. Proprioceptive sense of healthy subjects has been evaluated during the execution of a task with RehabRoby. Additionally, usability of RehabRoby has been evaluated using a questionnaire.\"],\n",
    "[263,0,0,\"A voltage current convertor is described having a quasi complementary class AB architecture that is particularly suited to implementation using discrete power MOSFETs. High-voltage mirror designs are presented, enabling the construction of sources with kilovolt compliance range, tens of watts of output power and greater than 100 kHz bandwidth. GOmega output impedance and distortion below 1% can be obtained with no trimming or transistor matching.\"],\n",
    "[264,0,0,\"The numerical control of an experimental assembly cell with two robots--termed a cognitive control unit (CCU)--is able to simulate human information processing at a rule-based level of cognitive control. To enable the CCU to work on a large range of assembly tasks expected of a human operator, the cognitive architecture SOAR is used. The CCU can plan assembly processes autonomously and react to ad-hoc changes in assembly sequences effectively. Extensive simulation studies have shown that cognitive automation based on SOAR is especially suitable for random parts supply, which reduces planning effort in logistics. Conversely, a disproportional increase in processing time was observed for deterministic parts supply, especially for assemblies containing large numbers of identical parts. In this contribution, the effect of phase-shifts in deterministic part supply is investigated for assemblies containing maximal different parts. It can be shown that the concept of cognitive automation is as well suitable for these planning problems.\"],\n",
    "[265,1,0,\"In this study, we propose an extension of the MOSAIC architecture to control real humanoid robots. MOSAIC was originally proposed by neuroscientists to understand the human ability of adaptive control. The modular architecture of the MOSAIC model can be useful for solving nonlinear and non-stationary control problems. Both humans and humanoid robots have nonlinear body dynamics and many degrees of freedom. Since they can interact with environments (e.g., carrying objects), control strategies need to deal with non-stationary dynamics. Therefore, MOSAIC has strong potential as a human motor-control model and a control framework for humanoid robots. Yet application of the MOSAIC model has been limited to simple simulated dynamics since it is susceptive to observation noise and also cannot be applied to partially observable systems. Our approach introduces state estimators into MOSAIC architecture to cope with real environments. By using an extended MOSAIC model, we are able to successfully generate squatting and object-carrying behaviors on a real humanoid robot.\"],\n",
    "[266,0,0,\"The micro-scale and meso-scale ocean dynamic processes which are nonlinear and have large variability, have a significant impact on the fisheries, natural resources, and marine climatology. A rapid, refined and sophisticated observation system is therefore needed in marine scientific research. The maneuverability and controllability of mobile sensor platforms make them a preferred choice to establish ocean observing networks, compared to the static sensor observing platform. In this study, marine vehicles are utilized as the nodes of mobile sensor networks for coverage sampling of a regional ocean area and ocean feature tracking. A synoptic analysis about marine vehicle dynamic control, multi vehicles mission assignment and path planning methods, and ocean feature tracking and observing techniques is given. Combined with the observation plan in the South China Sea, we provide an overview of the mobile sensor networks established with marine vehicles, and the corresponding simulation results.\"],\n",
    "[267,0,0,\"In the past three decades, the interest in trust has grown significantly due to its important role in our modern society. Everyday social experience involves 'confidence' among people, which can be interpreted at the neurological level of a human brain. Recent studies suggest that oxytocin is a centrally-acting neurotransmitter important in the development and alteration of trust. Its administration in humans seems to increase trust and reduce fear, in part by directly inhibiting the amygdala. However, the cerebral microcircuitry underlying this mechanism is still unknown. We propose the first biologically realistic model for trust, simulating spiking neurons in the cortex in a real-time human-robot interaction simulation. At the physiological level, oxytocin cells were modeled with triple apical dendrites characteristic of their structure in the paraventricular nucleus of the hypothalamus. As trust was established in the simulation, this architecture had a direct inhibitory effect on the amygdala tonic firing, which resulted in a willingness to exchange an object from the trustor (virtual neurorobot) to the trustee (human actor). Our software and hardware enhancements allowed the simulation of almost 100,000 neurons in real time and the incorporation of a sophisticated Gabor mechanism as a visual filter. Our brain was functional and our robotic system was robust in that it trusted or distrusted a human actor based on movement imitation.\"],\n",
    "[268,5,0,\"We have developed an extension of the NEAT neuroevolution method, called NEATfields, to solve problems with large input and output spaces. The NEATfields method is a multilevel neuroevolution method using externally specified design patterns. Its networks have three levels of architecture. The highest level is a NEAT-like network of neural fields. The intermediate level is a field of identical subnetworks, called field elements, with a two-dimensional topology. The lowest level is a NEAT-like subnetwork of neurons. The topology and connection weights of these networks are evolved with methods derived from the NEAT method. Evolution is provided with further design patterns to enable information flow between field elements, to dehomogenize neural fields, and to enable detection of local features. We show that the NEATfields method can solve a number of high dimensional pattern recognition and control problems, provide conceptual and empirical comparison with the state of the art HyperNEAT method, and evaluate the benefits of different design patterns.\"],\n",
    "[269,0,0,\"The recent outburst of interest in cognitive developmental robotics is fueled by the ambition to propose ecologically plausible mechanisms of how, among other things, a learning agent/robot could ground linguistic meanings in its sensorimotor behavior. Along this stream, we propose a model that allows the simulated iCub robot to learn the meanings of actions (point, touch, and push) oriented toward objects in robot's peripersonal space. In our experiments, the iCub learns to execute motor actions and comment on them. Architecturally, the model is composed of three neural-network-based modules that are trained in different ways. The first module, a two-layer perceptron, is trained by back-propagation to attend to the target position in the visual scene, given the low-level visual information and the feature-based target information. The second module, having the form of an actor-critic architecture, is the most distinguishing part of our model, and is trained by a continuous version of reinforcement learning to execute actions as sequences, based on a linguistic command. The third module, an echo-state network, is trained to provide the linguistic description of the executed actions. The trained model generalizes well in case of novel action-target combinations with randomized initial arm positions. It can also promptly adapt its behavior if the action/target suddenly changes during motor execution.\"],\n",
    "[270,0,0,\"BACKGROUND: In the past 20 years, technological advancements have modified the concept of modern operating rooms (ORs) with the introduction of computer-integrated surgery (CIS) systems, which promise to enhance the outcomes, safety and standardization of surgical procedures. With CIS, different types of sensor (mainly position-sensing devices, force sensors and intra-operative imaging devices) are widely used. Recently, the need for a combined use of different sensors raised issues related to synchronization and spatial consistency of data from different sources of information. METHODS: In this study, we propose a centralized, multi-sensor management software architecture for a distributed CIS system, which addresses sensor information consistency in both space and time. The software was developed as a data server module in a client-server architecture, using two open-source software libraries: Image-Guided Surgery Toolkit (IGSTK) and OpenCV. The ROBOCAST project (FP7 ICT 215190), which aims at integrating robotic and navigation devices and technologies in order to improve the outcome of the surgical intervention, was used as the benchmark. An experimental protocol was designed in order to prove the feasibility of a centralized module for data acquisition and to test the application latency when dealing with optical and electromagnetic tracking systems and ultrasound (US) imaging devices. RESULTS: Our results show that a centralized approach is suitable for minimizing synchronization errors; latency in the client-server communication was estimated to be 2 ms (median value) for tracking systems and 40 ms (median value) for US images. CONCLUSION: The proposed centralized approach proved to be adequate for neurosurgery requirements. Latency introduced by the proposed architecture does not affect tracking system performance in terms of frame rate and limits US images frame rate at 25 fps, which is acceptable for providing visual feedback to the surgeon in the OR.\"],\n",
    "[271,0,0,\"This article presents a novel closed loop control architecture based on audio channels of several types of computing devices, such as mobile phones and tablet computers, but not restricted to them. The communication is based on an audio interface that relies on the exchange of audio tones, allowing sensors to be read and actuators to be controlled. As an application example, the presented technique is used to build a low cost mobile robot, but the system can also be used in a variety of mechatronics applications and sensor networks, where smartphones are the basic building blocks.\"],\n",
    "[272,0,0,\"This paper presents an architecture for computing vector disparity for active vision systems as used on robotics applications. The control of the vergence angle of a binocular system allows us to efficiently explore dynamic environments, but requires a generalization of the disparity computation with respect to a static camera setup, where the disparity is strictly 1-D after the image rectification. The interaction between vision and motor control allows us to develop an active sensor that achieves high accuracy of the disparity computation around the fixation point, and fast reaction time for the vergence control. In this contribution, we address the development of a real-time architecture for vector disparity computation using an FPGA device. We implement the disparity unit and the control module for vergence, version, and tilt to determine the fixation point. In addition, two on-chip different alternatives for the vector disparity engines are discussed based on the luminance (gradient-based) and phase information of the binocular images. The multiscale versions of these engines are able to estimate the vector disparity up to 32 fps on VGA resolution images with very good accuracy as shown using benchmark sequences with known ground-truth. The performances in terms of frame-rate, resource utilization, and accuracy of the presented approaches are discussed. On the basis of these results, our study indicates that the gradient-based approach leads to the best trade-off choice for the integration with the active vision system.\"],\n",
    "[273,0,0,\"A key challenge in evolving control systems for robots using neural networks is training tractability. Evolving monolithic fixed topology neural networks is shown to be intractable with limited supervision in high dimensional search spaces. Common strategies to overcome this limitation are to provide more supervision by encouraging particular solution strategies, manually decomposing the task and segmenting the search space and network. These strategies require a supervisor with domain knowledge and may not be feasible for difficult tasks where novel concepts are required. The alternate strategy is to use self-organized task decomposition to solve difficult tasks with limited supervision. The artificial neural tissue (ANT) approach presented here uses self-organized task decomposition to solve tasks. ANT inspired by neurobiology combines standard neural networks with a novel wireless signaling scheme modeling chemical diffusion of neurotransmitters. These chemicals are used to dynamically activate and inhibit wired network of neurons using a coarse-coding framework. Using only a global fitness function that does not encourage a predefined solution, modular networks of neurons are shown to self-organize and perform task decomposition. This approach solves the sign-following task found to be intractable with conventional fixed and variable topology networks. In this paper, key attributes of the ANT architecture that perform self-organized task decomposition are shown. The architecture is robust and scalable to number of neurons, synaptic connections, and initialization parameters.\"],\n",
    "[274,0,0,\"Nonambulatory, visually impaired individuals mostly rely on caregivers for their day-to-day mobility needs. The Drive-Safe System (DSS) is a modular, semiautonomous smart wheelchair system aimed at providing independent mobility to people with visual and mobility impairments. In this project, clinical evaluation of the DSS was performed in a controlled laboratory setting with individuals who have visual impairment but no mobility impairment. Their performance using DSS was compared with their performance using a standard cane for navigation assistance. Participants rated their subjective appraisal of the DSS by using the National Aeronautics and Space Administration-Task Load Index inventory. DSS significantly reduced the number and severity of collisions compared with using a cane alone and without increasing the time required to complete the task. Users rated DSS favorably; they experienced less physical demand when using the DSS, but did not feel any difference in perceived effort, mental demand, and level of frustration when using the DSS alone or along with a cane in comparison with using a cane alone. These findings suggest that the DSS can be a safe, reliable, and easy-to-learn and operate independent mobility solution for visually impaired wheelchair users.\"],\n",
    "[275,0,0,\"This paper presents the design of a bat-like micro aerial vehicle with actuated morphing wings. NiTi shape memory alloys (SMAs) acting as artificial biceps and triceps muscles are used for mimicking the morphing wing mechanism of the bat flight apparatus. Our objective is twofold. Firstly, we have implemented a control architecture that allows an accurate and fast SMA actuation. This control makes use of the electrical resistance measurements of SMAs to adjust morphing wing motions. Secondly, the feasibility of using SMA actuation technology is evaluated for the application at hand. To this purpose, experiments are conducted to analyze the control performance in terms of nominal and overloaded operation modes of the SMAs. This analysis includes: (i) inertial forces regarding the stretchable wing membrane and aerodynamic loads, and (ii) uncertainties due to impact of airflow conditions over the resistance-motion relationship of SMAs. With the proposed control, morphing actuation speed can be increased up to 2.5 Hz, being sufficient to generate lift forces at a cruising speed of 5 m s(-1).\"],\n",
    "[276,0,0,\"BACKGROUND: Telesurgery delivers surgical care to a 'remote' patient by means of robotic manipulators. When accurate positioning of the surgeon's tool is required, as in microsurgery, physiological tremor causes unwanted imprecision during a surgical operation. Accurate estimation/compensation of physiological tremor in teleoperation systems has been shown to improve performance during telesurgery. METHOD: A new control architecture is proposed for estimation and compensation of physiological tremor in the presence of communication time delays. This control architecture guarantees stability with satisfactory transparency. In addition, the proposed method can be used for applications that require modifications in transmitted signals through communication channels. Stability of the bilateral tremor-compensated teleoperation is preserved by extending the bilateral teleoperation to the equivalent trilateral Dual-master/Single-slave teleoperation. The bandlimited multiple Fourier linear combiner (BMFLC) algorithm is employed for real-time estimation of the operator's physiological tremor. RESULTS: Two kinds of stability analysis are employed. In the model-base controller, Llewellyn's Criterion is used to analyze the teleoperation absolute stability. In the second method, a nonmodel-based controller is proposed and the stability of the time-delayed teleoperated system is proved by employing a Lyapunov function. Experimental results are presented to validate the effectiveness of the new control architecture. The tremorous motion is measured by accelerometer to be compensated in real time. In addition, a Needle-Insertion setup is proposed as a slave robot for the application of brachytherapy, in which the needle penetrates in the desired position. The slave performs the desired task in two classes of environments (free motion of the slave and in the soft tissue). CONCLUSION: Experiments show that the proposed control architecture effectively compensates the user's tremorous motion and the slave follows only the master's voluntary motion in a stable manner.\"],\n",
    "[277,0,0,\"In this paper we present a neuro-inspired spike-based close-loop controller written in VHDL and implemented for FPGAs. This controller has been focused on controlling a DC motor speed, but only using spikes for information representation, processing and DC motor driving. It could be applied to other motors with proper driver adaptation. This controller architecture represents one of the latest layers in a Spiking Neural Network (SNN), which implements a bridge between robotics actuators and spike-based processing layers and sensors. The presented control system fuses actuation and sensors information as spikes streams, processing these spikes in hard real-time, implementing a massively parallel information processing system, through specialized spike-based circuits. This spike-based close-loop controller has been implemented into an AER platform, designed in our labs, that allows direct control of DC motors: the AER-Robot. Experimental results evidence the viability of the implementation of spike-based controllers, and hardware synthesis denotes low hardware requirements that allow replicating this controller in a high number of parallel controllers working together to allow a real-time robot control.\"],\n",
    "[278,0,0,\"Various solid freeform fabrication technologies have been introduced for constructing three-dimensional (3-D) freeform structures. Of these, microstereolithography (MSTL) technology performs the best in 3-D space because it not only has high resolution, but also fast fabrication speed. Using this technology, 3-D structures with mesoscale size and microscale resolution are achievable. Many researchers have been trying to apply this technology to tissue engineering to construct medically applicable scaffolds, which require a 3-D shape that fits a defect with a mesoscale size and microscale inner architecture for efficient regeneration of artificial tissue. This chapter introduces the principles of MSTL technology and representative systems. It includes fabrication and computer-aided design/computer-aided manufacturing (CAD/CAM) processes to show the automation process by which measurements from medical images are used to fabricate the required 3-D shape. Then, various tissue engineering applications based on MSTL are summarized.\"],\n",
    "[279,0,0,\"Due to the sensitive international situation caused by still-recent terrorist attacks, there is a common need to protect the safety of large spaces such as government buildings, airports and power stations. To address this problem, developments in several research fields, such as video and cognitive audio, decision support systems, human interface, computer architecture, communications networks and communications security, should be integrated with the goal of achieving advanced security systems capable of checking all of the specified requirements and spanning the gap that presently exists in the current market. This paper describes the implementation of a decision system for crisis management in infrastructural building security. Specifically, it describes the implementation of a decision system in the management of building intrusions. The positions of the unidentified persons are reported with the help of a Wireless Sensor Network (WSN). The goal is to achieve an intelligent system capable of making the best decision in real time in order to quickly neutralise one or more intruders who threaten strategic installations. It is assumed that the intruders' behaviour is inferred through sequences of sensors' activations and their fusion. This article presents a general approach to selecting the optimum operation from the available neutralisation strategies based on a Minimax algorithm. The distances among different scenario elements will be used to measure the risk of the scene, so a path planning technique will be integrated in order to attain a good performance. Different actions to be executed over the elements of the scene such as moving a guard, blocking a door or turning on an alarm will be used to neutralise the crisis. This set of actions executed to stop the crisis is known as the neutralisation strategy. Finally, the system has been tested in simulations of real situations, and the results have been evaluated according to the final state of the intruders. In 86.5% of the cases, the system achieved the capture of the intruders, and in 59.25% of the cases, they were intercepted before they reached their objective.\"],\n",
    "[280,0,0,\"In this paper, we describe the development of a bipedal robot that models the neuromuscular architecture of human walking. The body is based on principles derived from human muscular architecture, using muscles on straps to mimic agonist/antagonist muscle action as well as bifunctional muscles. Load sensors in the straps model Golgi tendon organs. The neural architecture is a central pattern generator (CPG) composed of a half-center oscillator combined with phase-modulated reflexes that is simulated using a spiking neural network. We show that the interaction between the reflex system, body dynamics and CPG results in a walking cycle that is entrained to the dynamics of the system. We also show that the CPG helped stabilize the gait against perturbations relative to a purely reflexive system, and compared the joint trajectories to human walking data. This robot represents a complete physical, or 'neurorobotic', model of the system, demonstrating the usefulness of this type of robotics research for investigating the neurophysiological processes underlying walking in humans and animals.\"],\n",
    "[281,0,0,\"The use of a primate's spatial ability of mental rotation to serve as a basis for robotic navigation has been almost entirely overlooked by the robotics community to date. In this paper, the role of this cognitive capacity is presented as an adjunct to existing robotic control systems, with the underlying approach being derived from studies of primate spatial cognition. Specifically, optical flow is used as a basis for transitory representations (snapshots) that are compared to an a priori visual goal to provide corrective course action for a robot when moving through the world. The underlying architecture and procedures are described.\"],\n",
    "[282,0,0,\"Reverse engineering of biological form and function requires hierarchical design over several orders of space and time. Recent advances in the mechanistic understanding of biosynthetic compound materials, computer-aided design approaches in molecular synthetic biology 4,5 and traditional soft robotics, and increasing aptitude in generating structural and chemical micro environments that promote cellular self-organization have enhanced the ability to recapitulate such hierarchical architecture in engineered biological systems. Here we combined these capabilities in a systematic design strategy to reverse engineer a muscular pump. We report the construction of a freely swimming jellyfish from chemically dissociated rat tissue and silicone polymer as a proof of concept. The constructs, termed 'medusoids', were designed with computer simulations and experiments to match key determinants of jellyfish propulsion and feeding performance by quantitatively mimicking structural design, stroke kinematics and animal-fluid interactions. The combination of the engineering design algorithm with quantitative benchmarks of physiological performance suggests that our strategy is broadly applicable to reverse engineering of muscular organs or simple life forms that pump to survive.\"],\n",
    "[283,0,0,\"In biological systems, instead of actual encoders at different joints, proprioception signals are acquired through distributed receptive fields. In robotics, a single and accurate sensor output per link (encoder) is commonly used to track the position and the velocity. Interfacing bio-inspired control systems with spiking neural networks emulating the cerebellum with conventional robots is not a straight forward task. Therefore, it is necessary to adapt this one-dimensional measure (encoder output) into a multidimensional space (inputs for a spiking neural network) to connect, for instance, the spiking cerebellar architecture; i.e. a translation from an analog space into a distributed population coding in terms of spikes. This paper analyzes how evolved receptive fields (optimized towards information transmission) can efficiently generate a sensorimotor representation that facilitates its discrimination from other 'sensorimotor states'. This can be seen as an abstraction of the Cuneate Nucleus (CN) functionality in a robot-arm scenario. We model the CN as a spiking neuron population coding in time according to the response of mechanoreceptors during a multi-joint movement in a robot joint space. An encoding scheme that takes into account the relative spiking time of the signals propagating from peripheral nerve fibers to second-order somatosensory neurons is proposed. Due to the enormous number of possible encodings, we have applied an evolutionary algorithm to evolve the sensory receptive field representation from random to optimized encoding. Following the nature-inspired analogy, evolved configurations have shown to outperform simple hand-tuned configurations and other homogenized configurations based on the solution provided by the optimization engine (evolutionary algorithm). We have used artificial evolutionary engines as the optimization tool to circumvent nonlinearity responses in receptive fields.\"],\n",
    "[284,0,0,\"High-speed terrestrial locomotion inevitably involves high acceleration and extensive loadings on the legs. This imposes a challenging trade-off between weight and strength in leg design. This paper introduces a new design paradigm for a robotic leg inspired by musculoskeletal structures. The central hypothesis is that employing a tendon-bone co-location architecture not only provides compliance in the leg, but can also reduce bone stresses caused by bending on structures. This hypothesis is applied to a leg design, and verified by simulations and the experiments on a prototype. In addition, we also present an optimization scheme to maximize the strength to weight ratio. Using the tendon-bone co-location architecture, the stress on the bone during a stride is reduced by up to 59%. A new foam-core prototyping technique enables creating structural characteristics similar to mammalian bones in the robotic leg. This method allows us to use lighter polymeric structures that are cheaper and quicker to fabricate than conventional fabrication methods, and can eventually greatly shorten the design iteration cycle time.\"],\n",
    "[285,0,0,\"Kinesin is a protein-based natural nanomotor that transports molecular cargoes within cells by walking along microtubules. Kinesin nanomotor is considered as a bio-nanoagent which is able to sense the cell through its sensors (i.e. its heads and tail), make the decision internally and perform actions on the cell through its actuator (i.e. its motor domain). The study maps the agent-based architectural model of internal decision-making process of kinesin nanomotor to a machine language using an automata algorithm. The applied automata algorithm receives the internal agent-based architectural model of kinesin nanomotor as a deterministic finite automaton (DFA) model and generates a regular machine language. The generated regular machine language was acceptable by the architectural DFA model of the nanomotor and also in good agreement with its natural behaviour. The internal agent-based architectural model of kinesin nanomotor indicates the degree of autonomy and intelligence of the nanomotor interactions with its cell. Thus, our developed regular machine language can model the degree of autonomy and intelligence of kinesin nanomotor interactions with its cell as a language. Modelling of internal architectures of autonomous and intelligent bio-nanosystems as machine languages can lay the foundation towards the concept of bio-nanoswarms and next phases of the bio-nanorobotic systems development.\"],\n",
    "[286,0,0,\"This study proposes an adaptive control architecture based on an accurate regression method called Locally Weighted Projection Regression (LWPR) and on a bio-inspired module, such as a cerebellar-like engine. This hybrid architecture takes full advantage of the machine learning module (LWPR kernel) to abstract an optimized representation of the sensorimotor space while the cerebellar component integrates this to generate corrective terms in the framework of a control task. Furthermore, we illustrate how the use of a simple adaptive error feedback term allows to use the proposed architecture even in the absence of an accurate analytic reference model. The presented approach achieves an accurate control with low gain corrective terms (for compliant control schemes). We evaluate the contribution of the different components of the proposed scheme comparing the obtained performance with alternative approaches. Then, we show that the presented architecture can be used for accurate manipulation of different objects when their physical properties are not directly known by the controller. We evaluate how the scheme scales for simulated plants of high Degrees of Freedom (7-DOFs).\"],\n",
    "[287,0,0,\"The cerebellum is thought to implement internal models for sensory prediction, but details of the underlying circuitry are currently obscure. We therefore investigated a specific example of internal-model based sensory prediction, namely detection of whisker contacts during whisking. Inputs from the vibrissae in rats can be affected by signals generated by whisker movement, a phenomenon also observable in whisking robots. Robot novelty-detection can be improved by adaptive noise-cancellation, in which an adaptive filter learns a forward model of the whisker plant that allows the sensory effects of whisking to be predicted and thus subtracted from the noisy sensory input. However, the forward model only uses information from an efference copy of the whisking commands. Here we show that the addition of sensory information from the whiskers allows the adaptive filter to learn a more complex internal model that performs more robustly than the forward model, particularly when the whisking-induced interference has a periodic structure. We then propose a neural equivalent of the circuitry required for adaptive novelty-detection in the robot, in which the role of the adaptive filter is carried out by the cerebellum, with the comparison of its output (an estimate of the self-induced interference) and the original vibrissal signal occurring in the superior colliculus, a structure noted for its central role in novelty detection. This proposal makes a specific prediction concerning the whisker-related functions of a region in cerebellar cortical zone A(2) that in rats receives climbing fibre input from the superior colliculus (via the inferior olive). This region has not been observed in non-whisking animals such as cats and primates, and its functional role in vibrissal processing has hitherto remained mysterious. Further investigation of this system may throw light on how cerebellar-based internal models could be used in broader sensory, motor and cognitive contexts.\"],\n",
    "[288,0,0,\"In this paper, we present a spiking neural model that learns spatio-motor transformations. The model is in the form of a multilayered architecture consisting of integrate and fire neurons and synapses that employ spike-timing-dependent plasticity learning rule to enable the learning of such transformations. We developed a simple 2-degree-of-freedom robot-based reaching task which involves the learning of a nonlinear function. Computer simulations demonstrate the capability of such a model for learning the forward and inverse kinematics for such a task and hence to learn spatio-motor transformations. The interesting aspect of the model is its capacity to be tolerant to partial absence of sensory or motor inputs at various stages of learning. We believe that such a model lays the foundation for learning other complex functions and transformations in real-world scenarios.\"],\n",
    "[289,0,0,\"The intrinsic parallelism of visual neural architectures based on distributed hierarchical layers is well suited to be implemented on the multi-core architectures of modern graphics cards. The design strategies that allow us to optimally take advantage of such parallelism, in order to efficiently map on GPU the hierarchy of layers and the canonical neural computations, are proposed. Speci fi cally, the advantages of a cortical map-like representation of the data are exploited. Moreover, a GPU implementation of a novel neural architecture for the computation of binocular disparity from stereo image pairs, based on populations of binocular energy neurons, is presented. The implemented neural model achieves good performances in terms of reliability of the disparity estimates and a near real-time execution speed, thus demonstrating the effectiveness of the devised design strategies. The proposed approach is valid in general, since the neural building blocks we implemented are a common basis for the modeling of visual neural functionalities.\"],\n",
    "[290,0,0,\"In this paper we focus on modeling autonomous learning to improve performance of a humanoid robot through a modular artificial neural networks architecture. A model of a neural controller is presented, which allows a humanoid robot iCub to autonomously improve its sensorimotor skills. This is achieved by endowing the neural controller with a secondary neural system that, by exploiting the sensorimotor skills already acquired by the robot, is able to generate additional imaginary examples that can be used by the controller itself to improve the performance through a simulated mental training. Results and analysis presented in the paper provide evidence of the viability of the approach proposed and help to clarify the rational behind the chosen model and its implementation.\"],\n",
    "[291,0,0,\"Our institution established a new treatment facility for carbon ion beam scanning therapy in 2010. The major advantages of scanning beam treatment compared to the passive beam treatment are the following: high dose conformation with less excessive dose to the normal tissues, no bolus compensator and patient collimator/multi-leaf collimator, better dose efficiency by reducing the number of scatters. The new facility was designed to solve several problems encountered in the existing facility, at which several thousand patients were treated over more than 15 years. Here, we introduce the patient handling system in the new treatment facility. The new facility incorporates three main systems, a scanning irradiation system (S-IR), treatment planning system (TPS), and patient handling system (PTH). The PTH covers a wide range of functions including imaging, geometrical/position accuracy including motion management (immobilization, robotic arm treatment bed), layout of the treatment room, treatment workflow, software, and others. The first clinical trials without respiratory gating have been successfully started. The PTH allows a reduction in patient stay in the treatment room to as few as 7 min. The PTH plays an important role in carbon ion beam scanning therapy at the new institution, particularly in the management of patient handling, application of image-guided therapy, and improvement of treatment workflow, and thereby allows substantially better treatment at minimum cost.\"],\n",
    "[292,0,0,\"In robot-assisted minimally invasive laparoscopic surgery, dexterity has a high relevance. Ideally, the surgeon should feel like in open surgery with the robotic instrument able to perform all tool motions in a suitably wide workspace. The avoidance of the surrounding organs and the adaptation of the motion of the instrument to the space available in the patient should be carried out by the robot and should not interest the surgeon. The dexterity is improved by increasing the number of degrees of freedom available in the portion of the surgical instrument inside the patient. The trend has been to date to actuate the joints in the instrument using actuators located outside the patient and tendons or other transmissions to reach the joints. This approach presents intrinsic limitations that can be overcome only with a change of the architecture. The article presents a design of surgical arm made of modules joined together in a chain. Each module embeds its actuation and sensing. The arm architecture can be selected to be optimal for a specific patient and surgery. The major criticality of this architectural rethink is if small actuators could provide enough torque to move the chain and apply sufficient surgical forces. Preliminary experiments are presented proving that embedded actuation can be strong and powerful enough. The designs of a variety of modules are carefully described.\"],\n",
    "[293,9,1,\"One key idea behind morphological computation is that many difficulties of a control problem can be absorbed by the morphology of a robot. The performance of the controlled system naturally depends on the control architecture and on the morphology of the robot. Because of this strong coupling, most of the impressive applications in morphological computation typically apply minimalistic control architectures. Ideally, adapting the morphology of the plant and optimizing the control law interact so that finally, optimal physical properties of the system and optimal control laws emerge. As a first step toward this vision, we apply optimal control methods for investigating the power of morphological computation. We use a probabilistic optimal control method to acquire control laws, given the current morphology. We show that by changing the morphology of our robot, control problems can be simplified, resulting in optimal controllers with reduced complexity and higher performance. This concept is evaluated on a compliant four-link model of a humanoid robot, which has to keep balance in the presence of external pushes.\"],\n",
    "[294,0,0,\"The study of anatomical connectivity is essential for interpreting functional MRI data and for establishing how brain areas are linked together into networks to support higher-order functions. Diffusion-weighted MR images (DWI) and tractography provide a unique noninvasive tool to explore the connectional architecture of the brain. The identification of anatomical circuits associated with a specific function can be better accomplished by the joint application of diffusion and functional MRI. In this article, we propose a simple algorithm to identify the set of pathways between two regions of interest. The method is based upon running deterministic tractography from all possible starting positions in the brain and selecting trajectories that intersect both regions. We compare results from single-fiber tractography using diffusion tensor imaging and from multi-fiber tractography using reduced-encoding persistent angular structure (PAS) MRI on standard DWI datasets from healthy human volunteers. Our results show that, in comparison with single-fiber tractography, the multi-fiber technique reveals additional putative routes of connection. We demonstrate highly consistent results of the proposed technique over a cohort of 16 healthy subjects.\"],\n",
    "[295,0,0,\"Emerging technology, especially robotic technology, has been shown to be appealing to children with autism spectrum disorders (ASD). Such interest may be leveraged to provide repeatable, accurate and individualized intervention services to young children with ASD based on quantitative metrics. However, existing robot-mediated systems tend to have limited adaptive capability that may impact individualization. Our current work seeks to bridge this gap by developing an adaptive and individualized robot-mediated technology for children with ASD. The system is composed of a humanoid robot with its vision augmented by a network of cameras for real-time head tracking using a distributed architecture. Based on the cues from the child's head movement, the robot intelligently adapts itself in an individualized manner to generate prompts and reinforcements with potential to promote skills in the ASD core deficit area of early social orienting. The system was validated for feasibility, accuracy, and performance. Results from a pilot usability study involving six children with ASD and a control group of six typically developing (TD) children are presented.\"],\n",
    "[296,0,0,\"The development of inorganic-organic hybrid scaffolds with controllable degradation and bioactive properties is receiving considerable interest for bone and tissue regeneration. The objective of this study was to create hybrid scaffolds of gelatin and bioactive glass (BG) with a controlled, three-dimensional (3D) architecture by a combined sol-gel and robotic deposition (robocasting) method and evaluate their mechanical response, bioactivity, and response to cells in vitro. Inks for robotic deposition of the scaffolds were prepared by dissolving gelatin in a sol-gel precursor solution of the bioactive glass (70SiO2 -25CaO-5P2 O5 ; mol%) and aging the solution to form a gel with the requisite viscosity. After drying and crosslinking, the gelatin-BG scaffolds, with a grid-like architecture (filament diameter approximately 350 microm; pore width approximately 550 microm), showed an elasto-plastic response, with a compressive strength of 5.1 +/- 0.6 MPa, in the range of values for human trabecular bone (2-12 MPa). When immersed in phosphate-buffered saline, the crosslinked scaffolds rapidly absorbed water ( approximately 440% of its dry weight after 2 h) and showed an elastic response at deformations up to approximately 60%. Immersion of the scaffolds in a simulated body fluid resulted in the formation of a hydroxyapatite-like surface layer within 5 days, indicating their bioactivity in vitro. The scaffolds supported the proliferation, alkaline phosphatase activity, and mineralization of osteogenic MC3T3-E1 cells in vitro, showing their biocompatibility. Altogether, the results indicate that these gelatin-BG hybrid scaffolds with a controlled, 3D architecture of inter-connected pores have potential for use as implants for bone regeneration.\"],\n",
    "[297,0,0,\"As electronic devices become increasingly complex, ensuring their reliable, fault-free operation is becoming correspondingly more challenging. It can be observed that, in spite of their complexity, biological systems are highly reliable and fault tolerant. Hence, we are motivated to take inspiration for biological systems in the design of electronic ones. In SABRE (self-healing cellular architectures for biologically inspired highly reliable electronic systems), we have designed a bio-inspired fault-tolerant hierarchical architecture for this purpose. As in biology, the foundation for the whole system is cellular in nature, with each cell able to detect faults in its operation and trigger intra-cellular or extra-cellular repair as required. At the next level in the hierarchy, arrays of cells are configured and controlled as function units in a transport triggered architecture (TTA), which is able to perform partial-dynamic reconfiguration to rectify problems that cannot be solved at the cellular level. Each TTA is, in turn, part of a larger multi-processor system which employs coarser grain reconfiguration to tolerate faults that cause a processor to fail. In this paper, we describe the details of operation of each layer of the SABRE hierarchy, and how these layers interact to provide a high systemic level of fault tolerance.\"],\n",
    "[298,0,0,\"This paper describes a new intraoperative planning system created to improve precision and safety in teleoperated laser microsurgeries. It addresses major safety issues related to real-time control of a surgical laser during teleoperated procedures, which are related to the reliability and robustness of the telecommunication channels. Here, a safe solution is presented, consisting in a new planning system architecture that maintains the flexibility and benefits of real-time teleoperation and keeps the surgeon in control of all surgical actions. The developed system is based on our virtual scalpel system for robot-assisted laser microsurgery, and allows the intuitive use of stylus to create surgical plans directly over live video of the surgical field. In this case, surgical plans are defined as graphic objects overlaid on the live video, which can be easily modified or replaced as needed, and which are transmitted to the main surgical system controller for subsequent safe execution. In the process of improving safety, this new planning system also resulted in improved laser aiming precision and improved capability for higher quality laser procedures, both due to the new surgical plan execution module, which allows very fast and precise laser aiming control. Experimental results presented herein show that, in addition to the safety improvements, the new planning system resulted in a 48% improvement in laser aiming precision when compared to the previous virtual scalpel system.\"],\n",
    "[299,0,0,\"This paper presents the novel hybrid kinematic structure of the Active Headframe, a robotic head support to be employed in brain surgery operations for an active and dynamic control of the patient's head position and orientation, particularly addressing awake surgery requirements. The topology has been conceived in order to satisfy all the installation, functional and dynamic requirements. A kinetostatic optimization has been performed to obtain the actual geometric dimensions of the prototype currently being developed.\"],\n",
    "[300,0,0,\"This paper presents an efficient approach to achieve microparticles flocking with robotics and optical tweezers technologies. All particles trapped by optical tweezers can be automatically moved toward a predefined region without collision. The main contribution of this paper lies in the proposal of several solutions to the flocking manipulation of microparticles in microenvironments. First, a simple flocking controller is proposed to generate the desired positions and velocities for particles' movement. Second, a velocity saturation method is implemented to prevent the desired velocities from exceeding a safe limit. Third, a two-layer control architecture is proposed for the motion control of optical tweezers. This architecture can help make many robotic manipulations achievable under microenvironments. The proposed approach with these solutions can be applied to many bioapplications especially in cell engineering and biomedicine. Experiments on yeast cells with a robot-tweezers system are finally performed to verify the effectiveness of the proposed approach.\"],\n",
    "[301,0,0,\"This paper, proposes a novel solution for a stereo vision machine based on the System-on-Programmable-Chip (SoPC) architecture. The SOPC technology provides great convenience for accessing many hardware devices such as DDRII, SSRAM, Flash, etc., by IP reuse. The system hardware is implemented in a single FPGA chip involving a 32-bit Nios II microprocessor, which is a configurable soft IP core in charge of managing the image buffer and users' configuration data. The Sum of Absolute Differences (SAD) algorithm is used for dense disparity map computation. The circuits of the algorithmic module are modeled by the Matlab-based DSP Builder. With a set of configuration interfaces, the machine can process many different sizes of stereo pair images. The maximum image size is up to 512 K pixels. This machine is designed to focus on real time stereo vision applications. The stereo vision machine offers good performance and high efficiency in real time. Considering a hardware FPGA clock of 90 MHz, 23 frames of 640 x 480 disparity maps can be obtained in one second with 5 x 5 matching window and maximum 64 disparity pixels.\"],\n",
    "[302,0,0,\"Multifunctional materials and devices found in nature serve as inspiration for advanced synthetic materials, structures and robotics. Here, we elucidate the architecture and unusual deformation mechanisms of seahorse tails that provide prehension as well as protection against predators. The seahorse tail is composed of subdermal bony plates arranged in articulating ring-like segments that overlap for controlled ventral bending and twisting. The bony plates are highly deformable materials designed to slide past one another and buckle when compressed. This complex plate and segment motion, along with the unique hardness distribution and structural hierarchy of each plate, provide seahorses with joint flexibility while shielding them against impact and crushing. Mimicking seahorse armor may lead to novel bio-inspired technologies, such as flexible armor, fracture-resistant structures or prehensile robotics.\"],\n",
    "[303,5,0,\"We demonstrate the power of evolutionary robotics (ER) by comparing to a more traditional approach its performance and cost on the task of simulated robot locomotion. A novel quadruped robot is introduced, the legs of which - each having three non-coplanar degrees of freedom - are very maneuverable. Using a simplistic control architecture and a physics simulation of the robot, gaits are designed both by hand and using a highly parallel evolutionary algorithm (EA). It is found that the EA produces, in a small fraction of the time that takes to design by hand, gaits that travel at two to four times the speed of the hand-designed one. The flexibility of this approach is demonstrated by applying it across a range of differently configured simulators.\"],\n",
    "[304,0,0,\"This article presents a strategy for identifying the source location of a chemical plume in near-shore oceanic environments where the plume is developed under the influence of turbulence, tides and waves. This strategy includes two modules: source declaration (or identification) and source verification embedded in a subsumption architecture. Algorithms for source identification are derived from the moth-inspired plume tracing strategies based on a chemical sensor. The in-water test missions, conducted in November 2002 at San Clemente Island (California, USA) in June 2003 in Duck (North Carolina, USA) and in October 2010 at Dalian Bay (China), successfully identified the source locations after autonomous underwater vehicles tracked the rhodamine dye plumes with a significant meander over 100 meters. The objective of the verification module is to verify the declared plume source using a visual sensor. Because images taken in near shore oceanic environments are very vague and colors in the images are not well-defined, we adopt a fuzzy color extractor to segment the color components and recognize the chemical plume and its source by measuring color similarity. The source verification module is tested by images taken during the CPT missions.\"],\n",
    "[305,0,0,\"This article describes our experiences in creating a fully integrated, globally accessible, automated chemical synthesis laboratory. The goal of the project was to establish a fully integrated automated synthesis solution that was initially focused on minimizing the burden of repetitive, routine, rules-based operations that characterize more established chemistry workflows. The architecture was crafted to allow for the expansion of synthetic capabilities while also providing for a flexible interface that permits the synthesis objective to be introduced and manipulated as needed under the judicious direction of a remote user in real-time. This innovative central synthesis suite is herein described along with some case studies to illustrate the impact such a system is having in expanding drug discovery capabilities.\"],\n",
    "[306,0,0,\"A flexible endoscope could reach the potential surgical site via a single small incision on the patient or even through natural orifices, making it a very promising platform for surgical procedures. However, endoscopic surgery has strict spatial constraints on both tool-channel size and surgical site volume. It is therefore very challenging to deploy and control dexterous robotic instruments to conduct surgical procedures endoscopically. Pioneering endoscopic surgical robots have already been introduced, but the performance is limited by the flexible neck of the robot that passes through the endoscope tool channel. In this article we present a series of new developments to improve the performance of the robot: a force transmission model to address flexibility, elongation study for precise position control, and tissue property modeling for haptic feedback. Validation experiment results are presented for each sector. An integrated control architecture of the robot system is given in the end.\"],\n",
    "[307,0,0,\"This paper is focused in the design and implementation of a robotic surgical motion controller. The proposed control scheme addresses the issues related to the application of a robot assistant in novel surgical scenario, which combines hand assisted laparoscopic surgery (HALS) with the single incision laparoscopic surgery (SILS) techniques. It is designed for collaborating with the surgeon in a natural way, by performing autonomous movements, in order to assist the surgeon during a surgical maneuver. In this way, it is implemented a hierarchical architecture which includes an upper auto-guide velocity planner connected to a low-level force feedback controller. The first one, based on a behavior approach, computes a collision free trajectory of the surgical instrument tip, held by the robot, for reaching a goal location inside of the abdominal cavity. On the other hand, the force feedback controller uses this trajectory for performing the instrument displacement by taking into account the holonomic movement constraints introduced by the fulcrum point. The aim of this controller is positioning the surgical instrument by minimizing the forces exerted over the abdominal wall due to the fulcrum location uncertainty. The overall system has been integrated in the control architecture of the surgical assistant CISOBOT, designed and developed at the University of Malaga. The whole architecture performance has been tested by means of in vitro trials.\"],\n",
    "[308,0,0,\"┬á Official architectural education in China remains very traditional and has yet to engage with the digital age. To counter this, Shanghai-based Fab-Union was set up in 2014 to establish a cross-disciplinary community - now over 10,000 strong - that is driving the emergence of digital crafts in the country. Here, its founder Philip Yuan and lead designer Hao Meng describe Fab-Union's online design platform, its offline collective design space, and its robotic factory that functions as an open research facility and fabrication workshop.; Official architectural education in China remains very traditional and has yet to engage with the digital age. To counter this, ShanghaiΓÇÉbased FabΓÇÉUnion was set up in 2014 to establish a crossΓÇÉdisciplinary community ΓÇô now over 10,000 strong ΓÇô that is driving the emergence of digital crafts in the country. Here, its founder Philip Yuan and lead designer Hao Meng describe FabΓÇÉUnion's online design platform, its offline collective design space, and its robotic factory that functions as an open research facility and fabrication workshop.; Official architectural education in China remains very traditional and has yet to engage with the digital age. To counter this, Shanghai-based Fab-Union was set up in 2014 to establish a cross-disciplinary community - now over 10,000 strong - that is driving the emergence of digital crafts in the country. Here, its founder Philip Yuan and lead designer Hao Meng describe Fab-Union's online design platform, its offline collective design space, and its robotic factory that functions as an open research facility and fabrication workshop. (Author abstract); 'Official architectural education in China remains very traditional and has yet to engage with the digital age. To counter this, Shanghai-based Fab-Union was set up in 2014 to establish a cross-disciplinary community -- now over 10,000 strong -- that is driving the emergence of digital crafts in the country. Here, its founder Philip Yuan and lead designer Hao Meng describe Fab-Union's online design platform, its offline collective design space, and its robotic factory that functions as an open research facility and fabrication workshop.'\"],\n",
    "[309,0,0,\"The well-developed and well-known robotic technology used for product adaptability and versatility has the potential to be applied to sculptures or three-dimensional (3-D) artifacts, leading to a new class of sculptures called dynamic sculpture. The promise of dynamic sculpture is to enable the sculpture to exhibit controlled motion. This article introduces the architecture, modeling, and implementation of dynamic sculpture.; ┬á The well-developed and well-known robotic technology used for product adaptability and versatility has the potential to be applied to sculptures or three-dimensional (3-D) artifacts, leading to a new class of sculptures called dynamic sculpture. The promise of dynamic sculpture is to enable the sculpture to exhibit controlled motion. This article introduces the architecture, modeling, and implementation of dynamic sculpture.\"],\n",
    "[310,0,0,\"While a consensus exists that advanced digital and mechatronic technology is on the cusp of profoundly impacting virtually every manufacturing and industry sector, there are some industries that seem to have profited far less from this ongoing ΓÇÿrevolutionΓÇÖ. One prominent example of this is the construction sector and, in particular, building construction. In this paper, we aim at discussing some of the reasons for this apparent lack, and some reasons why this might change in the near future. We introduce the problem of digital in situ fabrication as both a significant challenge and a huge opportunity. We support the discussion with an example of a robotically-fabricated digital concrete wall. Overall, we find that solving in situ fabrication constitutes an inherently multidisciplinary challenge.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1016/j.cemconres.2018.05.013 While a consensus exists that advanced digital and mechatronic technology is on the cusp of profoundly impacting virtually every manufacturing and industry sector, there are some industries that seem to have profited far less from this ongoing 'revolution'. One prominent example of this is the construction sector and, in particular, building construction. In this paper, we aim at discussing some of the reasons for this apparent lack, and some reasons why this might change in the near future. We introduce the problem of digital in situ fabrication as both a significant challenge and a huge opportunity. We support the discussion with an example of a robotically-fabricated digital concrete wall. Overall, we find that solving in situ fabrication constitutes an inherently multidisciplinary challenge.\"],\n",
    "[311,0,0,\"┬á This article proposes a more design-orientated making process with the emerging robotic technologies through the 'Intelligent Wave Project' (IWP).This research project went through three stages including physical experimentation, computational simulation, and the design & making of a robotic installation. The research process synthesises abstract geometries, Complex System Theory, 3D Print, and automatic control through computational protocols. The core objective of the IWP is to achieve a self-supporting surface mass from a simple rule-based component system that transforms its shape. The breakthrough of this robotic installation is that the identical cells that are repeatedly connected under the reciprocal frame principles and the triangulated geometry constraints are capable of generating emerging global reconfigurations of both the spatial structure and the intricate geometric pattern. The surface responds to different external forces accordingly, i.e. the location, the intensity and the sequence of the force. Such behaviour is scripted into the digital modelling before the realisation of the final programed structure. Instead of using dynamic pistons, the transformation is achieved through local sliding and rotating in particular sequences; these trigger the global surface transformation into either concave or convex. This article also compares the above research project with the concurrent experiments of robotic applications in architectural research. It embraces design intelligence for a more holistic perspective in order to explore the meaningful and applicable design opportunities for the future of architectural robotics.\"],\n",
    "[312,0,0,\"As software interfaces become more intuitive and require less technical expertise, the robotic arm is not only becoming a tool for automating bespoke construction, it is becoming a tool to help bring the concept of the 'Master Builder' back to the architectural profession. Being analogous to a human arm, it is easy to imagine limitless possibilities the robotic arm. However, understanding and utilizing it for the purpose of construction requires more knowledge than just imagining it as prosthetic. Besides a fundamental understanding of the digital workflow from the initial design based data (3D modelling) to machine understandable data (proprietary output code), it requires the design and conception of the robot's physical environment from the tool at the end of its arm (end effector) to its physical surroundings(work cell). Contemporary software tools provide the capabilities for manufacturing purposes and allow for virtual simulations of the production process, ensuring higher rates of success for construction. It is the crossover between the virtual environment and the physical world that will empower architects of the future to reclaim the title of master builders as they will be required to not only comprehend but design and participate in the entire building process inclusive of the manufacturing of components. This paper outlines a pedagogical framework to introduce the multi-layered levels of knowledge to students of architecture that will allow them to use a 6-axis robotic arm for the purpose of automated construction, making them aware of a new and complex building process that will be integral to redefining architecture in the near future.; As software interfaces become more intuitive and require less technical expertise, the robotic arm is not only becoming a tool for automating bespoke construction, it is becoming a tool to help bring the concept of the 'Master Builder' back to the architectural profession. Being analogous to a human arm, it is easy to imagine limitless possibilities the robotic arm. However, understanding and utilizing it for the purpose of construction requires more knowledge than just imagining it as prosthetic. Besides a fundamental understanding of the digital workflow from the initial design based data (3D modelling) to machine understandable data (proprietary output code), it requires the design and conception of the robot's physical environment from the tool at the end of its arm (end effector) to its physical surroundings(work cell). Contemporary software tools provide the capabilities for manufacturing purposes and allow for virtual simulations of the production process, ensuring higher rates of success for construction. It is the crossover between the virtual environment and the physical world that will empower architects of the future to reclaim the title of master builders as they will be required to not only comprehend but design and participate in the entire building process inclusive of the manufacturing of components. This paper outlines a pedagogical framework to introduce the multi-layered levels of knowledge to students of architecture that will allow them to use a 6-axis robotic arm for the purpose of automated construction, making them aware of a new and complex building process that will be integral to redefining architecture in the near future. (C) 2016 Published by Elsevier B.V.\"],\n",
    "[313,0,0,\"Research efforts for development of agricultural robots that can effectively perform tedious field tasks have grown significantly in the past decade. Agricultural robots are complex systems that require interdisciplinary collaborations between different research groups for effective task delivery in unstructured crops and plants environments. With the exception of milking robots, the extensive research works that have been carried out in the past two decades for adaptation of robotics in agriculture have not yielded a commercial product to date. To accelerate this pace, simulation approach and evaluation methods in virtual environments can provide an affordable and reliable framework for experimenting with different sensing and acting mechanisms in order to verify the performance functionality of the robot in dynamic scenarios. This paper reviews several professional simulators and custom-built virtual environments that have been used for agricultural robotic applications. The key features and performance efficiency of three selected simulators were also compared. A simulation case study was demonstrated to highlight some of the powerful functionalities of the Virtual Robot Experimentation Platform. Details of the objects and scenes were presented as the proof-of-concept for using a completely simulated robotic platform and sensing systems in a virtual citrus orchard. It was shown that the simulated workspace can provide a configurable and modular prototype robotic system that is capable of adapting to several field conditions and tasks through easy testing and debugging of control algorithms with zero damage risk to the real robot and to the actual equipment. This review suggests that an open-source software platform for agricultural robotics will significantly accelerate effective collaborations between different research groups for sharing existing workspaces, algorithms, and reusing the materials.\"],\n",
    "[314,0,0,\"Fueled by long-standing dreams of both material efficiency and aesthetic liberation, robots have become part of mainstream architectural discourses, raising the question: How may we nurture an ethos of visual, tactile, and spatial exploration in technologies that epitomize the legacies of industrial automationΓÇöfor example, the pursuit of managerial efficiency, control, and an ever-finer subdivision of labor? Reviewing and extending a growing body of research on architectural robotics pedagogy, and bridging a constructionist tradition of design education with recent studies of science and technology, this article offers both a conceptual framework and concrete strategies to incorporate robots into architectural design education in ways that foster a spirit of exploration and discovery, which is key to learning creative design. Through reflective accounts of three learning experiences, we introduce the notions ΓÇ£assisted automationΓÇ¥ and ΓÇ£robotic embodimentΓÇ¥ as devices to enrich current approaches to robotΓÇôhuman design, highlighting situated and embodied aspects of designing with robotic machines.\"],\n",
    "[315,0,0,\"Industrial robots are reliable machines for manufacturing tasks such as welding, panting, assembly, palletizing or kitting operations. They are traditionally programmed by an operator using a teach pendant in a point-to-point scheme with limited sensing capabilities such as industrial vision systems and force/torque sensing. The use of these sensing capabilities is associated to the particular robot controller, operative systems and programming language. Today, robots can react to environment changes specific to their task domain but are still unable to learn skills to effectively use their current knowledge. The need for such a skill in unstructured environments where knowledge can be acquired and enhanced is desirable so that robots can effectively interact in multimodal real-world scenarios.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1016/j.rcim.2014.08.013 Industrial robots are reliable machines for manufacturing tasks such as welding, panting, assembly, palletizing or kitting operations. They are traditionally programmed by an operator using a teach pendant in a point-to-point scheme with limited sensing capabilities such as industrial vision systems and force/torque sensing. The use of these sensing capabilities is associated to the particular robot controller, operative systems and programming language. Today, robots can react to environment changes specific to their task domain but are still unable to learn skills to effectively use their current knowledge. The need for such a skill in unstructured environments where knowledge can be acquired and enhanced is desirable so that robots can effectively interact in multimodal real-world scenarios. * Corresponding author: Tel.: +52 844 438 9600.; Industrial robots are reliable machines for manufacturing tasks such as welding, panting, assembly, palletizing or kitting operations. They are traditionally programmed by an operator using a teach pendant in a point-to-point scheme with limited sensing capabilities such as industrial vision systems and force/torque sensing. The use of these sensing capabilities is associated to the particular robot controller, operative systems and programming language. Today, robots can react to environment changes speci fic to their task domain but are still unable to learn skills to effectively use their current knowledge. The need for such a skill in unstructured environments where knowledge can be acquired and enhanced is desirable so that robots can effectively interact in multimodal real-world scenarios. In this article we present a multimodal assembly controller (MAC) approach to embed and effectively enhance knowledge into industrial robots working in multimodal manufacturing scenarios such as assembly during kitting operations with varying shapes and tolerances. During learning, the robot uses its vision and force capabilities resembling a human operator carrying out the same operation. The approach consists of using a MAC based on the Fuzzy ARTMAP artificial neural network in conjunction with a knowledge base. The robot starts the operation having limited initial knowledge about what task it has to accomplish. During the operation, the robot learns the skill for recognising assembly parts and how to assemble them. The skill acquisition is evaluated by counting the steps to complete the assembly, length of the followed assembly path and compliant behaviour. The performance improves with time so that the robot becomes an expert demonstrated by the assembly of a kit with different part geometries. The kit is unknown by the robot at the beginning of the operation; therefore, the kit type, location and orientation are unknown as well as the parts to be assembled since they are randomly fed by a conveyor belt.; Industrial robots are reliable machines for manufacturing tasks such as welding, panting, assembly, palletizing or kitting operations. They are traditionally programmed by an operator using a teach pendant in a point-to-point scheme with limited sensing capabilities such as industrial vision systems and force/torque sensing. The use of these sensing capabilities is associated to the particular robot controller, operative systems and programming language. Today, robots can react to environment changes specific to their task domain but are still unable to learn skills to effectively use their current knowledge. The need for such a skill in unstructured environments where knowledge can be acquired and enhanced is desirable so that robots can effectively interact in multimodal real-world scenarios. In this article we present a multimodal assembly controller (MAC) approach to embed and effectively enhance knowledge into industrial robots working in multimodal manufacturing scenarios such as assembly during kitting operations with varying shapes and tolerances. During learning, the robot uses its vision and force capabilities resembling a human operator carrying out the same operation. The approach consists of using a MAC based on the Fuzzy ARTMAP artificial neural network in conjunction with a knowledge base. The robot starts the operation having limited initial knowledge about what task it has to accomplish. During the operation, the robot learns the skill for recognising assembly parts and how to assemble them. The skill acquisition is evaluated by counting the steps to complete the assembly, length of the followed assembly path and compliant behaviour. The performance improves with time so that the robot becomes an expert demonstrated by the assembly of a kit with different part geometries. The kit is unknown by the robot at the beginning of the operation; therefore, the kit type, location and orientation are unknown as well as the parts to be assembled since they are randomly fed by a conveyor belt. (C) 2014 Elsevier Ltd. All rights reserved.; Industrial robots are reliable machines for manufacturing tasks such as welding, panting, assembly, palletizing or kitting operations. They are traditionally programmed by an operator using a teach pendant in a point-to-point scheme with limited sensing capabilities such as industrial vision systems and force/torque sensing. The use of these sensing capabilities is associated to the particular robot controller, operative systems and programming language. Today, robots can react to environment changes specific to their task domain but are still unable to learn skills to effectively use their current knowledge. The need for such a skill in unstructured environments where knowledge can be acquired and enhanced is desirable so that robots can effectively interact in multimodal real-world scenarios.In this article we present a multimodal assembly controller (MAC) approach to embed and effectively enhance knowledge into industrial robots working in multimodal manufacturing scenarios such as assembly during kitting operations with varying shapes and tolerances. During learning, the robot uses its vision and force capabilities resembling a human operator carrying out the same operation. The approach consists of using a MAC based on the Fuzzy ARTMAP artificial neural network in conjunction with a knowledge base. The robot starts the operation having limited initial knowledge about what task it has to accomplish. During the operation, the robot learns the skill for recognising assembly parts and how to assemble them. The skill acquisition is evaluated by counting the steps to complete the assembly, length of the followed assembly path and compliant behaviour. The performance improves with time so that the robot becomes an expert demonstrated by the assembly of a kit with different part geometries. The kit is unknown by the robot at the beginning of the operation; therefore, the kit type, location and orientation are unknown as well as the parts to be assembled since they are randomly fed by a conveyor belt.\"],\n",
    "[316,0,0,\"Video understanding of robot-assisted surgery (RAS) videos is an active research area. Modeling the gestures and skill level of surgeons presents an interesting problem. The insights drawn may be applied in effective skill acquisition, objective skill assessment, real-time feedback, and human-robot collaborative surgeries. We propose a solution to the tool detection and localization open problem in RAS video understanding, using a strictly computer vision approach and the recent advances of deep learning. We propose an architecture using multimodal convolutional neural networks for fast detection and localization of tools in RAS videos. To the best of our knowledge, this approach will be the first to incorporate deep neural networks for tool detection and localization in RAS videos. Our architecture applies a region proposal network (RPN) and a multimodal two stream convolutional network for object detection to jointly predict objectness and localization on a fusion of image and temporal motion cues. Our results with an average precision of 91% and a mean computation time of 0.1 s per test frame detection indicate that our study is superior to conventionally used methods for medical imaging while also emphasizing the benefits of using RPN for precision and efficiency. We also introduce a new data set, ATLAS Dione, for RAS video understanding. Our data set provides video data of ten surgeons from Roswell Park Cancer Institute, Buffalo, NY, USA, performing six different surgical tasks on the daVinci Surgical System (dVSS) with annotations of robotic tools per frame.\"],\n",
    "[317,0,0,\"Purpose: Demographic change has resulted in an increase of elderly people, while at the same time the number of active working people is falling. In the future, there will be less caretaking, which is necessary to support the aging population. In order to enable the aged population to live in dignity, they should be able to perform activities of daily living (ADLs) as independently as possible. The aim of this paper is to describe several solutions and concepts that can support elderly people in their ADLs in a way that allows them to stay self-sufficient for as long as possible. Method: To reach this goal, the Building Realization and Robotics Lab is researching in the field of ambient assisted living. The idea is to implement robots and sensors in the home environment so as to efficiently support the inhabitants in their ADLs and eventually increase their independence. Through embedding vital sensors into furniture and using ICT technologies, the health status of elderly people can be remotely evaluated by a physician or family members. By investigating ergonomic aspects specific to elderly people (e.g. via an age-simulation suit), it is possible to develop and test new concepts and novel applications, which will offer innovative solutions. Via the introduction of mechatronics and robotics, the home environment can be made able to seamlessly interact with the inhabitant through gestures, vocal commands, and visual recognition algorithms. Meanwhile, several solutions have been developed that address how to build a smart home environment in order to create an ambient assisted environment. This article describes how these concepts were developed. The approach for each concept, proposed in this article, was performed as follows: (1) research of needs, (2) creating definitions of requirements, (3) identification of necessary technology and processes, (4) building initial concepts, (5) experiments in a real environment, and (6) development of the final concepts. To keep these concepts cost-effective, the suggested solutions are modular. Therefore, it will be possible to straightforwardly install the proposed devices in an existing home environment in a ΓÇÿplug and play' manner once the terminals can be prefabricated off-site. Results and Discussion: This article shows a variety of concepts that have been developed to support elderly people in their ADLs. The prototypes of the proposed concepts in this paper have been tested with elderly people. The results of the tests show that robots embedded in furniture, walls, ceiling, etc. offer enhanced support, properly addressing elderly as well as disabled people to individually and independently manage their ADLs. In order to make the concepts realizable in terms of cost, it will be necessary to standardize and modularize these concepts for industrial fabrication.; Demographic change has resulted in an increase of elderly people, while at the same time the number of active working people is falling. In the future, there will be less caretaking, which is necessary to support the aging population. In order to enable the aged population to live in dignity, they should be able to perform activities of daily living (ADLs) as independently as possible. The aim of this paper is to describe several solutions and concepts that can support elderly people in their ADLs in a way that allows them to stay self-sufficient for as long as possible. To reach this goal, the Building Realization and Robotics Lab is researching in the field of ambient assisted living. The idea is to implement robots and sensors in the home environment so as to efficiently support the inhabitants in their ADLs and eventually increase their independence. Through embedding vital sensors into furniture and using ICT technologies, the health status of elderly people can be remotely evaluated by a physician or family members. By investigating ergonomic aspects specific to elderly people (e.g. via an age-simulation suit), it is possible to develop and test new concepts and novel applications, which will offer innovative solutions. Via the introduction of mechatronics and robotics, the home environment can be made able to seamlessly interact with the inhabitant through gestures, vocal commands, and visual recognition algorithms. Meanwhile, several solutions have been developed that address how to build a smart home environment in order to create an ambient assisted environment. This article describes how these concepts were developed. The approach for each concept, proposed in this article, was performed as follows: (1) research of needs, (2) creating definitions of requirements, (3) identification of necessary technology and processes, (4) building initial concepts, (5) experiments in a real environment, and (6) development of the final concepts. To keep these concepts cost-effective, the suggested solutions are modular. Therefore, it will be possible to straightforwardly install the proposed devices in an existing home environment in a 'plug and play' manner once the terminals can be prefabricated off-site. This article shows a variety of concepts that have been developed to support elderly people in their ADLs. The prototypes of the proposed concepts in this paper have been tested with elderly people. The results of the tests show that robots embedded in furniture, walls, ceiling, etc. offer enhanced support, properly addressing elderly as well as disabled people to individually and independently manage their ADLs. In order to make the concepts realizable in terms of cost, it will be necessary to standardize and modularize these concepts for industrial fabrication.; ┬á Purpose: Demographic change has resulted in an increase of elderly people, while at the same time the number of active working people is falling. In the future, there will be less caretaking, which is necessary to support the aging population. In order to enable the aged population to live in dignity, they should be able to perform activities of daily living (ADLs) as independently as possible. The aim of this paper is to describe several solutions and concepts that can support elderly people in their ADLs in a way that allows them to stay self-sufficient for as long as possible. Method: To reach this goal, the Building Realization and Robotics Lab is researching in the field of ambient assisted living. The idea is to implement robots and sensors in the home environment so as to efficiently support the inhabitants in their ADLs and eventually increase their independence. Through embedding vital sensors into furniture and using ICT technologies, the health status of elderly people can be remotely evaluated by a physician or family members. By investigating ergonomic aspects specific to elderly people (e.g. via an age-simulation suit), it is possible to develop and test new concepts and novel applications, which will offer innovative solutions. Via the introduction of mechatronics and robotics, the home environment can be made able to seamlessly interact with the inhabitant through gestures, vocal commands, and visual recognition algorithms. Meanwhile, several solutions have been developed that address how to build a smart home environment in order to create an ambient assisted environment. This article describes how these concepts were developed. The approach for each concept, proposed in this article, was performed as follows: (1) research of needs, (2) creating definitions of requirements, (3) identification of necessary technology and processes, (4) building initial concepts, (5) experiments in a real environment, and (6) development of the final concepts. To keep these concepts cost-effective, the suggested solutions are modular. Therefore, it will be possible to straightforwardly install the proposed devices in an existing home environment in a 'plug and play' manner once the terminals can be prefabricated off-site. Results and Discussion: This article shows a variety of concepts that have been developed to support elderly people in their ADLs. The prototypes of the proposed concepts in this paper have been tested with elderly people. The results of the tests show that robots embedded in furniture, walls, ceiling, etc. offer enhanced support, properly addressing elderly as well as disabled people to individually and independently manage their ADLs. In order to make the concepts realizable in terms of cost, it will be necessary to standardize and modularize these concepts for industrial fabrication. ┬⌐ 2014 S. Karger AG, Basel; Purpose: Demographic change has resulted in an increase of elderly people, while at the same time the number of active working people is falling. In the future, there will be less caretaking, which is necessary to support the aging population. In order to enable the aged population to live in dignity, they should be able to perform activities of daily living (ADLs) as independently as possible. The aim of this paper is to describe several solutions and concepts that can support elderly people in their ADLs in a way that allows them to stay self-sufficient for as long as possible. Method: To reach this goal, the Building Realization and Robotics Lab is researching in the field of ambient assisted living. The idea is to implement robots and sensors in the home environment so as to efficiently support the inhabitants in their ADLs and eventually increase their independence. Through embedding vital sensors into furniture and using ICT technologies, the health status of elderly people can be remotely evaluated by a physician or family members. By investigating ergonomic aspects specific to elderly people (e.g. via an age-simulation suit), it is possible to develop and test new concepts and novel applications, which will offer innovative solutions. Via the introduction of mechatronics and robotics, the home environment can be made able to seamlessly interact with the inhabitant through gestures, vocal commands, and visual recognition algorithms. Meanwhile, several solutions have been developed that address how to build a smart home environment in order to create an ambient assisted environment. This article describes how these concepts were developed. The approach for each concept, proposed in this article, was performed as follows: (1) research of needs, (2) creating definitions of requirements, (3) identification of necessary technology and processes, (4) building initial concepts, (5) experiments in a real environment, and (6) development of the final concepts. To keep these concepts costeffective, the suggested solutions are modular. Therefore, it will be possible to straightforwardly install the proposed devices in an existing home environment in a 'plug and play' manner once the terminals can be prefabricated off-site. Results and Discussion: This article shows a variety of concepts that have been developed to support elderly people in their ADLs. The prototypes of the proposed concepts in this paper have been tested with elderly people. The results of the tests show that robots embedded in furniture, walls, ceiling, etc. offer enhanced support, properly addressing elderly as well as disabled people to individually and independently manage their ADLs. In order to make the concepts realizable in terms of cost, it will be necessary to standardize and modularize these concepts for industrial fabrication. (C) 2014 S. Karger AG, Basel\"],\n",
    "[318,0,0,\"This paper reports on the development of a cross-domain framework for describing complex design practices. The framework is grounded in studies of two different complex design fields: Synthetic Biology and Swarm Robotics. In the first study, we interviewed practitioners in Synthetic Biology, identifying three essential aspects of complex design problems and practices. The first of these aspects is the characterisation of system complexity, the second is the design objective taken with respect to this complexity, and the third is the design approach applied to realise this objective. In the second study, we interviewed designers in Swarm Robotics, confirming the domain generality of the three aspects identified in the first study and permitting a comparison to be made of how the two fields differ from each other in these aspects. Considered together, the two studies provide the basis for building a cross-domain framework for describing complex design practices. Such a framework is presented here, not to exhaust all possible descriptions of complex design practice but rather to provide a structured yet adaptable way of highlighting the important aspects of these descriptions. Indeed, each aspect of complex design can be can be broken down into different elements depending on the design contexts under consideration. Having such a framework enables designers to identify fundamental similarities and differences both between and within fields.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1007/s00163-016-0219-2\"],\n",
    "[319,0,0,\"PURPOSE: Design a compact, ergonomic, and safe endoscope positioner dedicated to the sino-nasal tract, and the anterior and middle-stage skull base. METHODS: A motion and force analysis of the surgeon's movement was performed on cadaver heads to gather objective data for specification purposes. An experimental comparative study was then performed with three different kinematics, again on cadaver heads, in order to define the best architecture satisfying the motion and force requirements. RESULTS: We quantified the maximal forces applied on the endoscope when traversing the sino-nasal tract in order to evaluate the forces that the robot should be able to overcome. We also quantified the minimal forces that should not be exceeded in order to avoid damaging vital structures. We showed that the entrance point of the endoscope into the nostril could not be considered, as in laparoscopic surgery, as a fixed point but rather as a fixed region whose location and dimensions depend on the targeted sinus. CONCLUSION: From the safety and ergonomic points of view, the best solution would be a co-manipulated standard 6-degree of freedom robot to which is attached a gimbal-like passive remote manipulator holding the endoscope.\"],\n",
    "[320,0,0,\"We develop a novel platform based on a tele-operated robot to perform high-resolution optical coherence tomography (OCT) imaging under continuous large field-of-view magnetic resonance imaging (MRI) guidance. Intra-operative MRI (iMRI) is a promising guidance tool for high-precision surgery, but it may not have sufficient resolution or contrast to visualize certain small targets. To address these limitations, we develop an MRI-compatible OCT needle probe, which is capable of providing microscale tissue architecture in conjunction with macroscale MRI tissue morphology in real time. Coregistered MRI/OCT images on ex vivo chicken breast and human brain tissues demonstrate that the complementary imaging scales and contrast mechanisms have great potential to improve the efficiency and the accuracy of iMRI procedure.\"],\n",
    "[321,1,0,\"In this work, a basic cerebellar neural layer and a machine learning engine are embedded in a recurrent loop which avoids dealing with the motor error or distal error problem. The presented approach learns the motor control based on available sensor error estimates (position, velocity, and acceleration) without explicitly knowing the motor errors. The paper focuses on how to decompose the input into different components in order to facilitate the learning process using an automatic incremental learning model (locally weighted projection regression (LWPR) algorithm). LWPR incrementally learns the forward model of the robot arm and provides the cerebellar module with optimal pre-processed signals. We present a recurrent adaptive control architecture in which an adaptive feedback (AF) controller guarantees a precise, compliant, and stable control during the manipulation of objects. Therefore, this approach efficiently integrates a bio-inspired module (cerebellar circuitry) with a machine learning component (LWPR). The cerebellar-LWPR synergy makes the robot adaptable to changing conditions. We evaluate how this scheme scales for robot-arms of a high number of degrees of freedom (DOFs) using a simulated model of a robot arm of the new generation of light weight robots (LWRs).\"],\n",
    "[322,0,0,\"Hydroxyapatite/beta-tricalcium phosphate (HA/beta-TCP) composite scaffolds have shown great potential for bone-tissue engineering applications. In this work, ceramic scaffold with different HA/beta-TCP compositions (pure HA, 60HA/40beta-TCP, and 20HA/80beta-TCP) were fabricated by a robotic-assisted deposition (robocasting) technique using water-based hydrogel inks. A systematic study was conducted to investigate the porosity, mechanical property, and degradation of the scaffolds. Our results indicate that, at a similar volume porosity, the mechanical strength of the sintered scaffolds increased with the decreasing rod diameter. The compressive strength of the fabricated scaffolds (porosity approximately 25-80 vol %) varied between approximately 3 and approximately 50 MPa, a value equal or higher than that of human cancellous bone (2-12 MPa). Although there was a slight increase of Ca and P ions in water after 5 month, no noticeable degradation of the scaffolds in SBF or water was observed. Our findings from this work indicate that composite calcium phosphate scaffolds with customer-designed chemistry and architecture may be fabricated by a robotic-assisted deposition method.\"],\n",
    "[323,0,0,\"BACKGROUND: Many people with mobility impairments, who require the use of powered wheelchairs, have difficulty completing basic maneuvering tasks during their activities of daily living (ADL). In order to provide assistance to this population, robotic and intelligent system technologies have been used to design an intelligent powered wheelchair (IPW). This paper provides a comprehensive overview of the design and validation of the IPW. METHODS: The main contributions of this work are three-fold. First, we present a software architecture for robot navigation and control in constrained spaces. Second, we describe a decision-theoretic approach for achieving robust speech-based control of the intelligent wheelchair. Third, we present an evaluation protocol motivated by a meaningful clinical outcome, in the form of the Robotic Wheelchair Skills Test (RWST). This allows us to perform a thorough characterization of the performance and safety of the system, involving 17 test subjects (8 non-PW users, 9 regular PW users), 32 complete RWST sessions, 25 total hours of testing, and 9 kilometers of total running distance. RESULTS: User tests with the RWST show that the navigation architecture reduced collisions by more than 60% compared to other recent intelligent wheelchair platforms. On the tasks of the RWST, we measured an average decrease of 4% in performance score and 3% in safety score (not statistically significant), compared to the scores obtained with conventional driving model. This analysis was performed with regular users that had over 6 years of wheelchair driving experience, compared to approximately one half-hour of training with the autonomous mode. CONCLUSIONS: The platform tested in these experiments is among the most experimentally validated robotic wheelchairs in realistic contexts. The results establish that proficient powered wheelchair users can achieve the same level of performance with the intelligent command mode, as with the conventional command mode.\"],\n",
    "[324,0,0,\"BACKGROUND: This paper describes the development of a mobile base for the Personal Mobility and Manipulation Appliance Generation II (PerMMA Gen II robotic wheelchair), an obstacle-climbing wheelchair able to move in structured and unstructured environments, and to climb over curbs as high as 8 inches. The mechanical, electrical, and software systems of the mobile base are presented in detail, and similar devices such as the iBOT mobility system, TopChair, and 6X6 Explorer are described. FINDINGS: The mobile base of PerMMA Gen II has two operating modes: 'advanced driving mode' on flat and uneven terrain, and 'automatic climbing mode' during stair climbing. The different operating modes are triggered either by local and dynamic conditions or by external commands from users. A step-climbing sequence, up to 0.2 m, is under development and to be evaluated via simulation. The mathematical model of the mobile base is introduced. A feedback and a feed-forward controller have been developed to maintain the posture of the passenger when driving over uneven surfaces or slopes. The effectiveness of the controller has been evaluated by simulation using the open dynamics engine tool. CONCLUSION: Future work for PerMMA Gen II mobile base is implementation of the simulation and control on a real system and evaluation of the system via further experimental tests.\"],\n",
    "[325,0,0,\"OBJECTIVE: Fine touch sensing relies on peripheral-to-central neurotransmission of somesthetic percepts, as well as on active motion policies shaping tactile exploration. This paper presents a novel neuroengineering framework for robotic applications based on the multistage processing of fine tactile information in the closed action-perception loop. APPROACH: The integrated system modules focus on (i) neural coding principles of spatiotemporal spiking patterns at the periphery of the somatosensory pathway, (ii) probabilistic decoding mechanisms mediating cortical-like tactile recognition and (iii) decision-making and low-level motor adaptation underlying active touch sensing. We probed the resulting neural architecture through a Braille reading task. MAIN RESULTS: Our results on the peripheral encoding of primary contact features are consistent with experimental data on human slow-adapting type I mechanoreceptors. They also suggest second-order processing by cuneate neurons may resolve perceptual ambiguities, contributing to a fast and highly performing online discrimination of Braille inputs by a downstream probabilistic decoder. The implemented multilevel adaptive control provides robustness to motion inaccuracy, while making the number of finger accelerations covariate with Braille character complexity. The resulting modulation of fingertip kinematics is coherent with that observed in human Braille readers. SIGNIFICANCE: This work provides a basis for the design and implementation of modular neuromimetic systems for fine touch discrimination in robotics.\"],\n",
    "[326,0,0,\"Single port access surgery (SPAS) presents surgeons with added challenges that require new surgical tools and surgical assistance systems with unique capabilities. To address these challenges, we designed and constructed a new insertable robotic end-effectors platform (IREP) for SPAS. The IREP can be inserted through a O15 mm trocar into the abdomen and it uses 21 actuated joints for controlling two dexterous arms and a stereo-vision module. Each dexterous arm has a hybrid mechanical architecture comprised of a two-segment continuum robot, a parallelogram mechanism for improved dual-arm triangulation, and a distal wrist for improved dexterity during suturing. The IREP is unique because of the combination of continuum arms with active and passive segments with rigid parallel kinematics mechanisms. This paper presents the clinical motivation, design considerations, kinematics, statics, and mechanical design of the IREP. The kinematics of coordination between the parallelogram mechanisms and the continuum arms is presented using the pseudo-rigid-body model of the beam representing the passive segment of each snake arm. Kinematic and static simulations and preliminary experiment results are presented in support of our design choices.\"],\n",
    "[327,0,0,\"The bioinspired approach has been key in combining the disciplines of robotics with neuroscience in an effective and promising fashion. Indeed, certain aspects in the field of neuroscience, such as goal-directed locomotion and behaviour selection, can be validated through robotic artefacts. In particular, swimming is a functionally important behaviour where neuromuscular structures, neural control architecture and operation can be replicated artificially following models from biology and neuroscience. In this article, we present a biomimetic system inspired by the lamprey, an early vertebrate that locomotes using anguilliform swimming. The artefact possesses extra- and proprioceptive sensory receptors, muscle-like actuation, distributed embedded control and a vision system. Experiments on optimised swimming and on goal-directed locomotion are reported, as well as the assessment of the performance of the system, which shows high energy efficiency and adaptive behaviour. While the focus is on providing a robotic platform for testing biological models, the reported system can also be of major relevance for the development of engineering system applications.\"],\n",
    "[328,0,0,\"This paper reports the development of an MRI-Safe robot for direct (interventional) MRI-guided endorectal prostate biopsy. The robot is constructed of nonmagnetic and electrically nonconductive materials, and is electricity free, using pneumatic actuation and optical sensors. Targeting biopsy lesions of MRI abnormality presents substantial clinical potential for the management of prostate cancer. The paper describes MRI-Safe requirements, presents the kinematic architecture, design and construction of the robot, and a comprehensive set of preclinical tests for MRI compatibility and needle targeting accuracy. The robot has a compact and simple 3 degree-of-freedom (DoF) structure, two for orienting a needle-guide and one to preset the depth of needle insertion. The actual insertion is performed manually through the guide and up to the preset depth. To reduce the complexity and size of the robot next to the patient, the depth setting DoF is remote. Experimental results show that the robot is safe to use in any MRI environment (MRI-Safe). Comprehensive MRI tests show that the presence and motion of the robot in the MRI scanner cause virtually no image deterioration or signal to noise ratio (SNR) change. Robot's accuracy in bench test, CT-guided in-vitro, MRI-guided in-vitro and animal tests are 0.37mm, 1.10mm, 2.09mm, and 2.58mm respectively. These values are acceptable for clinical use.\"],\n",
    "[329,0,0,\"The main activity of social robots is to interact with people. In order to do that, the robot must be able to understand what the user is saying or doing. Typically, this capability consists of pre-programmed behaviors or is acquired through controlled learning processes, which are executed before the social interaction begins. This paper presents a software architecture that enables a robot to learn poses in a similar way as people do. That is, hearing its teacher's explanations and acquiring new knowledge in real time. The architecture leans on two main components: an RGB-D (Red-, Green-, Blue- Depth) -based visual system, which gathers the user examples, and an Automatic Speech Recognition (ASR) system, which processes the speech describing those examples. The robot is able to naturally learn the poses the teacher is showing to it by maintaining a natural interaction with the teacher. We evaluate our system with 24 users who teach the robot a predetermined set of poses. The experimental results show that, with a few training examples, the system reaches high accuracy and robustness. This method shows how to combine data from the visual and auditory systems for the acquisition of new knowledge in a natural manner. Such a natural way of training enables robots to learn from users, even if they are not experts in robotics.\"],\n",
    "[330,9,1,\"Along with superior performance, research indicates that expertise is associated with a number of mediating cognitive adaptations. To this extent, extensive practice is associated with the development of general and task-specific mental representations, which play an important role in the organization and control of action. Recently, new experimental methods have been developed, which allow for investigating the organization and structure of these representations, along with the functional structure of the movement kinematics. In the current article, we present a new approach for examining the overlap between skill representations and motor output. In doing so, we first present an architecture model, which addresses links between biomechanical and cognitive levels of motor control. Next, we review the state of the art in assessing memory structures underlying complex action. Following we present a new spatio-temporal decomposition method for illuminating the functional structure of movement kinematics, and finally, we apply these methods to investigate the overlap between the structure of motor representations in memory and their corresponding kinematic structures. Our aim is to understand the extent to which the output at a kinematic level is governed by representations at a cognitive level of motor control.\"],\n",
    "[331,1,0,\"Autonomy and self-improvement capabilities are still challenging in the fields of robotics and machine learning. Allowing a robot to autonomously navigate in wide and unknown environments not only requires a repertoire of robust strategies to cope with miscellaneous situations, but also needs mechanisms of self-assessment for guiding learning and for monitoring strategies. Monitoring strategies requires feedbacks on the behavior's quality, from a given fitness system in order to take correct decisions. In this work, we focus on how a second-order controller can be used to (1) manage behaviors according to the situation and (2) seek for human interactions to improve skills. Following an incremental and constructivist approach, we present a generic neural architecture, based on an on-line novelty detection algorithm that may be able to self-evaluate any sensory-motor strategies. This architecture learns contingencies between sensations and actions, giving the expected sensation from the previous perception. Prediction error, coming from surprising events, provides a measure of the quality of the underlying sensory-motor contingencies. We show how a simple second-order controller (emotional system) based on the prediction progress allows the system to regulate its behavior to solve complex navigation tasks and also succeeds in asking for help if it detects dead-lock situations. We propose that this model could be a key structure toward self-assessment and autonomy. We made several experiments that can account for such properties for two different strategies (road following and place cells based navigation) in different situations.\"],\n",
    "[332,0,0,\"This paper presents an enhanced haptic-enabled master-slave teleoperation system which can be used to provide force feedback to surgeons in minimally invasive surgery (MIS). One of the research goals was to develop a combined-control architecture framework that included both direct force reflection (DFR) and position-error-based (PEB) control strategies. To achieve this goal, it was essential to measure accurately the direct contact forces between deformable bodies and a robotic tool tip. To measure the forces at a surgical tool tip and enhance the performance of the teleoperation system, an optical force sensor was designed, prototyped, and added to a robot manipulator. The enhanced teleoperation architecture was formulated by developing mathematical models for the optical force sensor, the extended slave robot manipulator, and the combined-control strategy. Human factor studies were also conducted to (a) examine experimentally the performance of the enhanced teleoperation system with the optical force sensor, and (b) study human haptic perception during the identification of remote object deformability. The first experiment was carried out to discriminate deformability of objects when human subjects were in direct contact with deformable objects by means of a laparoscopic tool. The control parameters were then tuned based on the results of this experiment using a gain-scheduling method. The second experiment was conducted to study the effectiveness of the force feedback provided through the enhanced teleoperation system. The results show that the force feedback increased the ability of subjects to correctly identify materials of different deformable types. In addition, the virtual force feedback provided by the teleoperation system comes close to the real force feedback experienced in direct MIS. The experimental results provide design guidelines for choosing and validating the control architecture and the optical force sensor.\"],\n",
    "[333,0,0,\"Advances introduced by additive manufacturing have significantly improved the ability to tailor scaffold architecture, enhancing the control over microstructural features. This has led to a growing interest in the development of innovative scaffold designs, as testified by the increasing amount of research activities devoted to the understanding of the correlation between topological features of scaffolds and their resulting properties, in order to find architectures capable of optimal trade-off between often conflicting requirements (such as biological and mechanical ones). The main aim of this paper is to provide a review and propose a classification of existing methodologies for scaffold design and optimization in order to address key issues and help in deciphering the complex link between design criteria and resulting scaffold properties.\"],\n",
    "[334,0,0,\"The cyclic and often linear torque-angle relationship of locomotion presents the opportunity to innovate on the design of traditional series-elastic actuators (SEAs). In this paper, a novel modification to the SEA architecture was proposed by adding a clutch in parallel with the motor within the SEA--denoted as a CSEA. This addition permits bimodal dynamics where the system is characterized by an SEA when the clutch is disengaged and a passive spring when the clutch is engaged. The purpose of the parallel clutch was to provide the ability to store energy in a tuned series spring, while requiring only reactionary torque from the clutch. Thus, when the clutch is engaged, a tuned elastic relationship can be achieved with minimal electrical energy consumption. The state-based model of the CSEA is introduced and the implementation of the CSEA mechanism in a powered knee prosthesis is detailed. The series elasticity was optimized to fit the spring-like torque-angle relationship of early stance phase knee flexion and extension during level ground walking. In simulation, the CSEA knee required 70% less electrical energy than a traditional SEA. Future work will focus on the mechanical implementation of the CSEA knee and an empirical demonstration of reduced electrical energy consumption during walking.\"],\n",
    "[335,0,0,\"In this paper we present a complete spike-based architecture: from a Dynamic Vision Sensor (retina) to a stereo head robotic platform. The aim of this research is to reproduce intended movements performed by humans taking into account as many features as possible from the biological point of view. This paper fills the gap between current spike silicon sensors and robotic actuators by applying a spike processing strategy to the data flows in real time. The architecture is divided into layers: the retina, visual information processing, the trajectory generator layer which uses a neuroinspired algorithm (SVITE) that can be replicated into as many times as DoF the robot has; and finally the actuation layer to supply the spikes to the robot (using PFM). All the layers do their tasks in a spike-processing mode, and they communicate each other through the neuro-inspired AER protocol. The open-loop controller is implemented on FPGA using AER interfaces developed by RTC Lab. Experimental results reveal the viability of this spike-based controller. Two main advantages are: low hardware resources (2% of a Xilinx Spartan 6) and power requirements (3.4 W) to control a robot with a high number of DoF (up to 100 for a Xilinx Spartan 6). It also evidences the suitable use of AER as a communication protocol between processing and actuation.\"],\n",
    "[336,0,0,\"SUMMARY: In this work, we present a CUDA-based GPU implementation of a Poisson-Boltzmann equation solver, in both the linear and non-linear versions, using double precision. A finite difference scheme is adopted and made suitable for the GPU architecture. The resulting code was interfaced with the electrostatics software for biomolecules DelPhi, which is widely used in the computational biology community. The algorithm has been implemented using CUDA and tested over a few representative cases of biological interest. Details of the implementation and performance test results are illustrated. A speedup of ~10 times was achieved both in the linear and non-linear cases. AVAILABILITY AND IMPLEMENTATION: The module is open-source and available at http://www.electrostaticszone.eu/index.php/downloads.\"],\n",
    "[337,0,0,\"Many algorithms and methods in artificial intelligence or machine learning were inspired by human cognition. As a mechanism to handle the exploration-exploitation dilemma in reinforcement learning, the loosely symmetric (LS) value function that models causal intuition of humans was proposed (Shinohara et al., 2007). While LS shows the highest correlation with causal induction by humans, it has been reported that it effectively works in multi-armed bandit problems that form the simplest class of tasks representing the dilemma. However, the scope of application of LS was limited to the reinforcement learning problems that have K actions with only one state (K-armed bandit problems). This study proposes LS-Q learning architecture that can deal with general reinforcement learning tasks with multiple states and delayed reward. We tested the learning performance of the new architecture in giant-swing robot motion learning, where uncertainty and unknown-ness of the environment is huge. In the test, the help of ready-made internal models or functional approximation of the state space were not given. The simulations showed that while the ordinary Q-learning agent does not reach giant-swing motion because of stagnant loops (local optima with low rewards), LS-Q escapes such loops and acquires giant-swing. It is confirmed that the smaller number of states is, in other words, the more coarse-grained the division of states and the more incomplete the state observation is, the better LS-Q performs in comparison with Q-learning. We also showed that the high performance of LS-Q depends comparatively little on parameter tuning and learning time. This suggests that the proposed method inspired by human cognition works adaptively in real environments.\"],\n",
    "[338,0,0,\"The conventional analog-to-digital conversion (ADC) and digital signal processing (DSP) architecture has led to major advances in miniature and micro-systems technology over the past several decades. The outlook for these systems is significantly enhanced by advances in sensing, signal processing, communications and control, and the combination of these technologies enables autonomous robotics on the miniature to micro scales. In this article we look at trends in the combination of analog and digital (mixed-signal) processing, and consider a generalized sampling architecture. Employing a parallel analog basis expansion of the input signal, this scalable approach is adaptable and reconfigurable, and is suitable for a large variety of current and future applications in networking, perception, cognition, and control.\"],\n",
    "[339,0,0,\"While potentially powerful, access to molecular diagnostics is substantially limited in the developing world. Here we present an approach to reduced cost molecular diagnostic instrumentation that has the potential to empower developing world communities by reducing costs through streamlining the sample preparation process. In addition, this instrument is capable of producing its own consumable devices on demand, reducing reliance on assay suppliers. Furthermore, this instrument is designed with an 'open' architecture, allowing users to visually observe the assay process and make modifications as necessary (as opposed to traditional 'black box' systems). This open environment enables integration of microfluidic fabrication and viral RNA purification onto an easy-to-use modular system via the use of interchangeable trays. Here we employ this system to develop a protocol to fabricate microfluidic devices and then use these devices to isolate viral RNA from serum for the measurement of human immunodeficiency virus (HIV) viral load. Results obtained from this method show significantly reduced error compared with similar nonautomated sample preparation processes.\"],\n",
    "[340,0,0,\"Brain-machine interface (BMI) systems give users direct neural control of robotic, communication, or functional electrical stimulation systems. As BMI systems begin transitioning from laboratory settings into activities of daily living, an important goal is to develop neural decoding algorithms that can be calibrated with a minimal burden on the user, provide stable control for long periods of time, and can be responsive to fluctuations in the decoder's neural input space (e.g. neurons appearing or being lost amongst electrode recordings). These are significant challenges for static neural decoding algorithms that assume stationary input/output relationships. Here we use an actor-critic reinforcement learning architecture to provide an adaptive BMI controller that can successfully adapt to dramatic neural reorganizations, can maintain its performance over long time periods, and which does not require the user to produce specific kinetic or kinematic activities to calibrate the BMI. Two marmoset monkeys used the Reinforcement Learning BMI (RLBMI) to successfully control a robotic arm during a two-target reaching task. The RLBMI was initialized using random initial conditions, and it quickly learned to control the robot from brain states using only a binary evaluative feedback regarding whether previously chosen robot actions were good or bad. The RLBMI was able to maintain control over the system throughout sessions spanning multiple weeks. Furthermore, the RLBMI was able to quickly adapt and maintain control of the robot despite dramatic perturbations to the neural inputs, including a series of tests in which the neuron input space was deliberately halved or doubled.\"],\n",
    "[341,0,0,\"Modern computing architecture based on the separation of memory and processing leads to a well known problem called the von Neumann bottleneck, a restrictive limit on the data bandwidth between CPU and RAM. This paper introduces a new approach to computing we call AHaH computing where memory and processing are combined. The idea is based on the attractor dynamics of volatile dissipative electronics inspired by biological systems, presenting an attractive alternative architecture that is able to adapt, self-repair, and learn from interactions with the environment. We envision that both von Neumann and AHaH computing architectures will operate together on the same machine, but that the AHaH computing processor may reduce the power consumption and processing time for certain adaptive learning tasks by orders of magnitude. The paper begins by drawing a connection between the properties of volatility, thermodynamics, and Anti-Hebbian and Hebbian (AHaH) plasticity. We show how AHaH synaptic plasticity leads to attractor states that extract the independent components of applied data streams and how they form a computationally complete set of logic functions. After introducing a general memristive device model based on collections of metastable switches, we show how adaptive synaptic weights can be formed from differential pairs of incremental memristors. We also disclose how arrays of synaptic weights can be used to build a neural node circuit operating AHaH plasticity. By configuring the attractor states of the AHaH node in different ways, high level machine learning functions are demonstrated. This includes unsupervised clustering, supervised and unsupervised classification, complex signal prediction, unsupervised robotic actuation and combinatorial optimization of procedures-all key capabilities of biological nervous systems and modern machine learning algorithms with real world application.\"],\n",
    "[342,9,1,\"A set of modular components is presented for use in reconfigurable robotic construction systems. The set includes passive and active components. The passive components can be formed into static structures and adaptable grids carrying electrical power and signals. Passive and active components can be combined into general purpose mobile manipulators which are able to augment and reconfigure the grid, construct new manipulators, and potentially perform general purpose fabrication tasks such as additive manufacturing. The components themselves are designed for low-cost, simple fabrication methods and could potentially be fabricated by constructors made of the same components. This work represents a step toward a Cyclic Fabrication System, a network of materials, tools, and manufacturing processes that can produce all of its constituent components. These and similar systems have been proposed for a wide range of far-term applications, including space-based manufacturing, construction of large-scale industrial facilities, and also for driving development of low-cost 3D printing machines. (C) 2013 Elsevier B.V. All rights reserved.; A set of modular components is presented for use in reconfigurable robotic construction systems. The set includes passive and active components. The passive components can be formed into static structures and adaptable grids carrying electrical power and signals. Passive and active components can be combined into general purpose mobile manipulators which are able to augment and reconfigure the grid, construct new manipulators, and potentially perform general purpose fabrication tasks such as additive manufacturing. The components themselves are designed for low-cost, simple fabrication methods and could potentially be fabricated by constructors made of the same components. This work represents a step toward a Cyclic Fabrication System, a network of materials, tools, and manufacturing processes that can produce all of its constituent components. These and similar systems have been proposed for a wide range of far-term applications, including space-based manufacturing, construction of large-scale industrial facilities, and also for driving development of low-cost 3D printing machines. ┬⌐ 2013 Elsevier B.V. All rights reserved.; A set of modular components is presented for use in reconfigurable robotic construction systems. The set includes passive and active components. The passive components can be formed into static structures and adaptable grids carrying electrical power and signals. Passive and active components can be combined into general purpose mobile manipulators which are able to augment and reconfigure the grid, construct new manipulators, and potentially perform general purpose fabrication tasks such as additive manufacturing. The components themselves are designed for low-cost, simple fabrication methods and could potentially be fabricated by constructors made of the same components. This work represents a step toward a Cyclic Fabrication System, a network of materials, tools, and manufacturing processes that can produce all of its constituent components. These and similar systems have been proposed for a wide range of far-term applications, including space-based manufacturing, construction of large-scale industrial facilities, and also for driving development of low-cost 3D printing machines.\"],\n",
    "[343,0,0,\"Rapid-prototyping processes are being extended to increasingly large scales, including 3D printing from gantries, and robotic arms for cutting, milling and winding. These all use designs that are digital, but materials that are not: they are continuously deposited or removed. Neil Gershenfeld, Matthew Carney, Benjamin Jenett, Sam Calisch and Spencer Wilson of the MIT Center for Bits and Atoms explore the implications of the use of digital materials, reversibly assembled from a discrete set of parts with a discrete set of relative positions and orientations, for applications on scales ranging from aerostructures to geoprinting. Here, they discuss the production of the parts, the modelling of structures made with them, and their automated assembly.; ┬á Rapid-prototyping processes are being extended to increasingly large scales, including 3D printing from gantries, and robotic arms for cutting, milling and winding. These all use designs that are digital, but materials that are not: they are continuously deposited or removed. Neil Gershenfeld, Matthew Carney, Benjamin Jenett, Sam Calisch and Spencer Wilson of the MIT Center for Bits and Atoms explore the implications of the use of digital materials, reversibly assembled from a discrete set of parts with a discrete set of relative positions and orientations, for applications on scales ranging from aerostructures to geoprinting. Here, they discuss the production of the parts, the modelling of structures made with them, and their automated assembly.; 'Rapid-prototyping processes are being extended to increasingly large scales, including 3D printing from gantries, and robotic arms for cutting, milling and winding. These all use designs that are digital, but materials that are not: they are continuously deposited or removed. Neil Gershenfeld, Matthew Carney, Benjamin Jenett, Sam Calisch and Spencer Wilson of the MIT Center for Bits and Atoms explore the implications of the use of digital materials, reversibly assembled from a discrete set of parts with a discrete set of relative positions and orientations, for applications on scales ranging from aerostructures to geoprinting. Here, they discuss the production of the parts, the modelling of structures made with them, and their automated assembly.'\"],\n",
    "[344,0,0,\"To fully exploit Digital Fabrication within architecture, robotic fabrication must be expanded in prefabrication, but also fully implemented directly on construction sites. Focus of featured projects is on how to bring robots directly to the construction site and autonomously fabricate structures beyond factory conditions.\"],\n",
    "[345,0,0,\"Departing from the conventional view of the reasons for the behavior of living systems, this research presents a radical and unique view of that behavior, as the observed side effects of a hierarchical set of simple, continuous, and dynamic negative feedback control systems, by way of an experimental model implemented on a real-world autonomous robotic rover. Rather than generating specific output from input, the systems control their perceptual inputs by varying output. The variables controlled do not exist in the environment, but are entirely internal perceptions constructed as a result of the layout and connections of the neural architecture. As the underlying processes are independent of the domain, the architecture is universal and thus has significant implications not only for understanding natural living systems, but also for the development of robotics systems. The central process of perceptual control has the potential to unify the behavioral sciences and is proposed as the missing behavioral principle of Artificial Life.\"],\n",
    "[346,0,0,\"In this paper, a new robotic architecture for plant phenotyping is being introduced. The architecture consists of two robotic platforms: an autonomous ground vehicle (Vinobot) and a mobile observation tower (Vinoculer). The ground vehicle collects data from individual plants, while the observation tower oversees an entire field, identifying specific plants for further inspection by the Vinobot. The advantage of this architecture is threefold: first, it allows the system to inspect large areas of a field at any time, during the day and night, while identifying specific regions affected by biotic and/or abiotic stresses; second, it provides high-throughput plant phenotyping in the field by either comprehensive or selective acquisition of accurate and detailed data from groups or individual plants; and third, it eliminates the need for expensive and cumbersome aerial vehicles or similarly expensive and confined field platforms. As the preliminary results from our algorithms for data collection and 3D image processing, as well as the data analysis and comparison with phenotype data collected by hand demonstrate, the proposed architecture is cost effective, reliable, versatile, and extendable.; ┬á In this paper, a new robotic architecture for plant phenotyping is being introduced. The architecture consists of two robotic platforms: an autonomous ground vehicle (Vinobot) and a mobile observation tower (Vinoculer). The ground vehicle collects data from individual plants, while the observation tower oversees an entire field, identifying specific plants for further inspection by the Vinobot. The advantage of this architecture is threefold: first, it allows the system to inspect large areas of a field at any time, during the day and night, while identifying specific regions affected by biotic and/or abiotic stresses; second, it provides high-throughput plant phenotyping in the field by either comprehensive or selective acquisition of accurate and detailed data from groups or individual plants; and third, it eliminates the need for expensive and cumbersome aerial vehicles or similarly expensive and confined field platforms. As the preliminary results from our algorithms for data collection and 3D image processing, as well as the data analysis and comparison with phenotype data collected by hand demonstrate, the proposed architecture is cost effective, reliable, versatile, and extendable.\"],\n",
    "[347,0,0,\"┬⌐ 2014 WILEY-VCH Verlag GmbH and Co. KGaA, Weinheim. This paper is on the design, fabrication, and testing of skins and sleeves for soft robotics with the focus on the mechanical features of the microstructure of these skins, drawing inspiration from nature and architecture. Biological inspirations drawn from animals are used for designing skin membranes or skin structures for soft robotic actuators, in particular pneumatic actuators that protect, guide, and contribute to the development of the actuated shape. The results presented in this paper will be a new step toward advancing the state-of-the-art of biologically inspired soft robots for minimally invasive surgery. Inspirations from architecture are of particular interest in the areas of formability of design and continuous flow. The report presents a trade-off study using various skin and sleeve technologies of innovative fiber structures and combinations of different materials in different innovative designs, surrounding a pneumatically actuated, soft robot of variable stiffness.; The image shows pneumatically actuated soft robot arms with skins inspired from nature and architecture: a crimped, braided sleeve inspired from an elephant trunk, and an internal dragonskin inspired from a Dragon Pavilion design. The microstructure of such skins and sleeves makes them able to guide and follow the arm deformation, restrict ballooning and stiffen the arm upon actuation.; This paper is on the design, fabrication, and testing of skins and sleeves for soft robotics with the focus on the mechanical features of the microstructure of these skins, drawing inspiration from nature and architecture. Biological inspirations drawn from animals are used for designing skin membranes or skin structures for soft robotic actuators, in particular pneumatic actuators that protect, guide, and contribute to the development of the actuated shape. The results presented in this paper will be a new step toward advancing the state-of-the-art of biologically inspired soft robots for minimally invasive surgery. Inspirations from architecture are of particular interest in the areas of formability of design and continuous flow. The report presents a trade-off study using various skin and sleeve technologies of innovative fiber structures and combinations of different materials in different innovative designs, surrounding a pneumatically actuated, soft robot of variable stiffness.\"],\n",
    "[348,0,0,\"This article presents a new hybrid motion (HM) planner, designed to allow robust indoor navigation in constrained environments of nonholonomic differential robots, such as RobChair, the brain-actuated robotic wheelchair [1] from the Institute of Systems and Robotics, University of Coimbra, Portugal. Relying on this new planning algorithm, RobChair is now able to operate in real dynamic environments and perform challenging maneuvers in narrow spaces. The HM planner integrates deliberative and reactive modules in a three-layer structure: a fast threedimensional (3-D)-global path planner, smoothing, and a new reactive local planner designated the doubledynamic window approach (D-DWA). The 3-D-global path planner consists in the A) algorithm, which defines a path composed by a sequence of (x, y) points, with an interpolation module that has the purpose of assigning an orientation to each (x, y) point. The smoothing algorithm adjusts the (x, y) points to reduce accelerations and jerk associated with the trajectory. The D-DWA is in charge of dynamically adapting the robot motion, taking into account the robot geometry (noncircular robot) and local static/dynamic obstacles, unknown from the global planner perspective. Real-time navigation is achieved because both the smoothing and the D-DWA algorithms are iteratively executed during navigation. The use of multiresolution local grid maps also contributes to the increase of computation performance. To show the effectiveness of the proposed planning algorithm, results of real navigation experiments are reported in this article. The experiments consist in steering RobChair in a real office-like scenario by different participants, using a selfpaced P300-based brain-computer interface (BCI).; This article presents a new hybrid motion (HM) planner, designed to allow robust indoor navigation in constrained environments of nonholonomic differential robots, such as RobChair, the brain-actuated robotic wheelchair from the Institute of Systems and Robotics, University of Coimbra, Portugal. Relying on this new planning algorithm, RobChair is now able to operate in real dynamic environments and perform challenging maneuvers in narrow spaces. The HM planner integrates deliberative and reactive modules in a three-layer structure: a fast three-dimensional (3-D)-global path planner, smoothing, and a new reactive local planner designated the double-dynamic window approach (D-DWA). The 3-D-global path planner consists in the A* algorithm, which defines a path composed by a sequence of (x, y) points, with an interpolation module that has the purpose of assigning an orientation to each (x, y) point. The smoothing algorithm adjusts the (x, y) points to reduce accelerations and jerk associated with the trajectory. The D-DWA is in charge of dynamically adapting the robot motion, taking into account the robot geometry (noncircular robot) and local static/dynamic obstacles, unknown from the global planner perspective. Real-time navigation is achieved because both the smoothing and the D-DWA algorithms are iteratively executed during navigation. The use of multiresolution local grid maps also contributes to the increase of computation performance. To show the effectiveness of the proposed planning algorithm, results of real navigation experiments are reported in this article. The experiments consist in steering RobChair in a real office-like scenario by different participants, using a self-paced P300-based brain-computer interface (BCI).\"],\n",
    "[349,0,0,\"In the era of advanced, intelligent, and flexible manufacturing, machining with industrial robots, it is expected to be set up in the next few years. This is due to the vast progress of these robots in terms of precision and stiffness. Moreover, there is a recent development of off-line programming. Consequently, industrial robots offer a real gain of modularity, flexibility, and access for machining on production lines, and are viable solutions to improve the productivity. At the same time, all the potentials of CAD/CAM solutions available for machining off-line programming are not fully exploited because of old G-code (ISO 6963, 1980) language that only enables the description of elementary actions and tools moves. In the context of Industry 4.0 and the development of smart equipments at all levels of production chain, the manufacturing digital thread has to be profoundly reconsidered in order to guarantee high-level information from the design to the manufacturing. In this paper, a solution is proposed based on the high-level programming STEP-NC standard combined with a suitable CAD/CAM solution for industrial robots machining. A complete platform has been developed to enable advanced and intelligent manufacturing with the possibility to integrate several modules of simulation, optimization, and visualization, as well as in-process fabrication adaptation, cloud manufacturing, and machine learning with database analytics.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1007/s00170-017-1466-8\"],\n",
    "[350,0,0,\"Gaze control requires the coordination of movements of both eyes and head to fixate on a target. We present a biologically constrained architecture for gaze control and show how the relationships between the coupled sensorimotor systems can be learnt autonomously from scratch, allowing for adaptation as the system grows or changes. Infant studies suggest developmental learning strategies, which can be applied to sensorimotor learning in humanoid robots. We examine two strategies (sequential and synchronous) for the learning of eye and head coupled mappings, and give results from implementations on an iCub robot. The results show that the developmental approach can give fast, cumulative, on-line learning of coupled sensorimotor systems.; ┬á Gaze control requires the coordination of movements of both eyes and head to fixate on a target. We present a biologically constrained architecture for gaze control and show how the relationships between the coupled sensorimotor systems can be learnt autonomously from scratch, allowing for adaptation as the system grows or changes. Infant studies suggest developmental learning strategies, which can be applied to sensorimotor learning in humanoid robots. We examine two strategies (sequential and synchronous) for the learning of eye and head coupled mappings, and give results from implementations on an iCub robot. The results show that the developmental approach can give fast, cumulative, on-line learning of coupled sensorimotor systems.[PUBLICATION ABSTRACT]\"],\n",
    "[351,0,0,\"Robotic telepresence is an emerging technology with a great potential in applications such as elder assistance, telework, and surveillance. It relies on a combination of information and communication technologies and mobile robotics to provide a person with autonomy to move and interact in a remote environment. The application environments range from homes to factories, even large outdoor spaces, and the type of users involved in particular application contexts is also varied. That leads to a great heterogeneity in the design of the robotic platforms, communication infrastructures, and interfaces found across robotic telepresence applications. This article analyzes the sources of such heterogeneity, defines a modular architecture that provides a suitable solution for generic applications, and presents an instantiation of the architecture into a web-based solution for robotic telepresence. The main advantages of the solution presented are its open-source nature and its cross-platform compatibility. We report a pilot experience that shows how a functional robotic telepresence system based on this solution has been successfully deployed in an office environment and intensively tested by inexperienced participants over the Internet.\"],\n",
    "[352,0,0,\"Human-Robot Interaction challenges Artificial Intelligence in many regards: dynamic, partially unknown environments that were not originally designed for robots; a broad variety of situations with rich semantics to understand and interpret; physical interactions with humans that requires fine, low-latency yet socially acceptable control strategies ; natural and multi-modal communication which mandates common-sense knowledge and the representation of possibly divergent mental models. This article is an attempt to characterise these challenges and to exhibit a set of key decisional issues that need to be addressed for a cognitive robot to successfully share space and tasks with a human. We identify first the needed individual and collaborative cognitive skills: geometric reasoning and situation assessment based on perspective-taking and affordance analysis; acquisition and representation of knowledge models for multiple agents (humans and robots, with their specificities); situated, natural and multi-modal dialogue; human-aware task planning; human-robot joint task achievement. The article discusses each of these abilities, presents working implementations , and shows how they combine in a coherent and original deliberative architecture for human-robot interaction. Supported by experimental results, we eventually show how explicit knowledge management, both symbolic and geometric, proves to be instrumental to richer and more natural human-robot interactions by pushing for pervasive, human-level semantics within the robot's deliberative system; Human-Robot Interaction challenges Artificial Intelligence in many regards: dynamic, partially unknown environments that were not originally designed for robots; a broad variety of situations with rich semantics to understand and interpret; physical interactions with humans that requires fine, low-latency yet socially acceptable control strategies; natural and multi-modal communication which mandates common-sense knowledge and the representation of possibly divergent mental models. This article is an attempt to characterise these challenges and to exhibit a set of key decisional issues that need to be addressed for a cognitive robot to successfully share space and tasks with a human. We identify first the needed individual and collaborative cognitive skills: geometric reasoning and situation assessment based on perspective-taking and affordance analysis; acquisition and representation of knowledge models for multiple agents (humans and robots, with their specificities); situated, natural and multi-modal dialogue; human-aware task planning; human-robot joint task achievement The article discusses each of these abilities, presents working implementations, and shows how they combine in a coherent and original deliberative architecture for human-robot interaction. Supported by experimental results, we eventually show how explicit knowledge management, both symbolic and geometric, proves to be instrumental to richer and more natural human-robot interactions by pushing for pervasive, human-level semantics within the robot's deliberative system.; Human-Robot Interaction challenges Artificial Intelligence in many regards: dynamic, partially unknown environments that were not originally designed for robots; a broad variety of situations with rich semantics to understand and interpret; physical interactions with humans that requires fine, low-latency yet socially acceptable control strategies; natural and multi-modal communication which mandates common-sense knowledge and the representation of possibly divergent mental models. This article is an attempt to characterise these challenges and to exhibit a set of key decisional issues that need to be addressed for a cognitive robot to successfully share space and tasks with a human.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1016/j.artint.2016.07.002 Human--Robot Interaction challenges Artificial Intelligence in many regards: dynamic, partially unknown environments that were not originally designed for robots; a broad variety of situations with rich semantics to understand and interpret; physical interactions with humans that requires fine, low-latency yet socially acceptable control strategies; natural and multi-modal communication which mandates common-sense knowledge and the representation of possibly divergent mental models. This article is an attempt to characterise these challenges and to exhibit a set of key decisional issues that need to be addressed for a cognitive robot to successfully share space and tasks with a human.; Human-Robot Interaction challenges Artificial Intelligence in many regards: dynamic, partially unknown environments that were not originally designed for robots; a broad variety of situations with rich semantics to understand and interpret; physical interactions with humans that requires fine, low-latency yet socially acceptable control strategies; natural and multi-modal communication which mandates common-sense knowledge and the representation of possibly divergent mental models. This article is an attempt to characterise these challenges and to exhibit a set of key decisional issues that need to be addressed for a cognitive robot to successfully share space and tasks with a human. We identify first the needed individual and collaborative cognitive skills: geometric reasoning and situation assessment based on perspective-taking and affordance analysis; acquisition and representation of knowledge models for multiple agents (humans and robots, with their specificities); situated, natural and multi-modal dialogue; human aware task planning; human-robot joint task achievement. The article discusses each of these abilities, presents working implementations, and shows how they combine in a coherent and original deliberative architecture for human-robot interaction. Supported by experimental results, we eventually show how explicit knowledge management, both symbolic and geometric, proves to be instrumental to richer and more natural human robot interactions by pushing for pervasive, human-level semantics within the robot's deliberative system. (C) 2017 The Authors. Published by Elsevier B.V.\"],\n",
    "[353,9,1,\"This paper presents a state machine-based architecture, which enhances the flexibility and reusability of industrial robots, more concretely dual-arm multisensor robots. The proposed architecture, in addition to allowing absolute control of the execution, eases the programming of new applications by increasing the reusability of the developed modules. Through an easy-to-use graphical user interface, operators are able to create, modify, reuse and maintain industrial processes, increasing the flexibility of the cell. Moreover, the proposed approach is applied in a real use case in order to demonstrate its capabilities and feasibility in industrial environments. A comparative analysis is presented for evaluating the presented approach versus traditional robot programming techniques.\"],\n",
    "[354,5,0,\"Service robots have the potential of improving the quality of life and assist with peopleΓÇÖs daily activities. Such robots must be capable of operating over long periods of time, performing multiple tasks, and scheduling them appropriately for execution. In addition, service robots must be capable of dealing with tasks whose goals may be in conflict with each other and would need to determine, dynamically, which task to pursue in such a case. Adding to the complexity of the problem is the fact that some task requests may have time constraintsΓÇödeadlines by which the task has to be completed. Given the dynamic nature of the environment, the robots must make decisions on what tasks to pursue in situations where there could be incomplete or missing information. The robots should also be capable of accepting requests for new tasks or services at runtime, while possibly working on another task. In order to achieve these requirements, this paper presents the Auction Behavior-Based Robotic Architecture that brings the following contributions: (1) it uses an auction mechanism to determine the relevance of a task to run at any given time, (2) it handles multiple user requests while dealing with potentially critical time constraints and incomplete information, (3) it enables long-term robot operation and (4) it allows for dynamic assignment of new tasks. The proposed system is validated on a physical robotic platform, the Segway RMP $$^{\\circledR }$$ ┬« and in simulation.; Service robots have the potential of improving the quality of life and assist with people's daily activities. Such robots must be capable of operating over long periods of time, performing multiple tasks, and scheduling them appropriately for execution. In addition, service robots must be capable of dealing with tasks whose goals may be in conflict with each other and would need to determine, dynamically, which task to pursue in such a case. Adding to the complexity of the problem is the fact that some task requests may have time constraints-deadlines by which the task has to be completed. Given the dynamic nature of the environment, the robots must make decisions on what tasks to pursue in situations where there could be incomplete or missing information. The robots should also be capable of accepting requests for new tasks or services at runtime, while possibly working on another task. In order to achieve these requirements, this paper presents the Auction Behavior-Based Robotic Architecture that brings the following contributions: (1) it uses an auction mechanism to determine the relevance of a task to run at any given time, (2) it handles multiple user requests while dealing with potentially critical time constraints and incomplete information, (3) it enables long-term robot operation and (4) it allows for dynamic assignment of new tasks. The proposed system is validated on a physical robotic platform, the Segway RMP (R) and in simulation.\"],\n",
    "[355,0,0,\"Purpose - This article aims to provide a brief overview of the field now known as 'evolutionary developmental robotics (evo-devo-robo)', which is based on the concept and principles of evolutionary and development principles such as evolutionary developmental psychology, evolutionary developmental biology (evo-devo) and evolutionary cognitive neuroscience. Design/methodology/approach - Evo-devo-robo is a new field bringing together developmental robotics and evolutionary robotics to form a new research area. Basic concepts and the origins of the field are described, and then some basic principles of evo-devo-robo that have been developed so far are discussed. Findings - Finally, some misunderstand concepts and the most promising future research developments in this area are discussed. Originality/value - Basic concepts and the origins of the field are described, and then some basic principles of evo-devo-robo that have been developed so far are discussed. Finally, some misunderstood concepts and the most promising future research developments in this area are discussed.; ┬á Purpose - This article aims to provide a brief overview of the field now known as 'evolutionary developmental robotics (evo-devo-robo)', which is based on the concept and principles of evolutionary and development principles such as evolutionary developmental psychology, evolutionary developmental biology (evo-devo) and evolutionary cognitive neuroscience. Design/methodology/approach - Evo-devo-robo is a new field bringing together developmental robotics and evolutionary robotics to form a new research area. Basic concepts and the origins of the field are described, and then some basic principles of evo-devo-robo that have been developed so far are discussed. Findings - Finally, some misunderstand concepts and the most promising future research developments in this area are discussed. Originality/value - Basic concepts and the origins of the field are described, and then some basic principles of evo-devo-robo that have been developed so far are discussed. Finally, some misunderstood concepts and the most promising future research developments in this area are discussed.\"],\n",
    "[356,0,0,\"Sorghum (Sorghum bicolor) is known as a major feedstock for biofuel production. To improve its biomass yield through genetic research, manually measuring yield component traits (e.g. plant height, stem diameter, leaf angle, leaf area, leaf number, and panicle size) in the field is the current best practice. However, such laborious and timeΓÇÉconsuming tasks have become a bottleneck limiting experiment scale and data acquisition frequency. This paper presents a highΓÇÉthroughput fieldΓÇÉbased robotic phenotyping system which performed sideΓÇÉview stereo imaging for dense sorghum plants with a wide range of plant heights throughout the growing season. Our study demonstrated the suitability of stereo vision for fieldΓÇÉbased threeΓÇÉdimensional plant phenotyping when recent advances in stereo matching algorithms were incorporated. A robust data processing pipeline was developed to quantify the variations or morphological traits in plant architecture, which included plotΓÇÉbased plant height, plotΓÇÉbased plant width, convex hull volume, plant surface area, and stem diameter (semiautomated). These imageΓÇÉderived measurements were highly repeatable and showed high correlations with the inΓÇÉfield manual measurements. Meanwhile, manually collecting the same traits required a large amount of manpower and time compared to the robotic system. The results demonstrated that the proposed system could be a promising tool for largeΓÇÉscale fieldΓÇÉbased highΓÇÉthroughput plant phenotyping of bioenergy crops.\"],\n",
    "[357,0,0,\"The Internet of Robotic Things is an emerging vision that brings together pervasive sensors and objects with robotic and autonomous systems. This survey examines how the merger of robotic and Internet of Things technologies will advance the abilities of both the current Internet of Things and the current robotic systems, thus enabling the creation of new, potentially disruptive services. We discuss some of the new technological challenges created by this merger and conclude that a truly holistic view is needed but currently lacking.\"],\n",
    "[358,9,1,\"* A standard model captures a community consensus over a coherent region of science, serving as a cumulative reference point for the field that can provide guidance for both research and applications, while also focusing efforts to extend or revise it. Here we propose developing such a model for humanlike minds, computational entities whose structures and processes are substantially similar to those found in human cognition. Our hypothesis is that cognitive architectures provide the appropriate computational abstraction for defining a standard model, although the standard model is not itself such an architecture. The proposed standard model began as an initial consensus at the 2013 AAAI Fall Symposium on Integrated Cognition, but is extended here through a synthesis across three existing cognitive architectures: ACT-R, Sigma, and Soar. The resulting standard model spans key aspects of structure and processing, memory and content, learning, and perception and motor, and highlights loci of architectural agreement as well as disagreement with the consensus while identifying potential areas of remaining incompleteness. The hope is that this work will provide an important step toward engaging the broader community in further development of the standard model of the mind.; A standard model captures a community consensus over a coherent region of science, serving as a cumulative reference point for the field that can provide guidance for both research and applications, while also focusing efforts to extend or revise it. Here we propose developing such a model for humanlike minds, computational entities whose structures and processes are substantially similar to those found in human cognition. Our hypothesis is that cognitive architectures provide the appropriate computational abstraction for defining a standard model, although the standard model is not itself such an architecture. The proposed standard model began as an initial consensus at the 2013 AAAI Fall Symposium on Integrated Cognition, but is extended here through a synthesis across three existing cognitive architectures: ACT-R, Sigma, and Soar. The resulting standard model spans key aspects of structure and processing, memory and content, learning, and perception and motor, and highlights loci of architectural agreement as well as disagreement with the consensus while identifying potential areas of remaining incompleteness. The hope is that this work will provide an important step toward engaging the broader community in further development of the standard model of the mind.\"],\n",
    "[359,0,0,\"To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1016/j.robot.2015.06.010 Human muscles contrast sharply with traditional robot actuators in that they consist of several motor units, connected in series and parallel, which can be progressively recruited. Some roboticists have explored this idea in robotic actuators, striving for improvements such as the ability to withstand partial damage, inexpensive repeatability by discrete open loop control and the potential of modular actuators. These systems, however, become rather complex or rely on less widely used actuation techniques such as piezo-actuators or SMAs to produce a compact implementation. This paper presents a novel design of a modular redundant actuation unit which can be combined in various combinations to form compliant actuators with varying characteristics. The actuation unit consists of discretely activated solenoids with an integrated compliant coupling. This paper presents the working principle and the physical implementation in detail. Failure of a single motor unit will merely lead to a loss in performance rather than failure of the actuator. Since each motor unit is discrete, neither power electronics nor control requires analog signals. Isometric experiments display the actuation characteristics and demonstrate the repeatability. The platform can be used in future work to further explore the virtues of exploiting discretization and redundancy in muscle-like control.; Human muscles contrast sharply with traditional robot actuators in that they consist of several motor units, connected in series and parallel, which can be progressively recruited. Some roboticists have explored this idea in robotic actuators, striving for improvements such as the ability to withstand partial damage, inexpensive repeatability by discrete open loop control and the potential of modular actuators. These systems, however, become rather complex or rely on less widely used actuation techniques such as piezo-actuators or SMAs to produce a compact implementation. This paper presents a novel design of a modular redundant actuation unit which can be combined in various combinations to form compliant actuators with varying characteristics. The actuation unit consists of discretely activated solenoids with an integrated compliant coupling. This paper presents the working principle and the physical implementation in detail. Failure of a single motor unit will merely lead to a loss in performance rather than failure of the actuator. Since each motor unit is discrete, neither power electronics nor control requires analog signals. Isometric experiments display the actuation characteristics and demonstrate the repeatability. The platform can be used in future work to further explore the virtues of exploiting discretization and redundancy in muscle-like control. (C) 2015 Elsevier B.V. All rights reserved.; Human muscles contrast sharply with traditional robot actuators in that they consist of several motor units, connected in series and parallel, which can be progressively recruited. Some roboticists have explored this idea in robotic actuators, striving for improvements such as the ability to withstand partial damage, inexpensive repeatability by discrete open loop control and the potential of modular actuators. These systems, however, become rather complex or rely on less widely used actuation techniques such as piezo-actuators or SMAs to produce a compact implementation. This paper presents a novel design of a modular redundant actuation unit which can be combined in various combinations to form compliant actuators with varying characteristics. The actuation unit consists of discretely activated solenoids with an integrated compliant coupling. This paper presents the working principle and the physical implementation in detail. Failure of a single motor unit will merely lead to a loss in performance rather than failure of the actuator. Since each motor unit is discrete, neither power electronics nor control requires analog signals. Isometric experiments display the actuation characteristics and demonstrate the repeatability. The platform can be used in future work to further explore the virtues of exploiting discretization and redundancy in muscle-like control.\"],\n",
    "[360,0,0,\"Complex systems are characterized by many independent components whose low-level actions produce collective high-level results. Predicting high-level results given low-level rules is a key open challenge; the inverse problem, finding low-level rules that give specific outcomes, is in general still less understood. We present a multi-agent construction system inspired by mound-building termites, solving such an inverse problem. A user specifies a desired structure, and the system automatically generates low-level rules for independent climbing robots that guarantee production of that structure. Robots use only local sensing and coordinate their activity via the shared environment. We demonstrate the approach via a physical realization with three autonomous climbing robots limited to onboard sensing. This work advances the aim of engineering complex systems that achieve specific human-designed goals.\"],\n",
    "[361,0,0,\"Evidence from developmental as well as neuroscientific studies suggest that finger counting activity plays an important role in the acquisition of numerical skills in children. It has been claimed that this skill helps in building motor-based representations of number that continue to influence number processing well into adulthood, facilitating the emergence of number concepts from sensorimotor experience through a bottom-up process. The act of counting also involves the acquisition and use of a verbal number system of which number words are the basic building blocks. Using a Cognitive Developmental Robotics paradigm we present results of a modeling experiment on whether finger counting and the association of number words (or tags) to fingers, could serve to bootstrap the representation of number in a cognitive robot, enabling it to perform basic numerical operations such as addition. The cognitive architecture of the robot is based on artificial neural networks, which enable the robot to learn both sensorimotor skills (finger counting) and linguistic skills (using number words). The results obtained in our experiments show that learning the number words in sequence along with finger configurations helps the fast building of the initial representation of number in the robot. Number knowledge, is instead, not as efficiently developed when number words are learned out of sequence without finger counting. Furthermore, the internal representations of the finger configurations themselves, developed by the robot as a result of the experiments, sustain the execution of basic arithmetic operations, something consistent with evidence coming from developmental research with children. The model and experiments demonstrate the importance of sensorimotor skill learning in robots for the acquisition of abstract knowledge such as numbers.\"],\n",
    "[362,0,0,\"In recent years, there have been major advances in the development of new and more powerful perception systems for agriculture, such as computer-vision and global positioning systems. Due to these advances, the automation of agricultural tasks has received an important stimulus, especially in the area of selective weed control where high precision is essential for the proper use of resources and the implementation of more efficient treatments. Such autonomous agricultural systems incorporate and integrate perception systems for acquiring information from the environment, decision-making systems for interpreting and analyzing such information, and actuation systems that are responsible for performing the agricultural operations. These systems consist of different sensors, actuators, and computers that work synchronously in a specific architecture for the intended purpose. The main contribution of this paper is the selection, arrangement, integration, and synchronization of these systems to form a whole autonomous vehicle for agricultural applications. This type of vehicle has attracted growing interest, not only for researchers but also for manufacturers and farmers. The experimental results demonstrate the success and performance of the integrated system in guidance and weed control tasks in a maize field, indicating its utility and efficiency. The whole system is sufficiently flexible for use in other agricultural tasks with little effort and is another important contribution in the field of autonomous agricultural vehicles.\"],\n",
    "[363,0,0,\"The large expansion of the robotic field in the last decades has created a growing interest in the research and development of tactile sensing solutions for robot hand and body integration. Piezoresistive composites are one of the most widely employed materials for this purpose, combining simple and low cost preparation with high flexibility and conformability to surfaces, low power consumption, and the use of simple read-out electronics. This work provides a review on the different type of composite materials, classified according to the conduction mechanism and analyzing the physics behind it. In particular piezoresistors, strain gauges, percolative and quantum tunnelling devices are reviewed here, with a perspective overview on the most used filler types and polymeric matrices. A description of the state-of-the-art of the tactile sensor solutions from the point of view of the architecture, the design and the performance is also reviewed, with a perspective outlook on the main promising applications.\"],\n",
    "[364,0,0,\"This paper introduces the smart tissue anastomosis robot (STAR). Currently, the STAR is a proof-of-concept for a vision-guided robotic system featuring an actuated laparoscopic suturing tool capable of executing running sutures from image-based commands. The STAR tool is designed around a commercially available laparoscopic suturing tool that is attached to a custom-made motor stage and the STAR supervisory control architecture that enables a surgeon to select and track incisions and the placement of stitches. The STAR supervisory-control interface provides two modes: A manual mode that enables a surgeon to specify the placement of each stitch and an automatic mode that automatically computes equally-spaced stitches based on an incision contour. Our experiments on planar phantoms demonstrate that the STAR in either mode is more accurate, up to four times more consistent and five times faster than surgeons using state-of-the-art robotic surgical system, four times faster than surgeons using manual Endo360( degrees )(R), and nine times faster than surgeons using manual laparoscopic tools.\"],\n",
    "[365,0,0,\"Based on the importance of relative disparity between objects for accurate hand-eye coordination, this paper presents a biological approach inspired by the cortical neural architecture. So, the motor information is coded in egocentric coordinates obtained from the allocentric representation of the space (in terms of disparity) generated from the egocentric representation of the visual information (image coordinates). In that way, the different aspects of the visuomotor coordination are integrated: an active vision system, composed of two vergent cameras; a module for the 2D binocular disparity estimation based on a local estimation of phase differences performed through a bank of Gabor filters; and a robotic actuator to perform the corresponding tasks (visually-guided reaching). The approach's performance is evaluated through experiments on both simulated and real data.\"],\n",
    "[366,0,0,\"This paper proposes the use of an autonomous assistant mobile robot in order to monitor the environmental conditions of a large indoor area and develop an ambient intelligence application. The mobile robot uses single high performance embedded sensors in order to collect and geo-reference environmental information such as ambient temperature, air velocity and orientation and gas concentration. The data collected with the assistant mobile robot is analyzed in order to detect unusual measurements or discrepancies and develop focused corrective ambient actions. This paper shows an example of the measurements performed in a research facility which have enabled the detection and location of an uncomfortable temperature profile inside an office of the research facility. The ambient intelligent application has been developed by performing some localized ambient measurements that have been analyzed in order to propose some ambient actuations to correct the uncomfortable temperature profile.\"],\n",
    "[367,0,0,\"In this article, we present a neurologically motivated computational architecture for visual information processing. The computational architecture's focus lies in multiple strategies: hierarchical processing, parallel and concurrent processing, and modularity. The architecture is modular and expandable in both hardware and software, so that it can also cope with multisensory integrations - making it an ideal tool for validating and applying computational neuroscience models in real time under real-world conditions. We apply our architecture in real time to validate a long-standing biologically inspired visual object recognition model, HMAX. In this context, the overall aim is to supply a humanoid robot with the ability to perceive and understand its environment with a focus on the active aspect of real-time spatiotemporal visual processing. We show that our approach is capable of simulating information processing in the visual cortex in real time and that our entropy-adaptive modification of HMAX has a higher efficiency and classification performance than the standard model (up to approximately +6%).\"],\n",
    "[368,0,0,\"PURPOSE: The accurate selection of materials and the fine tuning of their properties represent a fundamental aspect in the realization of new active systems able to produce actuating forces, such as artificial muscles. In this regard, exciting opportunities for the design of new advanced systems are offered by materials belonging to the emerging class of functional polymers: exploiting their actuation response, specific devices can be realized. Along this direction, materials showing either shape-memory effect (SME) or shape-change effect (SCE) have been the subject of extensive studies aimed at designing of actuators as artificial muscles. Here, we concisely review active polymers in terms of properties and main applications in artificial muscle design. STRUCTURE: The main aspects related to material properties in both shape-memory polymers (SMPs) and electroactive polymers (EAPs) are reviewed, based on recent scientific literature. SME in thermally activated SMPs is presented by preliminarily providing a definition that encompasses the new theories regarding their fundamental properties. EAPs are briefly presented, describing the working mechanisms and highlighting the main properties and drawbacks, in view of their application as actuators. For both classes of materials, some key examples of effective application in artificial muscles are offered. OUTLOOK: The potential in polymer architecture design for the fabrication of actively moving systems is described to give a perspective on the main achievements and new research activities.\"],\n",
    "[369,0,0,\"Semi-autonomous control schemes can address the limitations of both teleoperation and fully autonomous robotic control of rescue robots in disaster environments by allowing a human operator to cooperate and share such tasks with a rescue robot as navigation, exploration, and victim identification. In this paper, we present a unique hierarchical reinforcement learning-based semi-autonomous control architecture for rescue robots operating in cluttered and unknown urban search and rescue (USAR) environments. The aim of the controller is to enable a rescue robot to continuously learn from its own experiences in an environment in order to improve its overall performance in exploration of unknown disaster scenes. A direction-based exploration technique is integrated in the controller to expand the search area of the robot via the classification of regions and the rubble piles within these regions. Both simulations and physical experiments in USAR-like environments verify the robustness of the proposed HRL-based semi-autonomous controller to unknown cluttered scenes with different sizes and varying types of configurations.\"],\n",
    "[370,0,0,\"This paper describes a new method of measuring the position of everyday objects and a robot on the floor using distance and reflectance acquired by laser range finder (LRF). The information obtained by this method is important for a service robot working in a human daily life environment. Our method uses only one LRF together with a mirror installed on the wall. Moreover, since the area of sensing is limited to a LRF scanning plane parallel to the floor and just a few centimeters above the floor, the scanning covers the whole room with minimal invasion of privacy of a resident, and occlusion problem is mitigated by using mirror. We use the reflection intensity and position information obtained from the target surface. Although it is not possible to identify all objects by additionally using reflection values, it would be easier to identify unknown objects if we can eliminate easily identifiable objects by reflectance. In addition, we propose a method for measuring the robot's pose using the tag which has the encoded reflection pattern optically identified by the LRF. Our experimental results validate the effectiveness of the proposed method.\"],\n",
    "[371,0,0,\"This paper presents a multi-sensor humanoid robotic head for human robot interaction. The design of the robotic head, Muecas, is based on ongoing research on the mechanisms of perception and imitation of human expressions and emotions. These mechanisms allow direct interaction between the robot and its human companion through the different natural language modalities: speech, body language and facial expressions. The robotic head has 12 degrees of freedom, in a human-like configuration, including eyes, eyebrows, mouth and neck, and has been designed and built entirely by IADeX (Engineering, Automation and Design of Extremadura) and RoboLab. A detailed description of its kinematics is provided along with the design of the most complex controllers. Muecas can be directly controlled by FACS (Facial Action Coding System), the de facto standard for facial expression recognition and synthesis. This feature facilitates its use by third party platforms and encourages the development of imitation and of goal-based systems. Imitation systems learn from the user, while goal-based ones use planning techniques to drive the user towards a final desired state. To show the flexibility and reliability of the robotic head, the paper presents a software architecture that is able to detect, recognize, classify and generate facial expressions in real time using FACS. This system has been implemented using the robotics framework, RoboComp, which provides hardware-independent access to the sensors in the head. Finally, the paper presents experimental results showing the real-time functioning of the whole system, including recognition and imitation of human facial expressions.\"],\n",
    "[372,0,0,\"We developed two similar structure manipulators for medical endocavity ultrasound probes with 3 and 4 degrees of freedom (DoF). These robots allow scanning with ultrasound for 3-D imaging and enable robot-assisted image-guided procedures. Both robots use remote center of motion kinematics, characteristic of medical robots. The 4-DoF robot provides unrestricted manipulation of the endocavity probe. With the 3-DoF robot the insertion motion of the probe must be adjusted manually, but the device is simpler and may also be used to manipulate external-body probes. The robots enabled a novel surgical approach of using intraoperative image-based navigation during robot-assisted laparoscopic prostatectomy (RALP), performed with concurrent use of two robotic systems (Tandem, T-RALP). Thus far, a clinical trial for evaluation of safety and feasibility has been performed successfully on 46 patients. This paper describes the architecture and design of the robots, the two prototypes, control features related to safety, preclinical experiments, and the T-RALP procedure.\"],\n",
    "[373,0,0,\"Navigation in time-evolving environments with moving targets and obstacles requires cognitive abilities widely demonstrated by even simplest animals. However, it is a long-standing challenging problem for artificial agents. Cognitive autonomous robots coping with this problem must solve two essential tasks: 1) understand the environment in terms of what may happen and how I can deal with this and 2) learn successful experiences for their further use in an automatic subconscious way. The recently introduced concept of compact internal representation (CIR) provides the ground for both the tasks. CIR is a specific cognitive map that compacts time-evolving situations into static structures containing information necessary for navigation. It belongs to the class of global approaches, i.e., it finds trajectories to a target when they exist but also detects situations when no solution can be found. Here we extend the concept of situations with mobile targets. Then using CIR as a core, we propose a closed-loop neural network architecture consisting of conscious and subconscious pathways for efficient decision-making. The conscious pathway provides solutions to novel situations if the default subconscious pathway fails to guide the agent to a target. Employing experiments with roving robots and numerical simulations, we show that the proposed architecture provides the robot with cognitive abilities and enables reliable and flexible navigation in realistic time-evolving environments. We prove that the subconscious pathway is robust against uncertainty in the sensory information. Thus if a novel situation is similar but not identical to the previous experience (because of, e.g., noisy perception) then the subconscious pathway is able to provide an effective solution.\"],\n",
    "[374,0,0,\"The needs of molecular diagnostic laboratories that perform both Food and Drug Administration-cleared as well as laboratory-developed tests are usually not met on a single analytical platform. Furthermore, little information is available about the direct impact of molecular automation on labor costs and efficiency in clinical laboratories. We performed a process impact analysis from time and motion studies of a novel molecular diagnostic robotic system designed to automate sample preparation, extraction, and analysis. All 27 preanalytical tasks were quantified for the amount of time spent preparing 24 specimens for analysis. These steps were completed in 899 s (14 min, 59 s) followed by 7887 s (131 min, 27 s) of instrument operation independent of operator control (walk-away time). Postanalytical results evaluation required 1 min per specimen. The instrument automatically extracted the nucleic acid from the specimen, added the eluted DNA to the amplification reagents, and performed the analysis. Only 12% of the total instrument operations required relatively unskilled human labor. Thus, the availability of automated molecular diagnostic instruments will facilitate the expansion of molecular testing in the clinical laboratory because they reduce operator costs with respect to time and complexity of the tasks they are asked to perform.\"],\n",
    "[375,0,0,\"We report on the MARS2013 mission, a 4-week Mars analog field test in the northern Sahara. Nineteen experiments were conducted by a field crew in Morocco under simulated martian surface exploration conditions, supervised by a Mission Support Center in Innsbruck, Austria. A Remote Science Support team analyzed field data in near real time, providing planning input for the management of a complex system of field assets; two advanced space suit simulators, four robotic vehicles, an emergency shelter, and a stationary sensor platform in a realistic work flow were coordinated by a Flight Control Team. A dedicated flight planning group, external control centers for rover tele-operations, and a biomedical monitoring team supported the field operations. A 10 min satellite communication delay and other limitations pertinent to human planetary surface activities were introduced. The fields of research for the experiments were geology, human factors, astrobiology, robotics, tele-science, exploration, and operations research. This paper provides an overview of the geological context and environmental conditions of the test site and the mission architecture, in particular the communication infrastructure emulating the signal travel time between Earth and Mars. We report on the operational work flows and the experiments conducted, including a deployable shelter prototype for multiple-day extravehicular activities and contingency situations.\"],\n",
    "[376,0,0,\"A Microbial Fuel Cell is a bioelectrochemical device that exploits metabolic activities of living microorganisms for generation of electric current. The usefulness and unique and exclusive architecture of this device has received wide attention recently of engineers and researchers of various disciplines such as microbiologists, chemical engineers, biotechnologists, environment engineers and mechanical engineers, and the subject of MFCs has thereby progressed as a well-developed technology. Sustained innovations and continuous development efforts have established the usefulness of MFCs towards many specialized and value-added applications beyond electricity generation, such as wastewater treatment and implantable body devices. This review is an attempt to provide an update on this rapidly growing technology.\"],\n",
    "[377,0,0,\"Tactile sensing helps robots interact with humans and objects effectively in real environments. Piezoelectric polymer sensors provide the functional building blocks of the robotic electronic skin, mainly thanks to their flexibility and suitability for detecting dynamic contact events and for recognizing the touch modality. The paper focuses on the ability of tactile sensing systems to support the challenging recognition of certain qualities/modalities of touch. The research applies novel computational intelligence techniques and a tensor-based approach for the classification of touch modalities; its main results consist in providing a procedure to enhance system generalization ability and architecture for multi-class recognition applications. An experimental campaign involving 70 participants using three different modalities in touching the upper surface of the sensor array was conducted, and confirmed the validity of the approach.\"],\n",
    "[378,0,0,\"This paper presents the design and implementation of IsiMove, a new dynamic posturography platform. It allows the evaluation of the static and dynamic balance of a human placed on a force plate. IsiMove is a robotic platform open kinematic with four degrees of freedom: anteroposterior tilt, mediolateral tilt, vertical rotation, and horizontal translation. It is capable of measuring the displacement of the center of pressure over time, with a resolution of 0.1 mm for each foot and support a human of about 120 kg. IsiMove can generate various types of balance perturbations based on parameters such as direction, amplitude, frequency and shape. In this paper, we will give a description of the mechanisms that constitute our platform. First, the technical specifications of the hardware and software architecture will be presented. Then, we will provide details related to extensive experimental evaluations of the platform in both static and dynamic condition as well as result of postural stability analysis with healthy subjects and stroke patients.\"],\n",
    "[379,5,0,\"A promising idea for scaling robot learning to more complex tasks is to use elemental behaviors as building blocks to compose more complex behavior. Ideally, such building blocks are used in combination with a learning algorithm that is able to learn to select, adapt, sequence and co-activate the building blocks. While there has been a lot of work on approaches that support one of these requirements, no learning algorithm exists that unifies all these properties in one framework. In this paper we present our work on a unified approach for learning such a modular control architecture. We introduce new policy search algorithms that are based on information-theoretic principles and are able to learn to select, adapt and sequence the building blocks. Furthermore, we developed a new representation for the individual building block that supports co-activation and principled ways for adapting the movement. Finally, we summarize our experiments for learning modular control architectures in simulation and with real robots.\"],\n",
    "[380,0,0,\"This paper presents the design and validation of a control system for a pair of powered knee and ankle prostheses to be used as a prosthetic intervention for bilateral transfemoral amputees. The control system leverages communication between the prostheses for enhanced awareness and stability, along with power generation at the knee and ankle joints to better restore biomechanical functionality in level ground walking. The control methodology employed is a combination of an impedance-based framework for weight-bearing portions of gait and a trajectory-based approach for the nonweight-bearing portions. The control system was implemented on a pair of self-contained powered knee and ankle prostheses, and the ability of the prostheses and control approach to provide walking functionality was assessed in a set of experimental trials with a bilateral transfemoral amputee subject. Specifically, experimental data from these trials indicate that the powered prostheses and bilateral control architecture provide gait kinematics that reproduce healthy gait kinematics to a greater extent than the subject's daily-use passive prostheses.\"],\n",
    "[381,0,0,\"In robotic assisted beating heart surgery, the control architecture for heart motion tracking has stringent requirements in terms of bandwidth of the motion that needs to be tracked. In order to achieve sufficient tracking accuracy, feed-forward control algorithms, which rely on estimations of upcoming heart motion, have been proposed in the literature. However, performance of these feed-forward motion control algorithms under heart rhythm variations is an important concern. In their past work, the authors have demonstrated the effectiveness of a receding horizon model predictive control-based algorithm, which used generalized adaptive predictors, under constant and slowly varying heart rate conditions. This paper extends these studies to the case when the heart motion statistics change abruptly and significantly, such as during arrhythmias. A feasibility study is carried out to assess the motion tracking capabilities of the adaptive algorithms in the occurrence of arrhythmia during beating heart surgery. Specifically, the tracking performance of the algorithms is evaluated on prerecorded motion data, which is collected in vivo and includes heart rhythm irregularities. The algorithms are tested using both simulations and bench experiments on a three degree-of-freedom robotic test bed. They are also compared with a position-plus-derivative controller as well as a receding horizon model predictive controller that employs an extended Kalman filter algorithm for predicting future heart motion.\"],\n",
    "[382,0,0,\"Self-organizing artificial neural networks are a popular tool for studying visual system development, in particular the cortical feature maps present in real systems that represent properties such as ocular dominance (OD), orientation-selectivity (OR) and direction selectivity (DS). They are also potentially useful in artificial systems, for example robotics, where the ability to extract and learn features from the environment in an unsupervised way is important. In this computational study we explore a DS map that is already latent in a simple artificial network. This latent selectivity arises purely from the cortical architecture without any explicit coding for DS and prior to any self-organising process facilitated by spontaneous activity or training. We find DS maps with local patchy regions that exhibit features similar to maps derived experimentally and from previous modeling studies. We explore the consequences of changes to the afferent and lateral connectivity to establish the key features of this proto-architecture that support DS.\"],\n",
    "[383,0,0,\"Molecular machines composed of RNA-protein (RNP) complexes may expand the fields of molecular robotics, nanomedicine, and synthetic biology. However, constructing and directly visualizing a functional RNP nanostructure to detect and control living cell function remains a challenge. Here we show that RNP nanostructures with modular functions can be designed and visualized at single-RNP resolution in real time. The RNP structural images collected in solution through high-speed atomic force microscopy showed that a single RNP interaction induces a conformational change in the RNA scaffold, which supports the nanostructure formation designed. The specific RNP interaction also improved RNA nanostructure stability in a serum-containing buffer. We developed and visualized functional RNPs (e.g., to detect human cancer cells or knockdown target genes) by attaching a protein or RNA module to the same RNA scaffold of an optimal size. The synthetic RNP architecture may provide alternative materials to detect and control functions in target mammalian cells.\"],\n",
    "[384,0,0,\"This paper presents a control approach for a lower-limb exoskeleton intended to facilitate recovery of walking in individuals with lower-extremity hemiparesis after stroke. The authors hypothesize that such recovery is facilitated by allowing the patient rather than the exoskeleton to provide movement coordination. As such, an assistive controller that provides walking assistance without dictating the spatiotemporal nature of joint movement is described here. Following a description of the control laws and finite state structure of the controller, the authors present the results of an experimental implementation and preliminary validation of the control approach, in which the control architecture was implemented on a lower limb exoskeleton, and the exoskeleton implemented in an experimental protocol on three subjects with hemiparesis following stroke. In a series of sessions in which each patient used the exoskeleton, all patients showed substantial single-session improvements in all measured gait outcomes, presumably as a result of using the assistive controller and exoskeleton.\"],\n",
    "[385,0,0,\"Unmanned aerial vehicle (UAV) systems have already been used in civilian activities, although very limitedly. Confronted different types of tasks, multi UAVs usually need to be coordinated. This can be extracted as a multi UAVs system architecture problem. Based on the general system architecture problem, a specific description of the multi UAVs system architecture problem is presented. Then the corresponding optimization problem and an efficient genetic algorithm with a refined crossover operator (GA-RX) is proposed to accomplish the architecting process iteratively in the rest of this paper. The availability and effectiveness of overall method is validated using 2 simulations based on 2 different scenarios.\"],\n",
    "[386,9,1,\"Computer-based sensors and actuators such as global positioning systems, machine vision, and laser-based sensors have progressively been incorporated into mobile robots with the aim of configuring autonomous systems capable of shifting operator activities in agricultural tasks. However, the incorporation of many electronic systems into a robot impairs its reliability and increases its cost. Hardware minimization, as well as software minimization and ease of integration, is essential to obtain feasible robotic systems. A step forward in the application of automatic equipment in agriculture is the use of fleets of robots, in which a number of specialized robots collaborate to accomplish one or several agricultural tasks. This paper strives to develop a system architecture for both individual robots and robots working in fleets to improve reliability, decrease complexity and costs, and permit the integration of software from different developers. Several solutions are studied, from a fully distributed to a whole integrated architecture in which a central computer runs all processes. This work also studies diverse topologies for controlling fleets of robots and advances other prospective topologies. The architecture presented in this paper is being successfully applied in the RHEA fleet, which comprises three ground mobile units based on a commercial tractor chassis.\"],\n",
    "[387,0,0,\"In the context of Industry 4.0, industrial robotics such as automated guided vehicles have drawn increased attention due to their automation capabilities and low cost. With the support of cognitive technologies for industrial Internet of Things (IoT), production processes can be significantly optimized and more intelligent manufacturing can be implemented for smart factories. In this paper, for advanced material handling, a cognitive industrial entity called context-aware cloud robotics (CACR) are introduced and analyzed. Compared with the one-time on-demand delivery, CACR is characterized by two features: 1) context-aware services and 2) effective load balancing. First, the system architecture, advantages, challenges, and applications for CACR are introduced. Then, fundamental functions for material handling are articulated, namely, decision-making mechanisms and cloud-enabled simultaneous localization and mapping. Finally, a CACR case study is performed to highlight its energy-efficient and cost-saving material handling capabilities. Simulations indicate the superiority of cognitive industrial IoT and show that using CACR for material handling can significantly improve energy efficiency and save cost.; In the context of Industry 4.0, industrial robotics such as automated guided vehicles have drawn increased attention due to their automation capabilities and low cost. With the support of cognitive technologies for industrial Internet of Things (IoT), production processes can be significantly optimized and more intelligent manufacturing can be implemented for smart factories. In this paper, for advanced material handling, a cognitive industrial entity called context-aware cloud robotics (CACR) are introduced and analyzed. Compared with the one-time on-demand delivery, CACR is characterized by two features: (1) context-aware services and (2) effective load balancing. First, the system architecture, advantages, challenges, and applications for CACR are introduced. Then, fundamental functions for material handling are articulated, namely, decisionmaking mechanisms and cloud-enabled simultaneous localization and mapping. Finally, a CACR case study is performed to highlight its energy-efficient and cost-saving material handling capabilities. Simulations indicate the superiority of cognitive industrial IoT and show that using CACR for material handling can significantly improve energy efficiency and save cost.\"],\n",
    "[388,0,0,\"Display Omitted; The ability of artificial immune systems to adapt to varying pathogens makes such systems a suitable choice for various robotic applications. Generally, immunity-based robotic applications map local instantaneous sensory information into either an antigen or a co-stimulatory signal, according to the choice of representation schema. Algorithms then use relevant immune functions to output either evolved antibodies or maturity of dendritic cells, in terms of actuation signals. It is observed that researchers do not try to replicate the biological immunity but select necessary immune functions instead, resulting in an ad-hoc manner these applications are reported. On the other hand, the paradigm shift in robotics research from reactive to probabilistic approaches is also not being reflected in these applications. Authors, therefore, present a detailed review of immuno-inspired robotic applications in an attempt to identify the possible areas to explore. Moreover, the literature has been categorized according to the underlying immuno-definitions. Implementation details have been critically reviewed in terms of corresponding mathematical expressions and their representation schema that include binary, real or hybrid approaches. Limitations of reported applications have also been identified in light of modern immunological interpretations including the danger theory. As a result of this study, authors suggest a renewed focus on innate immunity, action contextualization prior to B/T cell invocation and behavior evolution instead of arbitration. In this context, a multi-tier immunological framework for robotics research, combining innate and adaptive components together is also suggested and skeletonized.; The ability of artificial immune systems to adapt to varying pathogens makes such systems a suitable choice for various robotic applications. Generally, immunity-based robotic applications map local instantaneous sensory information into either an antigen or a co-stimulatory signal, according to the choice of representation schema. Algorithms then use relevant immune functions to output either evolved antibodies or maturity of dendritic cells, in terms of actuation signals. It is observed that researchers do not try to replicate the biological immunity but select necessary immune functions instead, resulting in an ad-hoc manner these applications are reported. On the other hand, the paradigm shift in robotics research from reactive to probabilistic approaches is also not being reflected in these applications. Authors, therefore, present a detailed review of immuno-inspired robotic applications in an attempt to identify the possible areas to explore. Moreover, the literature has been categorized according to the underlying immuno-definitions. Implementation details have been critically reviewed in terms of corresponding mathematical expressions and their representation schema that include binary, real or hybrid approaches. Limitations of reported applications have also been identified in light of modern immunological interpretations including the danger theory. As a result of this study, authors suggest a renewed focus on innate immunity, action contextualization prior to B/T cell invocation and behavior evolution instead of arbitration. In this context, a multi-tier immunological framework for robotics research, combining innate and adaptive components together is also suggested and skeletonized. (C) 2015 Elsevier B.V. All rights reserved.\"],\n",
    "[389,0,0,\"This paper describes the basic idea of data transferring in the group of robots while they move in an area with a high density of obstacles with the goal of increasing their movement speed by creating and synchronizing an area map that is made by each robot separately. This paper provides a brief review of existing robotic swarm projects and definition of the problems in robot teamwork, shows pathfinding methods and their analysis, justifies our technical vision system choice and describes its method of obstacle detecting that is based on dynamic triangulation. According to some behavioristic models, using fuzzy logic, the method of leader changing was used. This knowledge helps with the choice of appropriate models of data transferring, makes their simulation and creates a proper network between the robots to avoid data loss. (C) 2016 Elsevier B.V. All rights reserved.; This paper describes the basic idea of data transferring in the group of robots while they move in an area with a high density of obstacles with the goal of increasing their movement speed by creating and synchronizing an area map that is made by each robot separately. This paper provides a brief review of existing robotic swarm projects and definition of the problems in robot teamwork, shows pathfinding methods and their analysis, justifies our technical vision system choice and describes its method of obstacle detecting that is based on dynamic triangulation. According to some behavioristic models, using fuzzy logic, the method of leader changing was used. This knowledge helps with the choice of appropriate models of data transferring, makes their simulation and creates a proper network between the robots to avoid data loss.\"],\n",
    "[390,9,1,\"Employing Modular Robotic Systems (MRS) in different application domains confronts a large number of challenging problems in design, optimization, and planning, and so identifying characteristics of such problems is an important step toward finding proper solution approaches for them. In this paper, we address this issue and provide a comprehensive study on MRS through a structured survey about MRS characteristics and their applications. A novel framework called MITE is proposed to characterize both the properties and applications of MRS from four perspectives of Module, Information, Task, and Environment, based on more than 120 domain-specific features, supplemented by a mapping scheme for describing the interrelations of the four basic aspects of the Task component, namely, Application (for describing high-level tasks such as navigation and rescue), Behavior (for referring to constitutive behaviors like locomotion and manipulation which bring about Applications), Goal (for characterizing the way Behaviors are accomplished), and Operation (for designating activities specific to modular robots, such as self-reconfiguration and gait control). Also, by providing a methodical review on modular robotics, the paper deals with some analyses on recent trends, research gaps and challenges, as well as open problems in the field of MRS.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1007/s10846-015-0237-8; ┬á Employing Modular Robotic Systems (MRS) in different application domains confronts a large number of challenging problems in design, optimization, and planning, and so identifying characteristics of such problems is an important step toward finding proper solution approaches for them. In this paper, we address this issue and provide a comprehensive study on MRS through a structured survey about MRS characteristics and their applications. A novel framework called MITE is proposed to characterize both the properties and applications of MRS from four perspectives of Module, Information, Task, and Environment, based on more than 120 domain-specific features, supplemented by a mapping scheme for describing the interrelations of the four basic aspects of the Task component, namely, Application (for describing high-level tasks such as navigation and rescue), Behavior (for referring to constitutive behaviors like locomotion and manipulation which bring about Applications), Goal (for characterizing the way Behaviors are accomplished), and Operation (for designating activities specific to modular robots, such as self-reconfiguration and gait control). Also, by providing a methodical review on modular robotics, the paper deals with some analyses on recent trends, research gaps and challenges, as well as open problems in the field of MRS.\"],\n",
    "[391,9,1,\"In this paper we introduce a novel cloud robotics architecture that provides different functionalities to support enhanced coordination of groups of Automated Guided Vehicles (AGVs) used for industrial logistics. In particular, we define a cooperative data fusion system that, gathering data from different sensing sources, provides a constantly updated global live view of the industrial environment, for coordinating the motion of the AGVs in an optimized manner. In fact, local sensing capabilities are complemented with global information, thus extending the field of view of each AGV. This knowledge extension allows to support a cooperative and flexible global route assignment and local path planning in order to avoid congestion zones, obstacles reported in the global live view map and deal with unexpected obstacles in. the current path. The proposed methodology is validated in a real industrial environment, allowing an AGV to safely perform an obstacle avoidance procedure. (c) 2017 Elsevier Ltd. All rights reserved.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1016/j.mechatronics.2017.04.005 In this paper we introduce a novel cloud robotics architecture that provides different functionalities to support enhanced coordination of groups of Automated Guided Vehicles (AGVs) used for industrial logistics. In particular, we define a cooperative data fusion system that, gathering data from different sensing sources, provides a constantly updated global live view of the industrial environment, for coordinating the motion of the AGVs in an optimized manner. In fact, local sensing capabilities are complemented with global information, thus extending the field of view of each AGV. This knowledge extension allows to support a cooperative and flexible global route assignment and local path planning in order to avoid congestion zones, obstacles reported in the global live view map and deal with unexpected obstacles in the current path. The proposed methodology is validated in a real industrial environment, allowing an AGV to safely perform an obstacle avoidance procedure.; In this paper we introduce a novel cloud robotics architecture that provides different functionalities to support enhanced coordination of groups of Automated Guided Vehicles (AGVs) used for industrial logistics. In particular, we define a cooperative data fusion system that, gathering data from different sensing sources, provides a constantly updated global live view of the industrial environment, for coordinating the motion of the AGVs in an optimized manner. In fact, local sensing capabilities are complemented with global information, thus extending the field of view of each AGV. This knowledge extension allows to support a cooperative and flexible global route assignment and local path planning in order to avoid congestion zones, obstacles reported in the global live view map and deal with unexpected obstacles in the current path. The proposed methodology is validated in a real industrial environment, allowing an AGV to safely perform an obstacle avoidance procedure.\"],\n",
    "[392,5,0,\"The paper presents a robotic system design methodology based on the concept of an embodied agent decomposed into communicating subsystems, whose activities are specified in terms of FSMs invoking behaviours parameterised by transition functions and terminal conditions. In the implementation phase, this specification is transformed into a system composed of a whiteboard providing communication means and logically labelled FSMs (LLFSMs) defining the system behaviour. These concepts are used to generate the code of the robot controller. The inclusion of inter-subsystem communication model completes the resulting system design with respect to our previous work that did not account for this model. Thus communication plays a central role in this presentation. The design methodology is exemplified with a rudimentary table tennis ball-collecting robot. The presented methodology and the implementation tools are suitable and beneficial for application to the design of other robotic systems.\"],\n",
    "[393,5,0,\"This paper presents a technical approach to robot learning of motor skills which combines active intrinsically motivated learning with imitation learning. Our architecture, called SGIM-D, allows efficient learning of high-dimensional continuous sensorimotor inverse models in robots, and in particular learns distributions of parameterised motor policies that solve a corresponding distribution of parameterised goals/tasks. This is made possible by the technical integration of imitation learning techniques within an algorithm for learning inverse models that relies on active goal babbling. After reviewing social learning and intrinsic motivation approaches to action learning, we describe the general framework of our algorithm, before detailing its architecture. In an experiment where a robot arm has to learn to use a flexible fishing line , we illustrate that SGIM-D efficiently combines the advantages of social learning and intrinsic motivation and benefits from human demonstration properties to learn how to produce varied outcomes in the environment, while developing more precise control policies in large spaces.; This paper presents a technical approach to robot learning of motor skills which combines active intrinsically motivated learning with imitation learning. Our algorithmic architecture, called SGIM-D, allows efficient learning of high-dimensional continuous sensorimotor inverse models in robots, and in particular learns distributions of parameterised motor policies that solve a corresponding distribution of parameterised goals/tasks. This is made possible by the technical integration of imitation learning techniques within an algorithm for learning inverse models that relies on active goal babbling. After reviewing social learning and intrinsic motivation approaches to action learning, we describe the general framework of our algorithm, before detailing its architecture. In an experiment where a robot arm has to learn to use a flexible fishing line, we illustrate that SGIM-D efficiently combines the advantages of social learning and intrinsic motivation and benefits from human demonstration properties to learn how to produce varied outcomes in the environment, while developing more precise control policies in large spaces.; Autonomous Robots, Springer Verlag, 2014, 36 (3), pp.273-294 This paper presents a technical approach to robot learning of motor skills which combines active intrinsically motivated learning with imitation learning. Our architecture, called SGIM-D, allows efficient learning of high-dimensional continuous sensorimotor inverse models in robots, and in particular learns distributions of parameterised motor policies that solve a corresponding distribution of parameterised goals/tasks. This is made possible by the technical integration of imitation learning techniques within an algorithm for learning inverse models that relies on active goal babbling. After reviewing social learning and intrinsic motivation approaches to action learning, we describe the general framework of our algorithm, before detailing its architecture. In an experiment where a robot arm has to learn to use a flexible fishing line , we illustrate that SGIM-D efficiently combines the advantages of social learning and intrinsic motivation and benefits from human demonstration properties to learn how to produce varied outcomes in the environment, while developing more precise control policies in large spaces.; ┬á This paper presents a technical approach to robot learning of motor skills which combines active intrinsically motivated learning with imitation learning. Our algorithmic architecture, called SGIM-D, allows efficient learning of high-dimensional continuous sensorimotor inverse models in robots, and in particular learns distributions of parameterised motor policies that solve a corresponding distribution of parameterised goals/tasks. This is made possible by the technical integration of imitation learning techniques within an algorithm for learning inverse models that relies on active goal babbling. After reviewing social learning and intrinsic motivation approaches to action learning, we describe the general framework of our algorithm, before detailing its architecture. In an experiment where a robot arm has to learn to use a flexible fishing line, we illustrate that SGIM-D efficiently combines the advantages of social learning and intrinsic motivation and benefits from human demonstration properties to learn how to produce varied outcomes in the environment, while developing more precise control policies in large spaces.[PUBLICATION ABSTRACT]\"],\n",
    "[394,0,0,\"Robots are leaving factories and entering urban spaces. In this paper, I will explore how we can integrate robots of various types into the urban landscape. I will distinguish between two perspectives: (1) the responsible design and use of urban robots and (2) robots as part of responsible urban innovations. The first viewpoint considers issues arising from the use of a robot in an urban environment. To develop a substantive understanding of Responsible Urban Robotics, we need to focus on normative implications of city life as the context in which in robots are being used. I will refer to the desirable qualities of city life as ΓÇ£citynessΓÇ¥ and will argue that we should design for cityness. The second approach asks how robots might be used to address challenges specific to cities. From the perspective of RRI, this may require participatory approaches in which the needs of the stakeholders are addressed. But we may also find inspiration in the work undertaken in architecture on expanding the concept and field to ensure that architects not only provide services to the lucky few but also create useful and beautiful spaces for the many. A dialogue with architects, urban designers, and urban planners may also be needed to successfully address the spatial issues raised by the presence of robots in the city.\"],\n",
    "[395,0,0,\"To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1007/s10514-016-9586-9 Information and Communication Technology and personal robots could play a fundamental role in efficiently managing chronic diseases and avoiding improper medications. They could support senior citizens with reminders, thus promoting their independent living and quality of life, especially in the presence of several chronic diseases (multimorbidity). In this context, this article proposes a service model for personalised medical support that is able to provide adequate healthcare service by means of a hybrid robot-cloud approach. This service was quantitatively and qualitatively tested to assess the technical feasibility and user acceptability level of the service. The service was tested with 23 older people (65--86 years) in the DomoCasa Lab (Italy). This study demonstrated the feasibility of the proposed hybrid cloud solution and the usability and acceptability were positively evaluated thus confirming the ability to utilise these innovative technologies for active and healthy ageing.; Information and Communication Technology and personal robots could play a fundamental role in efficiently managing chronic diseases and avoiding improper medications. They could support senior citizens with reminders, thus promoting their independent living and quality of life, especially in the presence of several chronic diseases (multimorbidity). In this context, this article proposes a service model for personalised medical support that is able to provide adequate healthcare service by means of a hybrid robot-cloud approach. This service was quantitatively and qualitatively tested to assess the technical feasibility and user acceptability level of the service. The service was tested with 23 older people (65-86 years) in the DomoCasa Lab (Italy). This study demonstrated the feasibility of the proposed hybrid cloud solution and the usability and acceptability were positively evaluated thus confirming the ability to utilise these innovative technologies for active and healthy ageing.\"],\n",
    "[396,9,1,\"Cloud robotics (CR) is a red-hot branch of the burgeoning field of service robots that is centered on the benefits of integrating infrastructure and shared services via a cloud computing environment. Although it extends the computation power and information sharing capabilities of the network robots, the development and operations (DevOps) of the CR system are currently limited for enterprise-scale projects due to the heavy framework. In fact, current developed CR systems are typical distributed monomer architectures followed by a 'top-down' design. As the scale of the applications gets larger, the operation and maintenance of CR systems will become a very difficult task. In this paper, a new architecture for a microservice-based cloud robotics system in intelligent space is proposed to solve the present dilemma. To enable this, we design a service management architecture based on a microservice to provide a highly efficient and flexible development/deployment mechanism. The container technology based on the docker engine is then used to functionally decompose the application into a set of collaborating services to ensure the software design methods, based on microservice, easy for implementation. Finally, a real experiment on SLAM (Simulation localization and mapping) in an intelligent space is implemented to verify the proposed architecture. Compared with traditional monomer architectures, the results show that the proposed framework is more productive, flexible and cost effective. (C) 2018 Elsevier B.V. All rights reserved.; Cloud robotics (CR) is a red-hot branch of the burgeoning field of service robots that is centered on the benefits of integrating infrastructure and shared services via a cloud computing environment. Although it extends the computation power and information sharing capabilities of the network robots, the development and operations (DevOps) of the CR system are currently limited for enterprise-scale projects due to the heavy framework. In fact, current developed CR systems are typical distributed monomer architectures followed by a 'top-down' design. As the scale of the applications gets larger, the operation and maintenance of CR systems will become a very difficult task. In this paper, a new architecture for a microservice-based cloud robotics system in intelligent space is proposed to solve the present dilemma. To enable this, we design a service management architecture based on a microservice to provide a highly efficient and flexible development/deployment mechanism. The container technology based on the docker engine is then used to functionally decompose the application into a set of collaborating services to ensure the software design methods, based on microservice, easy for implementation. Finally, a real experiment on SLAM (Simulation localization and mapping) in an intelligent space is implemented to verify the proposed architecture. Compared with traditional monomer architectures, the results show that the proposed framework is more productive, flexible and cost effective.\"],\n",
    "[397,0,0,\"This paper discusses hardware and software improvements to the RoboSimian system leading up to and during the 2015 DARPA Robotics Challenge (DRC) Finals. Team RoboSimian achieved a 5th place finish by achieving 7 points in 47:59 min. We present an architecture that was structured to be adaptable at the lowest level and repeatable at the highest level. The low-level adaptability was achieved by leveraging tactile measurements from force torque sensors in the wrist coupled with whole-body motion primitives. We use the term 'behaviors' to conceptualize this low-level adaptability. Each behavior is a contact-triggered state machine that enables execution of short-order manipulation and mobility tasks autonomously. At a high level, we focused on a teach-and-repeat style of development by storing executed behaviors and navigation poses in an object/task frame for recall later. This enabled us to perform tasks with high repeatability on competition day while being robust to task differences from practice to execution. (C) 2016 Wiley Periodicals, Inc.; ┬á This paper discusses hardware and software improvements to the RoboSimian system leading up to and during the 2015 DARPA Robotics Challenge (DRC) Finals. Team RoboSimian achieved a 5th place finish by achieving 7 points in 47:59 min. We present an architecture that was structured to be adaptable at the lowest level and repeatable at the highest level. The low-level adaptability was achieved by leveraging tactile measurements from force torque sensors in the wrist coupled with whole-body motion primitives. We use the term 'behaviors' to conceptualize this low-level adaptability. Each behavior is a contact-triggered state machine that enables execution of short-order manipulation and mobility tasks autonomously. At a high level, we focused on a teach-and-repeat style of development by storing executed behaviors and navigation poses in an object/task frame for recall later. This enabled us to perform tasks with high repeatability on competition day while being robust to task differences from practice to execution.; This paper discusses hardware and software improvements to the RoboSimian system leading up to and during the 2015 DARPA Robotics Challenge (DRC) Finals. Team RoboSimian achieved a 5th place finish by achieving 7 points in 47:59 min. We present an architecture that was structured to be adaptable at the lowest level and repeatable at the highest level. The lowΓÇÉlevel adaptability was achieved by leveraging tactile measurements from force torque sensors in the wrist coupled with wholeΓÇÉbody motion primitives. We use the term ΓÇ£behaviorsΓÇ¥ to conceptualize this lowΓÇÉlevel adaptability. Each behavior is a contactΓÇÉtriggered state machine that enables execution of shortΓÇÉorder manipulation and mobility tasks autonomously. At a high level, we focused on a teachΓÇÉandΓÇÉrepeat style of development by storing executed behaviors and navigation poses in an object/task frame for recall later. This enabled us to perform tasks with high repeatability on competition day while being robust to task differences from practice to execution.\"],\n",
    "[398,0,0,\"The Robo-AO Kepler Planetary Candidate Survey is observing every Kepler planet candidate host star with laser adaptive optics imaging to search for blended nearby stars, which may be physically associated companions and/or responsible for transit false positives. In this paper, we present the results from the 2012 observing season, searching for stars close to 715 Kepler planet candidate hosts. We find 53 companions, 43 of which are new discoveries. We detail the Robo-AO survey data reduction methods including a method of using the large ensemble of target observations as mutual point-spread-function references, along with a new automated companion-detection algorithm designed for large adaptive optics surveys. Our survey is sensitive to objects from approximate to 0 ''.15 to 2 ''.5 separation, with magnitude differences up to Delta m approximate to 6. We measure an overall nearby-star probability for Kepler planet candidates of 7.4% +/- 1.0%, and calculate the effects of each detected nearby star on the Kepler-measured planetary radius. We discuss several Kepler Objects of Interest (KOIs) of particular interest, including KOI-191 and KOI-1151, which are both multi-planet systems with detected stellar companions whose unusual planetary system architecture might be best explained if they are 'coincident multiple' systems, with several transiting planets shared between the two stars. Finally, we find 98% confidence evidence that short-period giant planets are two to three times more likely than longer-period planets to be found in wide stellar binaries.; The Robo-AO Kepler Planetary Candidate Survey is designed to observe every Kepler planet candidate host star with laser adaptive optics imaging to search for blended nearby stars, which may be physically associated companions and/or responsible for transit false positives. In this paper we present the results from the 2012 observing season, searching for stars close to 715 representative Kepler planet candidate hosts. We find 53 companions, 44 of which are new discoveries. We detail the Robo-AO survey data reduction methods including a method of using the large ensemble of target observations as mutual point-spread-function references, along with a new automated companion-detection algorithm designed for large adaptive optics surveys. Our survey is sensitive to objects from 0.15' to 2.5' separation, with contrast ratios up to delta-m~6. We measure an overall nearby-star-probability for Kepler planet candidates of 7.4% +/- 1.0%, and calculate the effects of each detected nearby star on the Kepler-measured planetary radius. We discuss several KOIs of particular interest, including KOI-191 and KOI-1151, which are both multi-planet systems with detected stellar companions whose unusual planetary system architecture might be best explained if they are 'coincident multiple' systems, with several transiting planets shared between the two stars. Finally, we detect 2.6-sigma evidence for <15d-period giant planets being 2-3 times more likely be found in wide stellar binaries than smaller close-in planets and all sizes of further-out planets.\"],\n",
    "[399,0,0,\"Scientific breakthroughs have led to an increase in life expectancy, to the point where senior citizens comprise an ever increasing percentage of the general population. In this direction, the EU funded RAPP project 'Robotic Applications for Delivering Smart User Empowering Applications' introduces socially interactive robots that will not only physically assist, but also serve as a companion to senior citizens. The proposed RAPP framework has been designed aiming towards a cloud-based integrated approach that enables robotic devices to seamlessly deploy robotic applications, relieving the actual robots from computational burdens. The Robotic Applications (RApps) developed according to the RAPP paradigm will empower consumer social robots, allowing them to adapt to versatile situations and materialize complex behaviors and scenarios. The RAPP pilot cases involve the development of RApps for the NAO humanoid robot and the ANG-MED rollator targeting senior citizens that (a) are technology illiterate, (b) have been diagnosed with mild cognitive impairment or (c) are in the process of hip fracture rehabilitation. Initial results establish the robustness of RAPP in addressing the needs of end users and developers, as well as its contribution in significantly increasing the quality of life of senior citizens. (C) 2016 Elsevier B.V. All rights reserved.; Scientific breakthroughs have led to an increase in life expectancy, to the point where senior citizens comprise an ever increasing percentage of the general population. In this direction, the EU funded RAPP project ΓÇ£Robotic Applications for Delivering Smart User Empowering ApplicationsΓÇ¥ introduces socially interactive robots that will not only physically assist, but also serve as a companion to senior citizens. The proposed RAPP framework has been designed aiming towards a cloud-based integrated approach that enables robotic devices to seamlessly deploy robotic applications, relieving the actual robots from computational burdens. The Robotic Applications (RApps) developed according to the RAPP paradigm will empower consumer social robots, allowing them to adapt to versatile situations and materialize complex behaviors and scenarios. The RAPP pilot cases involve the development of RApps for the NAO humanoid robot and the ANG-MED rollator targeting senior citizens that (a) are technology illiterate, (b) have been diagnosed with mild cognitive impairment or (c) are in the process of hip fracture rehabilitation. Initial results establish the robustness of RAPP in addressing the needs of end users and developers, as well as its contribution in significantly increasing the quality of life of senior citizens.; To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1016/j.cogsys.2016.08.004 (b) Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki 54124, Greece\"],\n",
    "[400,0,0,\"With the development of cloud computing, big data, and other emerging technologies, the integration of cloud technology and multi-robot systems makes it possible to design multi-robot systems with improved energy efficiency, high real-time performance, and low cost. In order to address the potential of clouds in enhancing robotics for industrial systems, this paper describes the basic concepts and development process of cloud robotics and the overall architecture of these systems. Then, the major driving forces behind the development of cloud robotics are carefully analyzed from the point of view of cloud computing, big data, open source resources, robot cooperative learning, and network connectivity. Subsequently, the key issues and challenges in the current cloud robotic systems are proposed, and some possible solutions are also given. Finally, the potential value of cloud robotic systems in different practical applications is discussed.\"],\n",
    "[401,0,0,\"The Cloud infrastructure and its extensive set of Internet-accessible resources has potential to provide significant benefits to robots and automation systems. We consider robots and automation systems that rely on data or code from a network to support their operation, i.e., where not all sensing, computation, and memory is integrated into a standalone system. This survey is organized around four potential benefits of the Cloud: 1) Big Data: access to libraries of images, maps, trajectories, and descriptive data; 2) Cloud Computing: access to parallel grid computing on demand for statistical analysis, learning, and motion planning; 3) Collective Robot Learning: robots sharing trajectories, control policies, and outcomes; and 4) Human Computation: use of crowd-sourcing to tap human skills for analyzing images and video, classification, learning, and error recovery. The Cloud can also improve robots and automation systems by providing access to: a) datasets, publications, models, benchmarks, and simulation tools; b) open competitions for designs and systems; and c) open-source software. This survey includes over 150 references on results and open challenges. A website with new developments and updates is available at: http://goldberg.berkeley.edu/cloud-robotics/ Note to Practitioners-Most robots and automation systems still operate independently using onboard computation, memory, and programming. Emerging advances and the increasing availability of networking in the 'Cloud' suggests new approaches where processing is performed remotely with access to dynamic global datasets to support a range of functions. This paper surveys research to date.; The Cloud infrastructure and its extensive set of Internet-accessible resources has potential to provide significant benefits to robots and automation systems. We consider robots and automation systems that rely on data or code from a network to support their operation, i.e., where not all sensing, computation, and memory is integrated into a standalone system. This survey is organized around four potential benefits of the Cloud: 1) Big Data: access to libraries of images, maps, trajectories, and descriptive data; 2) Cloud Computing: access to parallel grid computing on demand for statistical analysis, learning, and motion planning; 3) Collective Robot Learning: robots sharing trajectories, control policies, and outcomes; and 4) Human Computation: use of crowdsourcing to tap human skills for analyzing images and video, classification, learning, and error recovery. The Cloud can also improve robots and automation systems by providing access to: a) datasets, publications, models, benchmarks, and simulation tools; b) open competitions for designs and systems; and c) open-source software. This survey includes over 150 references on results and open challenges. A website with new developments and updates is available at: http://goldberg.berkeley.edu/cloud-robotics/.; ┬á The Cloud infrastructure and its extensive set of Internet-accessible resources has potential to provide significant benefits to robots and automation systems. We consider robots and automation systems that rely on data or code from a network to support their operation, i.e., where not all sensing, computation, and memory is integrated into a standalone system. This survey is organized around four potential benefits of the Cloud: 1) Big Data: access to libraries of images, maps, trajectories, and descriptive data; 2) Cloud Computing: access to parallel grid computing on demand for statistical analysis, learning, and motion planning; 3) Collective Robot Learning: robots sharing trajectories, control policies, and outcomes; and 4) Human Computation: use of crowdsourcing to tap human skills for analyzing images and video, classification, learning, and error recovery. The Cloud can also improve robots and automation systems by providing access to: a) datasets, publications, models, benchmarks, and simulation tools; b) open competitions for designs and systems; and c) open-source software.\"],\n",
    "[402,5,0,\"This article is concerned with the generic structure of the motion coordination system resulting from the application of the method of virtual holonomic constraints (VHCs) to the problem of the generation and robust execution of a dynamic humanlike motion by a humanoid robot. The motion coordination developed using VHCs is based on a motion generator equation, which is a scalar nonlinear differential equation of second order. It can be considered equivalent in function to a central pattern generator in living organisms. The relative time evolution of the degrees of freedom of a humanoid robot during a typical motion are specified by a set of coordination functions that uniquely define the overall pattern of the motion. This is comparable to a hypothesis on the existence of motion patterns in biomechanics. A robust control is derived based on a transverse linearization along the configuration manifold defined by the coordination functions. It is shown that the derived coordination and control architecture possesses excellent robustness properties. The analysis is performed on an example of a real human motion recorded in test experiments.\"],\n",
    "[403,0,0,\"In this paper, a remote lab for experimenting with a team of mobile robots is presented. Robots are built with the LEGO Mindstorms technology and user-defined control laws can be directly coded in the Matlab programming language and validated on the real system. The lab is versatile enough to be used for both teaching and research purposes. Students can easily go through a number of predefined mobile robotics experiences without having to worry about robot hardware or low-level programming languages. More advanced experiments can also be carried out by uploading custom controllers. The capability to have full control of the vehicles, together with the possibility to define arbitrarily complex environments through the definition of virtual obstacles, makes the proposed facility well suited to quickly test and compare different control laws in a real-world scenario. Moreover, the user can simulate the presence of different types of exteroceptive sensors on board of the robots or a specific communication architecture among the agents, so that decentralized control strategies and motion coordination algorithms can be easily implemented and tested. A number of possible applications and real experiments are presented in order to illustrate the main features of the proposed mobile robotics remote lab.\"],\n",
    "[404,0,0,\"A study of the motor cortex during the programming, execution and mental representation of voluntary movement is of great relevance; its evaluation in conditions close to reality is necessary, given the close integration of the visuomotor, sensory feedback and proprioceptive systems, as of yet, a functional Magnetic Resonance Imaging (fMRI) scanner allowing a human subject to maintain erect stance, observe the surroundings and conserve limb freedom is still a dream. The need for high field suggests a solenoid magnet geometry that forces an unnatural posture that affects the results, particularly when the motor cortex is investigated. In contrast in a motor functional study, the scanner should allow the subject to sit or stand, with unobstructed sight and unimpeded movement. Two approaches are presented here to solve this problem. In the first approach, an increased field intensity in an open magnet is obtained lining the 'back wall' of the cavity with a sheet of current: this boosts the field intensity at the cost of the introduction of a gradient, which has to be canceled by the introduction of an opposite gradient; The second approach is an adaptation of the 'double doughnut' architecture, in which the cavity widens at the center to provide additional room for the subject. The detailed design of this kind of structure has proven the feasibility of the solution.\"],\n",
    "[405,0,0,\"Sound source localization using a two-microphone array is an active area of research, with considerable potential for use with video conferencing, mobile devices, and robotics. Based on the observed time-differences of arrival between sound signals, a probability distribution of the location of the sources is considered to estimate the actual source positions. However, these algorithms assume a given number of sound sources. This paper describes an updated research account on the solution presented in Escolano et al. [J. Acoust. Am. Soc. 132(3), 1257-1260 (2012)], where nested sampling is used to explore a probability distribution of the source position using a Laplacian mixture model, which allows both the number and position of speech sources to be inferred. This paper presents different experimental setups and scenarios to demonstrate the viability of the proposed method, which is compared with some of the most popular sampling methods, demonstrating that nested sampling is an accurate tool for speech localization.\"],\n",
    "[406,0,0,\"Spatiotemporal regulation of cell contractility coordinates cell shape change to construct tissue architecture and ultimately directs the morphology and function of the organism. Here we show that contractility responses to spatially and temporally controlled chemical stimuli depend much more strongly on intercellular mechanical connections than on biochemical cues in both stimulated tissues and adjacent cells. We investigate how the cell contractility is triggered within an embryonic epithelial sheet by local ligand stimulation and coordinates a long-range contraction response. Our custom microfluidic control system allows spatiotemporally controlled stimulation with extracellular ATP, which results in locally distinct contractility followed by mechanical strain pattern formation. The stimulation-response circuit exposed here provides a better understanding of how morphogenetic processes integrate responses to stimulation and how intercellular responses are transmitted across multiple cells. These findings may enable one to create a biological actuator that actively drives morphogenesis.\"],\n",
    "[407,0,0,\"Conventional structural Magnetic Resonance (MR) techniques can accurately identify brain tumors but do not provide exhaustive information about the integrity of the surrounding/embedded white matter (WM). In this study, we used Diffusion-Weighted (DW) MRI tractography to explore tumor-induced alterations of WM architecture without any a priori knowledge about the fiber paths under consideration. We used deterministic multi-fiber tractography to analyze 16 cases of histologically classified brain tumors (meningioma, low-grade glioma, high-grade glioma) to evaluate the integrity of WM bundles in the tumoral region, in relation to the contralateral unaffected hemisphere. Our new tractographic approach yielded measures of WM involvement which were strongly correlated with the histopathological features of the tumor (r = 0.83, p = 0.0001). In particular, the number of affected fiber tracts were significantly (p = 0.0006) different among tumor types. Our method proposes a new application of diffusion tractography for the detection of tumor aggressiveness in those cases in which the lesion does not involve any major/known WM paths and when a priori information about the local fiber anatomy is lacking.\"],\n",
    "[408,5,0,\"BACKGROUND: Neurorehabilitation therapies exploiting the use-dependent plasticity of our neuromuscular system are devised to help patients who suffer from injuries or diseases of this system. These therapies take advantage of the fact that the motor activity alters the properties of our neurons and muscles, including the pattern of their connectivity, and thus their functionality. Hence, a sensor-motor treatment where patients makes certain movements will help them (re)learn how to move the affected body parts. But these traditional rehabilitation processes are usually repetitive and lengthy, reducing motivation and adherence to the treatment, and thus limiting the benefits for the patients. OBJECTIVE: Our goal was to create innovative neurorehabilitation therapies based on THERAPIST, a socially assistive robot. THERAPIST is an autonomous robot that is able to find and execute plans and adapt them to new situations in real-time. The software architecture of THERAPIST monitors and determines the course of action, learns from previous experiences, and interacts with people using verbal and non-verbal channels. THERAPIST can increase the adherence of the patient to the sessions using serious games. Data are recorded and can be used to tailor patient sessions. METHODS: We hypothesized that pediatric patients would engage better in a therapeutic non-physical interaction with a robot, facilitating the design of new therapies to improve patient motivation. We propose RoboCog, a novel cognitive architecture. This architecture will enhance the effectiveness and time-of-response of complex multi-degree-of-freedom robots designed to collaborate with humans, combining two core elements: a deep and hybrid representation of the current state, own, and observed; and a set of task-dependent planners, working at different levels of abstraction but connected to this central representation through a common interface. Using RoboCog, THERAPIST engages the human partner in an active interactive process. But RoboCog also endows the robot with abilities for high-level planning, monitoring, and learning. Thus, THERAPIST engages the patient through different games or activities, and adapts the session to each individual. RESULTS: RoboCog successfully integrates a deliberative planner with a set of modules working at situational or sensorimotor levels. This architecture also allows THERAPIST to deliver responses at a human rate. The synchronization of the multiple interaction modalities results from a unique scene representation or model. THERAPIST is now a socially interactive robot that, instead of reproducing the phrases or gestures that the developers decide, maintains a dialogue and autonomously generate gestures or expressions. THERAPIST is able to play simple games with human partners, which requires humans to perform certain movements, and also to capture the human motion, for later analysis by clinic specialists. CONCLUSIONS: The initial hypothesis was validated by our experimental studies showing that interaction with the robot results in highly attentive and collaborative attitudes in pediatric patients. We also verified that RoboCog allows the robot to interact with patients at human rates. However, there remain many issues to overcome. The development of novel hands-off rehabilitation therapies will require the intersection of multiple challenging directions of research that we are currently exploring.\"],\n",
    "[409,0,0,\"BACKGROUND: Advances in technology are allowing for the production of several viable wearable robotic devices to assist with activities of daily living and with rehabilitation. One of the most pressing limitations to user satisfaction is the lack of consistency in motion between the user and the robotic device. The displacement between the robot and the body segment may not correspond because of differences in skin and tissue compliance, mechanical backlash, and/or incorrect fit. FINDINGS: This report presents the results of an analysis of relative displacement between the user's hand and a wearable exoskeleton, the HX. HX has been designed to maximize comfort, wearability and user safety, exploiting chains with multiple degrees-of-freedom with a modular architecture. These appealing features may introduce several uncertainties in the kinematic performances, especially when considering the anthropometry, morphology and degree of mobility of the human hand. The small relative displacements between the hand and the exoskeleton were measured with a video-based motion capture system, while the user executed several different grips in different exoskeleton modes. CONCLUSIONS: The analysis furnished quantitative results about the device performance, differentiated among device modules and test conditions. In general, the global relative displacement for the distal part of the device was in the range 0.5-1.5 mm, while within 3 mm (worse but still acceptable) for displacements nearest to the hand dorsum. Conclusions over the HX design principles have been drawn, as well as guidelines for future developments.\"],\n",
    "[410,0,0,\"PURPOSE: Demographic change has resulted in an increase of elderly people, while at the same time the number of active working people is falling. In the future, there will be less caretaking, which is necessary to support the aging population. In order to enable the aged population to live in dignity, they should be able to perform activities of daily living (ADLs) as independently as possible. The aim of this paper is to describe several solutions and concepts that can support elderly people in their ADLs in a way that allows them to stay self-sufficient for as long as possible. METHOD: To reach this goal, the Building Realization and Robotics Lab is researching in the field of ambient assisted living. The idea is to implement robots and sensors in the home environment so as to efficiently support the inhabitants in their ADLs and eventually increase their independence. Through embedding vital sensors into furniture and using ICT technologies, the health status of elderly people can be remotely evaluated by a physician or family members. By investigating ergonomic aspects specific to elderly people (e.g. via an age-simulation suit), it is possible to develop and test new concepts and novel applications, which will offer innovative solutions. Via the introduction of mechatronics and robotics, the home environment can be made able to seamlessly interact with the inhabitant through gestures, vocal commands, and visual recognition algorithms. Meanwhile, several solutions have been developed that address how to build a smart home environment in order to create an ambient assisted environment. This article describes how these concepts were developed. The approach for each concept, proposed in this article, was performed as follows: (1) research of needs, (2) creating definitions of requirements, (3) identification of necessary technology and processes, (4) building initial concepts, (5) experiments in a real environment, and (6) development of the final concepts. To keep these concepts cost-effective, the suggested solutions are modular. Therefore, it will be possible to straightforwardly install the proposed devices in an existing home environment in a 'plug and play' manner once the terminals can be prefabricated off-site. RESULTS AND DISCUSSION: This article shows a variety of concepts that have been developed to support elderly people in their ADLs. The prototypes of the proposed concepts in this paper have been tested with elderly people. The results of the tests show that robots embedded in furniture, walls, ceiling, etc. offer enhanced support, properly addressing elderly as well as disabled people to individually and independently manage their ADLs. In order to make the concepts realizable in terms of cost, it will be necessary to standardize and modularize these concepts for industrial fabrication.\"],\n",
    "[411,0,0,\"This paper presents an extension of the time-domain passivity control approach to a four-channel bilateral controller under the effects of time delays. Time-domain passivity control has been used successfully to stabilize teleoperation systems with position-force and position-position controllers; however, the performance with such control architectures is sub-optimal both with and without time delays. This work extends the network representation of the time-domain passivity controller to the four-channel architecture, which provides perfect transparency to the user without time delay. The proposed architecture is based on modelling the controllers as dependent voltage sources and using only series passivity controllers. The obtained results are shown on a one degree-of-freedom setup and illustrate the stabilization behaviour of the proposed controller when time delay is present in the communication channel.\"],\n",
    "[412,0,0,\"In materials science, high performance is typically associated with regularity and order, while disorder and the presence of defects are assumed to lead to sub-optimal outcomes. This holds for traditional solids such as crystals as well as for many types of nanoscale devices. However, there are circumstances where disorder can be harnessed to achieve performance not possible with approaches based on regularity. Recent research has shown opportunities specifically for soft matter. There, the phenomenon of jamming leads to unique emergent behavior that enables disordered, amorphous systems to switch reversibly between solid-like rigidity and fluid-like plasticity. This makes it possible to envision materials that can change stiffness or even shape adaptively. We review some of the progress in this direction, discussing examples where jamming has been explored from micro to macro scales in colloidal systems, suspensions, granular-materials-enabled soft robotics, and architecture. We focus in particular on how the jammed aggregate state can be tailored by controlling particle level properties and discuss very recent ideas that provide an important first step toward actual design of specifically targeted jamming behavior.\"],\n",
    "[413,5,0,\"The cerebellum is involved in a large number of different neural processes, especially in associative learning and in fine motor control. To develop a comprehensive theory of sensorimotor learning and control, it is crucial to determine the neural basis of coding and plasticity embedded into the cerebellar neural circuit and how they are translated into behavioral outcomes in learning paradigms. Learning has to be inferred from the interaction of an embodied system with its real environment, and the same cerebellar principles derived from cell physiology have to be able to drive a variety of tasks of different nature, calling for complex timing and movement patterns. We have coupled a realistic cerebellar spiking neural network (SNN) with a real robot and challenged it in multiple diverse sensorimotor tasks. Encoding and decoding strategies based on neuronal firing rates were applied. Adaptive motor control protocols with acquisition and extinction phases have been designed and tested, including an associative Pavlovian task (Eye blinking classical conditioning), a vestibulo-ocular task and a perturbed arm reaching task operating in closed-loop. The SNN processed in real-time mossy fiber inputs as arbitrary contextual signals, irrespective of whether they conveyed a tone, a vestibular stimulus or the position of a limb. A bidirectional long-term plasticity rule implemented at parallel fibers-Purkinje cell synapses modulated the output activity in the deep cerebellar nuclei. In all tasks, the neurorobot learned to adjust timing and gain of the motor responses by tuning its output discharge. It succeeded in reproducing how human biological systems acquire, extinguish and express knowledge of a noisy and changing world. By varying stimuli and perturbations patterns, real-time control robustness and generalizability were validated. The implicit spiking dynamics of the cerebellar model fulfill timing, prediction and learning functions.\"],\n",
    "[414,0,0,\"The demand for bendable sensors increases constantly in the challenging field of soft and micro-scale robotics. We present here, in more detail, the flexible, functional, insect-inspired curved artificial compound eye (CurvACE) that was previously introduced in the Proceedings of the National Academy of Sciences (PNAS, 2013). This cylindrically-bent sensor with a large panoramic field-of-view of 180 degrees x 60 degrees composed of 630 artificial ommatidia weighs only 1.75 g, is extremely compact and power-lean (0.9 W), while it achieves unique visual motion sensing performance (1950 frames per second) in a five-decade range of illuminance. In particular, this paper details the innovative Very Large Scale Integration (VLSI) sensing layout, the accurate assembly fabrication process, the innovative, new fast read-out interface, as well as the auto-adaptive dynamic response of the CurvACE sensor. Starting from photodetectors and microoptics on wafer substrates and flexible printed circuit board, the complete assembly of CurvACE was performed in a planar configuration, ensuring high alignment accuracy and compatibility with state-of-the art assembling processes. The characteristics of the photodetector of one artificial ommatidium have been assessed in terms of their dynamic response to light steps. We also characterized the local auto-adaptability of CurvACE photodetectors in response to large illuminance changes: this feature will certainly be of great interest for future applications in real indoor and outdoor environments.\"],\n",
    "[415,5,0,\"BACKGROUND: Spinal-like regulators have recently been shown to support complex behavioral patterns during volitional goal-oriented reaching paradigms. We use an interpretation of the adaptive spinal-like controller as inspiration for the development of a controller for a robotic limb. It will be demonstrated that a simulated robot arm with linear actuators can achieve biological-like limb movements. In addition, it will be shown that programmability in the regulator enables independent spatial and temporal changes to be defined for movement tasks, downstream of central commands using sensory stimuli. The adaptive spinal-like controller is the first to demonstrate such behavior for complex motor behaviors in multi-joint limb movements. METHODS: The controller is evaluated using a simulated robotic apparatus and three goal-oriented reaching paradigms: 1) shaping of trajectory profiles during reaching; 2) sensitivity of trajectories to sudden perturbations; 3) reaching to a moving target. The experiments were designed to highlight complex motor tasks that are omitted in earlier studies, and important for the development of improved artificial limb control. RESULTS: In all three cases the controller was able to reach the targets without a priori planning of end-point or segmental motor trajectories. Instead, trajectory spatio-temporal dynamics evolve from properties of the controller architecture using the spatial error (vector distance to goal). Results show that curvature amplitude in hand trajectory paths are reduced by as much as 98% using simple gain scaling techniques, while adaptive network behavior allows the regulator to successfully adapt to perturbations and track a moving target. An important observation for this study is that all motions resemble human-like movements with non-linear muscles and complex joint mechanics. CONCLUSIONS: The controller shows that it can adapt to various behavioral contexts which are not included in previous biomimetic studies. The research supplements an earlier study by examining the tunability of the spinal-like controller for complex reaching tasks. This work is a step toward building more robust controllers for powered artificial limbs.\"],\n",
    "[416,0,0,\"In this work we propose a proof of principle that dynamic causal modelling can identify plausible mechanisms at the synaptic level underlying brain state changes over a timescale of seconds. As a benchmark example for validation we used intracranial electroencephalographic signals in a human subject. These data were used to infer the (effective connectivity) architecture of synaptic connections among neural populations assumed to generate seizure activity. Dynamic causal modelling allowed us to quantify empirical changes in spectral activity in terms of a trajectory in parameter space - identifying key synaptic parameters or connections that cause observed signals. Using recordings from three seizures in one patient, we considered a network of two sources (within and just outside the putative ictal zone). Bayesian model selection was used to identify the intrinsic (within-source) and extrinsic (between-source) connectivity. Having established the underlying architecture, we were able to track the evolution of key connectivity parameters (e.g., inhibitory connections to superficial pyramidal cells) and test specific hypotheses about the synaptic mechanisms involved in ictogenesis. Our key finding was that intrinsic synaptic changes were sufficient to explain seizure onset, where these changes showed dissociable time courses over several seconds. Crucially, these changes spoke to an increase in the sensitivity of principal cells to intrinsic inhibitory afferents and a transient loss of excitatory-inhibitory balance.\"],\n",
    "[417,0,0,\"Speech is a complex skill to master. In addition to sophisticated phono-articulatory abilities, speech acquisition requires neuronal systems configured for vocal learning, with adaptable sensorimotor maps that couple heard speech sounds with motor programs for speech production; imitation and self-imitation mechanisms that can train the sensorimotor maps to reproduce heard speech sounds; and a 'pedagogical' learning environment that supports tutor learning.\"],\n",
    "[418,0,0,\"In minimally invasive surgery methods such as laparoscopic surgery, surgical instruments are introduced through small incisions to minimize patient trauma and recovery times. To reduce the number of incisions, new techniques such as natural orifice transluminal endoscopic surgery (NOTES) have been proposed. Compared to laparoscopic surgery, the NOTES approach, which requires new technology and improved instruments, presents some unique challenges. Robotic NOTES (R-NOTES) could be an enabling technology for these procedures. In this paper, we first review relevant work in R-NOTES. We then present our work and the system architecture for an R-NOTES prototype system incorporating wireless command and control. The system was tested twice in swine animal studies.\"],\n",
    "[419,0,0,\"Hyper-redundant (or snakelike) manipulators have many more degrees of freedom than are required to position and orient an object in space. They have been employed in a variety of applications ranging from search-and-rescue to minimally invasive surgical procedures, and recently they even have been proposed as solutions to problems in maintaining civil infrastructure and the repair of satellites. The kinematic and dynamic properties of snakelike robots are captured naturally using a continuum backbone curve equipped with a naturally evolving set of reference frames, stiffness properties, and mass density. When the snakelike robot has a continuum architecture, the backbone curve corresponds with the physical device itself. Interestingly, these same modeling ideas can be used to describe conformational shapes of DNA molecules and filamentous protein structures in solution and in cells. This paper reviews several classes of snakelike robots: (1) hyper-redundant manipulators guided by backbone curves; (2) flexible steerable needles; and (3) concentric tube continuum robots. It is then shown how the same mathematical modeling methods used in these robotics contexts can be used to model molecules such as DNA. All of these problems are treated in the context of a common mathematical framework based on the differential geometry of curves, continuum mechanics, and variational calculus. Both coordinate-dependent Euler-Lagrange formulations and coordinate-free Euler-Poincare approaches are reviewed.\"],\n",
    "[420,0,0,\"Recent efforts to develop large-scale brain and neurocognitive architectures have paid relatively little attention to the use of self-organizing maps (SOMs). Part of the reason for this is that most conventional SOMs use a static encoding representation: each input pattern or sequence is effectively represented as a fixed point activation pattern in the map layer, something that is inconsistent with the rhythmic oscillatory activity observed in the brain. Here we develop and study an alternative encoding scheme that instead uses sparsely-coded limit cycles to represent external input patterns/sequences. We establish conditions under which learned limit cycle representations arise reliably and dominate the dynamics in a SOM. These limit cycles tend to be relatively unique for different inputs, robust to perturbations, and fairly insensitive to timing. In spite of the continually changing activity in the map layer when a limit cycle representation is used, map formation continues to occur reliably. In a two-SOM architecture where each SOM represents a different sensory modality, we also show that after learning, limit cycles in one SOM can correctly evoke corresponding limit cycles in the other, and thus there is the potential for multi-SOM systems using limit cycles to work effectively as hetero-associative memories. While the results presented here are only first steps, they establish the viability of SOM models based on limit cycle activity patterns, and suggest that such models merit further study.\"],\n",
    "[421,0,0,\"This paper describes a novel controller, intended for use in a lower-limb exoskeleton, to aid gait rehabilitation in patients with hemiparesis after stroke. The controller makes use of gravity compensation, feedforward movement assistance, and reinforcement of isometric joint torques to achieve assistance without dictating the spatiotemporal nature of joint movement. The patient is allowed to self-select walking speed and is able to make trajectory adaptations to maintain balance without interference from the controller. The governing equations and the finite state machine which comprise the system are described herein. The control architecture was implemented in a lower-limb exoskeleton and a preliminary experimental assessment was conducted in which a patient with hemiparesis resulting from stroke walked with assistance from the exoskeleton. The patient exhibited improvements in fast gait speed, step length asymmetry, and stride length in each session, as measured before and after exoskeleton training, presumably as a result of using the exoskeleton.\"],\n",
    "[422,0,0,\"As the field of brain-machine interfaces and neuro-prosthetics continues to grow, there is a high need for sensor and actuation mechanisms that can provide haptic feedback to the user. Current technologies employ expensive, invasive and often inefficient force feedback methods, resulting in an unrealistic solution for individuals who rely on these devices. This paper responds through the development, integration and analysis of a novel feedback architecture where haptic information during the neural control of a prosthetic hand is perceived through multi-frequency auditory signals. Through representing force magnitude with volume and force location with frequency, the feedback architecture can translate the haptic experiences of a robotic end effector into the alternative sensory modality of sound. Previous research with the proposed cross-modal feedback method confirmed its learnability, so the current work aimed to investigate which frequency map (i.e. frequency-specific locations on the hand) is optimal in helping users distinguish between hand-held objects and tasks associated with them. After short use with the cross-modal feedback during the electromyographic (EMG) control of a prosthetic hand, testing results show that users are able to use audial feedback alone to discriminate between everyday objects. While users showed adaptation to three different frequency maps, the simplest map containing only two frequencies was found to be the most useful in discriminating between objects. This outcome provides support for the feasibility and practicality of the cross-modal feedback method during the neural control of prosthetics.\"],\n",
    "[423,0,0,\"The quintessential living element of all organisms is the cell-a fluid-filled compartment enclosed, but not isolated, by a layer of amphiphilic molecules that self-assemble at its boundary. Cells of different composition can aggregate and communicate through the exchange of molecules across their boundaries. The astounding success of this architecture is readily apparent throughout the biological world. Inspired by the versatility of nature's architecture, we investigate aggregates of membrane-enclosed droplets as a design concept for robotics. This will require droplets capable of sensing, information processing, and actuation. It will also require the integration of functionally specialized droplets into an interconnected functional unit. Based on results from the literature and from our own laboratory, we argue the viability of this approach. Sensing and information processing in droplets have been the subject of several recent studies, on which we draw. Integrating droplets into coherently acting units and the aspect of controlled actuation for locomotion have received less attention. This article describes experiments that address both of these challenges. Using lipid-coated droplets of Belousov-Zhabotinsky reaction medium in oil, we show here that such droplets can be integrated and that chemically driven mechanical motion can be achieved.\"],\n",
    "[424,0,0,\"This article will focus on recent reports that have applied three-dimensional (3D) printing for designing millimeter to micrometer architecture for robotic motility. The utilization of 3D printing has rapidly grown in applications for medical prosthetics and scaffolds for organs and tissue, but more recently has been implemented for designing mobile robotics. With an increase in the demand for devices to perform in fragile and confined biological environments, it is crucial to develop new miniaturized, biocompatible 3D systems. Fabrication of materials at different scales with different properties makes 3D printing an ideal system for creating frameworks for small-scale robotics. 3D printing has been applied for the design of externally powered, artificial microswimmers and studying their locomotive capabilities in different fluids. Printed materials have also been incorporated with motile cells for bio-hybrid robots capable of functioning by cell contraction and swimming. These 3D devices offer new methods of robotic motility for biomedical applications requiring miniature structures. Traditional 3D printing methods, where a structure is fabricated in an additive process from a digital design, and non-traditional 3D printing methods, such as lithography and molding, will be discussed.\"],\n",
    "[425,0,0,\"Recent progress in bioresorbable radio frequency electronics and engineered bacteria has promised the prospect of realizing a transient microbot (TM) system for therapeutic applications. The inorganic or organic miniature robots will dissolve into the human body after completing the required tasks and cause no side-effect. In this paper, we propose a potential architecture of a TM system for transporting pharmaceutical compounds inside the body, and analyze the system using a micro-to-macro cross-scale communication model. The remote controllability and tangibility of a TM essentially lead to a touch-communication (TouchCom) paradigm. Externally maneuverable and trackable TMs are responsible for the delivery of drug particles (information molecules in the TouchCom context). The loading/injection and unloading of the drug correspond to the transmitting and receiving processes in the TouchCom framework. Subsequently, we investigate simulation tools for the propagation and transient characteristics of TMs in the blood vessels. We also define the propagation delay, path loss, as well as angular and delay spectra of targeting intensity, which are parallel to their counterpart concepts in the conventional wireless channel. Finally, our approach is illustrated with comprehensive simulation studies of targeted drug delivery by using the proposed analytical framework integrating robotics and communications at crossover length scales. The proposed methodology may find important applications in the design and analysis of TM-assisted administration of pharmaceutical compounds.\"],\n",
    "[426,9,1,\"This paper describes a supervisor system for monitoring the operation of automated agricultural vehicles. The system analyses all of the information provided by the sensors and subsystems on the vehicles in real time and notifies the user when a failure or potentially dangerous situation is detected. In some situations, it is even able to execute a neutralising protocol to remedy the failure. The system is based on a distributed and multi-level architecture that divides the supervision into different subsystems, allowing for better management of the detection and repair of failures. The proposed supervision system was developed to perform well in several scenarios, such as spraying canopy treatments against insects and diseases and selective weed treatments, by either spraying herbicide or burning pests with a mechanical-thermal actuator. Results are presented for selective weed treatment by the spraying of herbicide. The system successfully supervised the task; it detected failures such as service disruptions, incorrect working speeds, incorrect implement states, and potential collisions. Moreover, the system was able to prevent collisions between vehicles by taking action to avoid intersecting trajectories. The results show that the proposed system is a highly useful tool for managing fleets of autonomous vehicles. In particular, it can be used to manage agricultural vehicles during treatment operations.\"],\n",
    "[427,5,0,\"The cerebellum plays a crucial role in motor learning and it acts as a predictive controller. Modeling it and embedding it into sensorimotor tasks allows us to create functional links between plasticity mechanisms, neural circuits and behavioral learning. Moreover, if applied to real-time control of a neurorobot, the cerebellar model has to deal with a real noisy and changing environment, thus showing its robustness and effectiveness in learning. A biologically inspired cerebellar model with distributed plasticity, both at cortical and nuclear sites, has been used. Two cerebellum-mediated paradigms have been designed: an associative Pavlovian task and a vestibulo-ocular reflex, with multiple sessions of acquisition and extinction and with different stimuli and perturbation patterns. The cerebellar controller succeeded to generate conditioned responses and finely tuned eye movement compensation, thus reproducing human-like behaviors. Through a productive plasticity transfer from cortical to nuclear sites, the distributed cerebellar controller showed in both tasks the capability to optimize learning on multiple time-scales, to store motor memory and to effectively adapt to dynamic ranges of stimuli.\"],\n",
    "[428,0,0,\"A large array of neuroscientific techniques, including in vivo electrophysiology, two-photon imaging, optogenetics, lesions, and microdialysis, require access to the brain through the skull. Ideally, the necessary craniotomies could be performed in a repeatable and automated fashion, without damaging the underlying brain tissue. Here we report that when drilling through the skull a stereotypical increase in conductance can be observed when the drill bit passes through the skull base. We present an architecture for a robotic device that can perform this algorithm, along with two implementations--one based on homebuilt hardware and one based on commercially available hardware--that can automatically detect such changes and create large numbers of precise craniotomies, even in a single skull. We also show that this technique can be adapted to automatically drill cranial windows several millimeters in diameter. Such robots will not only be useful for helping neuroscientists perform both small and large craniotomies more reliably but can also be used to create precisely aligned arrays of craniotomies with stereotaxic registration to standard brain atlases that would be difficult to drill by hand.\"],\n",
    "[429,0,0,\"The path that humans take while walking to a goal is the result of a cognitive process modulated by the perception of the environment and physiological constraints. The path shape and timing implicitly embeds aspects of the architecture behind this process. Here, locomotion paths were investigated during a simple task of walking to and from a goal, by looking at the evolution of the position of the human on a horizontal (x,y) plane. We found that the path while walking to a goal was not the same as that while returning from it. Forward-return paths were systematically separated by 0.5-1.9m, or about 5% of the goal distance. We show that this path separation occurs as a consequence of anticipating the desired body orientation at the goal while keeping the target in view. The magnitude of this separation was strongly influenced by the bearing angle (difference between body orientation and angle to goal) and the final orientation imposed at the goal. This phenomenon highlights the impact of a trade-off between a directional perceptual apparatus-eyes in the head on the shoulders-and and physiological limitations, in the formation of human locomotion paths. Our results give an insight into the influence of environmental and perceptual variables on human locomotion and provide a basis for further mathematical study of these mechanisms.\"],\n",
    "[430,5,0,\"Learning and reproducing temporal sequences is a fundamental ability used by living beings to adapt behaviour repertoire to environmental constraints. This paper is focused on the description of a model based on spiking neurons, able to learn and autonomously generate a sequence of events. The neural architecture is inspired by the insect Mushroom Bodies (MBs) that are a crucial centre for multimodal sensory integration and behaviour modulation. The sequence learning capability coexists, within the insect brain computational model, with all the other features already addressed like attention, expectation, learning classification and others. This is a clear example that a unique neural structure is able to cope concurrently with a plethora of behaviours. Simulation results and robotic experiments are reported and discussed.\"],\n",
    "[431,5,0,\"Information coding in the Central Nervous System (CNS) remains unexplored. There is mounting evidence that, even at a very low level, the representation of a given stimulus might be dependent on context and history. If this is actually the case, bi-directional interactions between the brain (or if need be a reduced model of it) and sensory-motor system can shed a light on how encoding and decoding of information is performed. Here an experimental system is introduced and described in which the activity of a neuronal element (i.e., a network of neurons extracted from embryonic mammalian hippocampi) is given context and used to control the movement of an artificial agent, while environmental information is fed back to the culture as a sequence of electrical stimuli. This architecture allows a quick selection of diverse encoding, decoding, and learning algorithms to test different hypotheses on the computational properties of neuronal networks.\"],\n",
    "[432,0,0,\"In the present study, a new architecture for the generation of grid cells (GC) was implemented on a real robot. In order to test this model a simple place cell (PC) model merging visual PC activity and GC was developed. GC were first built from a simple 'several to one' projection (similar to a modulo operation) performed on a neural field coding for path integration (PI). Robotics experiments raised several practical and theoretical issues. To limit the important angular drift of PI, head direction information was introduced in addition to the robot proprioceptive signal coming from the wheel rotation. Next, a simple associative learning between visual place cells and the neural field coding for the PI has been used to recalibrate the PI and to limit its drift. Finally, the parameters controlling the shape of the PC built from the GC have been studied. Increasing the number of GC obviously improves the shape of the resulting place field. Yet, other parameters such as the discretization factor of PI or the lateral interactions between GC can have an important impact on the place field quality and avoid the need of a very large number of GC. In conclusion, our results show our GC model based on the compression of PI is congruent with neurobiological studies made on rodent. GC firing patterns can be the result of a modulo transformation of PI information. We argue that such a transformation may be a general property of the connectivity from the cortex to the entorhinal cortex. Our model predicts that the effect of similar transformations on other kinds of sensory information (visual, tactile, auditory, etc...) in the entorhinal cortex should be observed. Consequently, a given EC cell should react to non-contiguous input configurations in non-spatial conditions according to the projection from its different inputs.\"],\n",
    "[433,0,0,\"KEY POINTS: It is often assumed that central pattern generators, which generate rhythmic patterns without rhythmic inputs, play a key role in the spinal control of human locomotion. We propose a neural control model in which the spinal control generates muscle stimulations mainly through integrated reflex pathways with no central pattern generator. Using a physics-based neuromuscular human model, we show that this control network is sufficient to compose steady and transitional 3-D locomotion behaviours, including walking and running, acceleration and deceleration, slope and stair negotiation, turning, and deliberate obstacle avoidance. The results suggest feedback integration to be functionally more important than central pattern generation in human locomotion across behaviours. In addition, the proposed control architecture may serve as a guide in the search for the neurophysiological origin and circuitry of spinal control in humans. ABSTRACT: Neural networks along the spinal cord contribute substantially to generating locomotion behaviours in humans and other legged animals. However, the neural circuitry involved in this spinal control remains unclear. We here propose a specific circuitry that emphasizes feedback integration over central pattern generation. The circuitry is based on neurophysiologically plausible muscle-reflex pathways that are organized in 10 spinal modules realizing limb functions essential to legged systems in stance and swing. These modules are combined with a supraspinal control layer that adjusts the desired foot placements and selects the leg that is to transition into swing control during double support. Using physics-based simulation, we test the proposed circuitry in a neuromuscular human model that includes neural transmission delays, musculotendon dynamics and compliant foot-ground contacts. We find that the control network is sufficient to compose steady and transitional 3-D locomotion behaviours including walking and running, acceleration and deceleration, slope and stair negotiation, turning, and deliberate obstacle avoidance. The results suggest feedback integration to be functionally more important than central pattern generation in human locomotion across behaviours. In addition, the proposed control architecture may serve as a guide in the search for the neurophysiological origin and circuitry of spinal control in humans.\"],\n",
    "[434,0,0,\"Medical drills are subject to intensive wear due to mechanical factors which occur during the bone drilling process, and potential thermal and chemical factors related to the sterilisation process. Intensive wear increases friction between the drill and the surrounding bone tissue, resulting in higher drilling temperatures and cutting forces. Therefore, the goal of this experimental research was to develop a drill wear classification model based on multi-sensor approach and artificial neural network algorithm. A required set of tool wear features were extracted from the following three types of signals: cutting forces, servomotor drive currents and acoustic emission. Their capacity to classify precisely one of three predefined drill wear levels has been established using a pattern recognition type of the Radial Basis Function Neural Network algorithm. Experiments were performed on a custom-made test bed system using fresh bovine bones and standard medical drills. Results have shown high classification success rate, together with the model robustness and insensitivity to variations of bone mechanical properties. Features extracted from acoustic emission and servomotor drive signals achieved the highest precision in drill wear level classification (92.8%), thus indicating their potential in the design of a new type of medical drilling machine with process monitoring capabilities.\"],\n",
    "[435,0,0,\"The brain operates through the coordinated activation and the dynamic communication of neuronal assemblies. A major open question is how a vast repertoire of dynamical motifs, which underlie most diverse brain functions, can emerge out of a fixed topological and modular organization of brain circuits. Compared to in vivo studies of neuronal circuits which present intrinsic experimental difficulties, in vitro preparations offer a much larger possibility to manipulate and probe the structural, dynamical and chemical properties of experimental neuronal systems. This work describes an in vitro experimental methodology which allows growing of modular networks composed by spatially distinct, functionally interconnected neuronal assemblies. The protocol allows controlling the two-dimensional (2D) architecture of the neuronal network at different levels of topological complexity. A desired network patterning can be achieved both on regular cover slips and substrate embedded micro electrode arrays. Micromachined structures are embossed on a silicon wafer and used to create biocompatible polymeric stencils, which incorporate the negative features of the desired network architecture. The stencils are placed on the culturing substrates during the surface coating procedure with a molecular layer for promoting cellular adhesion. After removal of the stencils, neurons are plated and they spontaneously redirected to the coated areas. By decreasing the inter-compartment distance, it is possible to obtain either isolated or interconnected neuronal circuits. To promote cell survival, cells are co-cultured with a supporting neuronal network which is located at the periphery of the culture dish. Electrophysiological and optical recordings of the activity of modular networks obtained respectively by using substrate embedded micro electrode arrays and calcium imaging are presented. While each module shows spontaneous global synchronizations, the occurrence of inter-module synchronization is regulated by the density of connection among the circuits.\"],\n",
    "[436,0,0,\"Traditional methods of rehabilitation require continuous attention of therapists during the therapy sessions. This is a hard and expensive task in terms of time and effort. In many cases, the therapeutic objectives cannot be achieved due to the overwork or the difficulty for therapists to plan accurate sessions according to the medical criteria. For this purpose, a wide range of studies is opened in order to research new ways of rehabilitation, as in the field of social robotics. This work presents the current state of the THERAPIST project. Our main goal is to develop a cognitive architecture which provides a robot with enough autonomy to carry out an upper-limb rehabilitation therapy for patients with physical impairments, such as Cerebral Palsy and Obstetric Brachial Plexus Palsy.\"],\n",
    "[437,9,1,\"Convergent evidence suggests that the lateral frontal cortex is at the heart of a brain network subserving cognitive control. Recent theories assume a functional segregation along the rostro-caudal axis of the lateral frontal cortex based on differences in the degree of complexity of cognitive control. However, the functional contribution of specific rostral and caudal sub-regions remains elusive. Here we investigate the impact of disrupting rostral and caudal target regions on cognitive control processes, using Transcranial Magnetic Stimulation (TMS). Participants performed three different task-switching conditions that assessed differences in the degree of complexity of cognitive control processes, after temporally disrupting rostral, or caudal target regions, or a control region. Disrupting the rostral lateral frontal region specifically impaired behavioral performance of the most complex task-switching condition, in comparison to the caudal target region and the control region. These novel findings shed light on the neuroanatomical architecture supporting control over goal-directed behavior.\"],\n",
    "[438,0,0,\"Growing interest in the development of bio-inspired autonomous underwater vehicles (AUVs) has motivated research in understanding the mechanisms behind the propulsion systems of marine animals. For example, the locomotive behavior of rays (Batoidea) by movement of the pectoral fins is of particular interest due to their superior performance characteristics over contemporary AUV propulsion systems. To better understand the mechanics of pectoral fin propulsion, this paper introduces a biomechanical model that simulates how batoid skeletal structures function to achieve the swimming locomotion observed in nature. Two rays were studied, Dasyatis sabina (Atlantic ray), and Rhinoptera bonasus (cownose ray). These species were selected because they exhibit very different swimming styles (undulation versus oscillation), but all use primarily their pectoral fins for propulsion (unlike electric rays or guitarfishes). Computerized tomography scans of each species were taken to image the underlying structure, which reveal a complex system of cartilaginous joints and linkages. Data collected from these images were used to quantify the complete skeletal morphometry of each batoid fin. Morphological differences were identified in the internal cartilage arrangement between each species including variations in the orientation of the skeletal elements, or radials, and the joint patterns between them, called the inter-radial joint pattern. These data were used as the primary input into the biomechanical model to couple a given ray skeletal structure with various swimming motions. A key output of the model is an estimation of the uniaxial strain that develops in the skeletal connective tissue in order for the structure to achieve motions observed during swimming. Tensile load tests of this connective tissue were conducted to further investigate the implications of the material strain predictions. The model also demonstrates that changes in the skeletal architecture (e.g., joint positioning) will effect fin deformation characteristics. Ultimately, the results of this study can be used to guide the design of optimally performing bio-inspired AUVs.\"],\n",
    "[439,5,0,\"For specific purpose, vision-based surveillance robot that can be run autonomously and able to acquire images from its dynamic environment is very important, for example, in rescuing disaster victims in Indonesia. In this paper, we propose architecture for intelligent surveillance robot that is able to avoid obstacles using 3 ultrasonic distance sensors based on backpropagation neural network and a camera for face recognition. 2.4 GHz transmitter for transmitting video is used by the operator/user to direct the robot to the desired area. Results show the effectiveness of our method and we evaluate the performance of the system.\"],\n",
    "[440,0,0,\"This paper considers a decentralized fault tolerant control (DFTC) scheme for reconfigurable manipulators. With the appearance of norm-bounded failure, a dual closed-loop trajectory tracking control algorithm is proposed on the basis of the Lyapunov stability theory. Characterized by the modularization property, the actuator failure is estimated by the proposed decentralized sliding mode observer (DSMO). Moreover, the actuator failure can be treated in view of the local joint information, so its control performance degradation is independent of other normal joints. In addition, the presented DFTC scheme is significantly simplified in terms of the structure of the controller due to its dual closed-loop architecture, and its feasibility is highly reflected in the control of reconfigurable manipulators. Finally, the effectiveness of the proposed DFTC scheme is demonstrated using simulations.\"],\n",
    "[441,0,0,\"The mammalian visual system has been extensively studied since Hubel and Wiesel's work on cortical feature maps in the 1960s. Feature maps representing the cortical neurons' ocular dominance, orientation and direction preferences have been well explored experimentally and computationally. The predominant view has been that direction selectivity (DS) in particular, is a feature entirely dependent upon visual experience and as such does not exist prior to eye opening (EO). However, recent experimental work has shown that there is in fact a DS bias already present at EO. In the current work we use a computational model to reproduce the main results of this experimental work and show that the DS bias present at EO could arise purely from the cortical architecture without any explicit coding for DS and prior to any self-organising process facilitated by spontaneous activity or training. We explore how this latent DS (and its corresponding cortical map) is refined by training and that the time-course of development exhibits similar features to those seen in the experimental study. In particular we show that the specific cortical connectivity or 'proto-architecture' is required for DS to mature rapidly and correctly with visual experience.\"],\n",
    "[442,0,0,\"The basal ganglia (BG) comprise multiple subcortical nuclei, which are responsible for cognition and other functions. Developing a brain-machine interface (BMI) demands a suitable solution for the real-time implementation of a portable BG. In this study, we used a digital hardware implementation of a BG network containing 256 modified Izhikevich neurons and 2048 synapses to reliably reproduce the biological characteristics of BG on a single field programmable gate array (FPGA) core. We also highlighted the role of Parkinsonian analysis by considering neural dynamics in the design of the hardware-based architecture. Thus, we developed a multi-precision architecture based on a precise analysis using the FPGA-based platform with fixed-point arithmetic. The proposed embedding BG network can be applied to intelligent agents and neurorobotics, as well as in BMI projects with clinical applications. Although we only characterized the BG network with Izhikevich models, the proposed approach can also be extended to more complex neuron models and other types of functional networks.\"],\n",
    "[443,0,0,\"Biofeedback from physical rehabilitation exercises has proved to lead to faster recovery, better outcomes, and increased patient motivation. In addition, it allows the physical rehabilitation processes carried out at the clinic to be complemented with exercises performed at home. However, currently existing approaches rely mostly on audio and visual reinforcement cues, usually presented to the user on a computer screen or a mobile phone interface. Some users, such as elderly people, can experience difficulties to use and understand these interfaces, leading to non-compliance with the rehabilitation exercises. To overcome this barrier, latest biosignal technologies can be used to enhance the efficacy of the biofeedback, decreasing the complexity of the user interface. In this paper we propose and validate a context-aware framework for the use of animatronic biofeedback, as a way of potentially increasing the compliance of elderly users with physical rehabilitation exercises performed at home. In the scope of our work, animatronic biofeedback entails the use of pre-programmed actions on a robot that are triggered in response to certain changes detected in the users biomechanical or electrophysiological signals. We use electromyographic and accelerometer signals, collected in real time, to monitor the performance of the user while executing the exercises, and a mobile robot to provide animatronic reinforcement cues associated with their correct or incorrect execution. A context-aware application running on a smartphone aggregates the sensor data and controls the animatronic feedback. The acceptability of the animatronic biofeedback has been tested on a set of volunteer elderly users, and results suggest that the participants found the animatronic feedback engaging and of added value.\"],\n",
    "[444,0,0,\"Creating android and humanoid robots to furnish companionship in the nursing care of older people continues to attract substantial development capital and research. Some people object, though, that machines of this kind furnish human-robot interaction characterized by inauthentic relationships. In particular, robotic and artificial intelligence (AI) technologies have been charged with substituting mindless mimicry of human behaviour for the real presence of conscious caring offered by human nurses. When thus viewed as deceptive, the robots also have prompted corresponding concerns regarding their potential psychological, moral, and spiritual implications for people who will be interacting socially with these machines. The foregoing objections and concerns can be assessed quite differently, depending upon ambient religious beliefs or metaphysical presuppositions. The complaints may be set aside as unnecessary, for example, within religious traditions for which even current robots can be viewed as presenting spiritual aspects. Elsewhere, technological cultures may reject the complaints as expression of outdated superstition, holding that the machines eventually will enjoy a consciousness described entirely in materialist and behaviourist terms. While recognizing such assessments, the authors of this essay propose that the heart of the foregoing objections and concerns may be evaluated, in part, scientifically - albeit with a conclusion recommending fundamental revisions in AI modelling of human mental life. Specifically, considerations now favour introduction of AI models using interactive classical and quantum computation. Without this change, the answer to the essay's title question arguably is 'no' - with it, the answer plausibly becomes 'maybe'. Either outcome holds very interesting implications for nurses.\"],\n",
    "[445,5,0,\"In embodied computation (or morphological computation), part of the complexity of motor control is offloaded to the body dynamics. We demonstrate that a simple Hebbian-like learning rule can be used to train systems with (partial) embodiment, and can be extended outside of the scope of traditional neural networks. To this end, we apply the learning rule to optimize the connection weights of recurrent neural networks with different topologies and for various tasks. We then apply this learning rule to a simulated compliant tensegrity robot by optimizing static feedback controllers that directly exploit the dynamics of the robot body. This leads to partially embodied controllers, i.e., hybrid controllers that naturally integrate the computations that are performed by the robot body into a neural network architecture. Our results demonstrate the universal applicability of reward-modulated Hebbian learning. Furthermore, they demonstrate the robustness of systems trained with the learning rule. This study strengthens our belief that compliant robots should or can be seen as computational units, instead of dumb hardware that needs a complex controller. This link between compliant robotics and neural networks is also the main reason for our search for simple universal learning rules for both neural networks and robotics.\"],\n",
    "[446,0,0,\"Autism spectrum disorder (ASD) impacts 1 in 68 children in the U.S., with tremendous individual and societal costs. Technology-aided intervention, more specifically robotic intervention, has gained momentum in recent years due to the inherent affinity of many children with ASD towards technology. In this paper we present a novel robot-mediated intervention system for imitation skill learning, which is considered a core deficit area for children with ASD. The Robot-mediated Imitation Skill Training Architecture (RISTA) is designed in such a manner that it can operate either completely autonomously or in coordination with a human therapist depending on the intervention need. Experimental results are presented from small user studies validating system functionality, assessing user tolerance, and documenting subject performance. Preliminary results show that this novel robotic system draws more attention from the children with ASD and teaches gestures more effectively as compared to a human therapist. While no broad generalized conclusions can be made about the effectiveness of RISTA based on our small user studies, initial results are encouraging and justify further exploration in the future.\"],\n",
    "[447,0,0,\"High compliant legs are essential for the efficient versatile locomotion and shock absorbency of humans. This study proposes a biped robot actuated by pneumatic artificial muscles to mimic human locomotion. On the basis of the musculoskeletal architecture of human lower limbs, each leg of the biped robot is modeled as a system of three segments, namely, hip joint, knee joint, and ankle joint, and eleven muscles, including both monoarticular and biarticular muscles. Each rotational joint is driven by a pair of antagonistic muscles, enabling joint compliance to be tuned by operating the pressure inside the muscles. Biarticular muscles play an important role in transferring power between joints. Walking simulations verify that biarticular muscles contribute to joint compliance and can absorb impact energy when the robot makes an impact upon ground contact.\"],\n",
    "[448,0,0,\"Synthetic micro-/nanomotors (MNMs) are capable of performing self-propelled motion in fluids through harvesting different types of energies into mechanical movement, with potential applications in biomedicine and other fields. To address the challenges in these applications, a promising strategy that combines controlled assembly (bottom-up approaches) with top-down approaches for engineering autonomous, multifunctionalized MNMs is under investigation, beginning in 2012. These MNMs, derived from layer-by-layer assembly or molecular self-assembly, display the advantages of: i) mass production, ii) response to the external stimuli, and iii) access to multifunctionality, biocompatibility, and biodegradability. The advance on how to integrate diverse functional components into different architectures based on controlled assemblies, to realize controlled fabrication, motion control (including the movement speed, direction, and state), and biomedical applications of MNMs, directed by the concept of nanoarchitectonics, are highlighted here. The remaining challenges and future research directions are also discussed.\"],\n",
    "[449,1,0,\"This article presents a Lyapunov function based neural network tracking (LNT) strategy for single-input, single-output (SISO) discrete-time nonlinear dynamic systems. The proposed LNT architecture is composed of two feedforward neural networks operating as controller and estimator. A Lyapunov function based back propagation learning algorithm is used for online adjustment of the controller and estimator parameters. The controller and estimator error convergence and closed-loop system stability analysis is performed by Lyapunov stability theory. Moreover, two simulation examples and one real-time experiment are investigated as case studies. The achieved results successfully validate the controller performance.\"],\n",
    "[450,0,0,\"To investigate how cells sense stiffness in settings structurally similar to native extracellular matrices, we designed a synthetic fibrous material with tunable mechanics and user-defined architecture. In contrast to flat hydrogel surfaces, these fibrous materials recapitulated cell-matrix interactions observed with collagen matrices including stellate cell morphologies, cell-mediated realignment of fibres, and bulk contraction of the material. Increasing the stiffness of flat hydrogel surfaces induced mesenchymal stem cell spreading and proliferation; however, increasing fibre stiffness instead suppressed spreading and proliferation for certain network architectures. Lower fibre stiffness permitted active cellular forces to recruit nearby fibres, dynamically increasing ligand density at the cell surface and promoting the formation of focal adhesions and related signalling. These studies demonstrate a departure from the well-described relationship between material stiffness and spreading established with hydrogel surfaces, and introduce fibre recruitment as a previously undescribed mechanism by which cells probe and respond to mechanics in fibrillar matrices.\"],\n",
    "[451,0,0,\"The scaling paradigm known as Moore's Law, with the shrinking of transistors and their doubling on a chip every two years, is going to reach a painful end. Another less-known paradigm, the so-called Koomey's Law, stating that the computing efficiency doubles every 1.57 years, poses other important challenges, since the efficiency of rechargeable energy sources is substantially constant, and any other evolution is based on device architecture only. How can we still increase the computational power/reduce the power consumption of our electronic environments? A first answer to this question comes from the quest for new functionalities. Within this aim, negative capacitance (NC) is becoming one of the most intriguing and studied phenomena since it can be exploited for reducing the aforementioned limiting effects in the downscaling of electronic devices. Here we report the evidence of negative capacitance in 80 nm thick ZnO thin films sputtered on Au interdigital electrodes (IDEs). Highly (002)-oriented ZnO thin films, with a fine-grained surface nanostructure and the desired chemical composition, are deposited at room temperature on different IDEs structures. Direct-current electrical measurements highlighted the semiconducting nature of ZnO (current density in the order of 1 x 10(-3) A/cm(2)). When turned into the alternating current regime (from 20 Hz to 2 MHz) the presence of NC values is observed in the low-frequency range (20-120 Hz). The loss of metal/semiconductor interface charge states under forward bias conditions, together with the presence of oxygen vacancies and piezoelectric/electrostriction effects, is believed to be at the basis of the observed negative behavior, suggesting that ZnO thin-film-based field-effect transistors can be a powerful instrument to go beyond the Boltzmann limit and the downscaling of integrated circuit elements required for the fabrication of portable and miniaturized electronic devices, especially for electric household appliances working in the low 50 Hz utility frequency.\"],\n",
    "[452,0,0,\"Smart applications of the Internet of Things are improving the performance of buildings, reducing energy demand. Local and smart networks, soft computing methodologies, machine intelligence algorithms and pervasive sensors are some of the basics of energy optimization strategies developed for the benefit of environmental sustainability and user comfort. This work presents a distributed sensor-processor-communication decision-making architecture to improve the acquisition, storage and transfer of thermal energy in buildings. The developed system is implemented in a near Zero-Energy Building (nZEB) prototype equipped with a built-in thermal solar collector, where optical properties are analysed; a low enthalpy geothermal accumulation system, segmented in different temperature zones; and an envelope that includes a dynamic thermal barrier. An intelligent control of this dynamic thermal barrier is applied to reduce the thermal energy demand (heating and cooling) caused by daily and seasonal weather variations. Simulations and experimental results are presented to highlight the nZEB thermal energy reduction.\"],\n",
    "[453,0,0,\"There has been extensive research in recent years on the multi-scale nature of hippocampal place cells and entorhinal grid cells encoding which led to many speculations on their role in spatial cognition. In this paper we focus on the multi-scale nature of place cells and how they contribute to faster learning during goal-oriented navigation when compared to a spatial cognition system composed of single scale place cells. The task consists of a circular arena with a fixed goal location, in which a robot is trained to find the shortest path to the goal after a number of learning trials. Synaptic connections are modified using a reinforcement learning paradigm adapted to the place cells multi-scale architecture. The model is evaluated in both simulation and physical robots. We find that larger scale and combined multi-scale representations favor goal-oriented navigation task learning.\"],\n",
    "[454,0,0,\"The objective of a socially assistive robot is to create a close and effective interaction with a human user for the purpose of giving assistance. In particular, the social interaction, guidance, and support that a socially assistive robot can provide a person can be very beneficial to patient-centered care. However, there are a number of research issues that need to be addressed in order to design such robots. This paper focuses on developing effective emotion-based assistive behavior for a socially assistive robot intended for natural human-robot interaction (HRI) scenarios with explicit social and assistive task functionalities. In particular, in this paper, a unique emotional behavior module is presented and implemented in a learning-based control architecture for assistive HRI. The module is utilized to determine the appropriate emotions of the robot to display, as motivated by the well-being of the person, during assistive task-driven interactions in order to elicit suitable actions from users to accomplish a given person-centered assistive task. A novel online updating technique is used in order to allow the emotional model to adapt to new people and scenarios. Experiments presented show the effectiveness of utilizing robotic emotional assistive behavior during HRI scenarios.\"],\n",
    "[455,0,0,\"Communicative interactions involve a kind of procedural knowledge that is used by the human brain for processing verbal and nonverbal inputs and for language production. Although considerable work has been done on modeling human language abilities, it has been difficult to bring them together to a comprehensive tabula rasa system compatible with current knowledge of how verbal information is processed in the brain. This work presents a cognitive system, entirely based on a large-scale neural architecture, which was developed to shed light on the procedural knowledge involved in language elaboration. The main component of this system is the central executive, which is a supervising system that coordinates the other components of the working memory. In our model, the central executive is a neural network that takes as input the neural activation states of the short-term memory and yields as output mental actions, which control the flow of information among the working memory components through neural gating mechanisms. The proposed system is capable of learning to communicate through natural language starting from tabula rasa, without any a priori knowledge of the structure of phrases, meaning of words, role of the different classes of words, only by interacting with a human through a text-based interface, using an open-ended incremental learning process. It is able to learn nouns, verbs, adjectives, pronouns and other word classes, and to use them in expressive language. The model was validated on a corpus of 1587 input sentences, based on literature on early language assessment, at the level of about 4-years old child, and produced 521 output sentences, expressing a broad range of language processing functionalities.\"],\n",
    "[456,0,0,\"Mental rotation, a classic experimental paradigm of cognitive psychology, tests the capacity of humans to mentally rotate a seen object to decide if it matches a target object. In recent years, mental rotation has been investigated with brain imaging techniques to identify the brain areas involved. Mental rotation has also been investigated through the development of neural-network models, used to identify the specific mechanisms that underlie its process, and with neurorobotics models to investigate its embodied nature. Current models, however, have limited capacities to relate to neuro-scientific evidence, to generalise mental rotation to new objects, to suitably represent decision making mechanisms, and to allow the study of the effects of overt gestures on mental rotation. The work presented in this study overcomes these limitations by proposing a novel neurorobotic model that has a macro-architecture constrained by knowledge held on brain, encompasses a rather general mental rotation mechanism, and incorporates a biologically plausible decision making mechanism. The model was tested using the humanoid robot iCub in tasks requiring the robot to mentally rotate 2D geometrical images appearing on a computer screen. The results show that the robot gained an enhanced capacity to generalise mental rotation to new objects and to express the possible effects of overt movements of the wrist on mental rotation. The model also represents a further step in the identification of the embodied neural mechanisms that may underlie mental rotation in humans and might also give hints to enhance robots' planning capabilities.\"],\n",
    "[457,0,0,\"The Virtual Brain (TVB; thevirtualbrain.org) is a neuroinformatics platform for full brain network simulation based on individual anatomical connectivity data. The framework addresses clinical and neuroscientific questions by simulating multi-scale neural dynamics that range from local population activity to large-scale brain function and related macroscopic signals like electroencephalography and functional magnetic resonance imaging. TVB is equipped with a graphical and a command-line interface to create models that capture the characteristic biological variability to predict the brain activity of individual subjects. To enable researchers from various backgrounds a quick start into TVB and brain network modeling in general, we developed an educational module: TVB-EduPack. EduPack offers two educational functionalities that seamlessly integrate into TVB's graphical user interface (GUI): (i) interactive tutorials introduce GUI elements, guide through the basic mechanics of software usage and develop complex use-case scenarios; animations, videos and textual descriptions transport essential principles of computational neuroscience and brain modeling; (ii) an automatic script generator records model parameters and produces input files for TVB's Python programming interface; thereby, simulation configurations can be exported as scripts that allow flexible customization of the modeling process and self-defined batch- and post-processing applications while benefitting from the full power of the Python language and its toolboxes. This article covers the implementation of TVB-EduPack and its integration into TVB architecture. Like TVB, EduPack is an open source community project that lives from the participation and contribution of its users. TVB-EduPack can be obtained as part of TVB from thevirtualbrain.org.\"],\n",
    "[458,0,0,\"Current neurobiological accounts of language and cognition offer diverging views on the questions of 'where' and 'how' semantic information is stored and processed in the human brain. Neuroimaging data showing consistent activation of different multi-modal areas during word and sentence comprehension suggest that all meanings are processed indistinctively, by a set of general semantic centres or 'hubs'. However, words belonging to specific semantic categories selectively activate modality-preferential areas; for example, action-related words spark activity in dorsal motor cortex, whereas object-related ones activate ventral visual areas. The evidence for category-specific and category-general semantic areas begs for a unifying explanation, able to integrate the emergence of both. Here, a neurobiological model offering such an explanation is described. Using a neural architecture replicating anatomical and neurophysiological features of frontal, occipital and temporal cortices, basic aspects of word learning and semantic grounding in action and perception were simulated. As the network underwent training, distributed lexico-semantic circuits spontaneously emerged. These circuits exhibited different cortical distributions that reached into dorsal-motor or ventral-visual areas, reflecting the correlated category-specific sensorimotor patterns that co-occurred during action- or object-related semantic grounding, respectively. Crucially, substantial numbers of neurons of both types of distributed circuits emerged in areas interfacing between modality-preferential regions, i.e. in multimodal connection hubs, which therefore became loci of general semantic binding. By relating neuroanatomical structure and cellular-level learning mechanisms with system-level cognitive function, this model offers a neurobiological account of category-general and category-specific semantic areas based on the different cortical distributions of the underlying semantic circuits.\"],\n",
    "[459,0,0,\"OBJECTIVE: The objective of this study was to design effectively integrated information architecture for a mobile teleoperated robot in remote assistance to the delivery of home health care. METHODS: Three role classes were identified related to the deployment of a telerobot, namely, engineer, technology integrator, and health professional. Patients and natural caregivers were indirectly considered, this being a component of future field studies. Interviewing representatives of each class provided the functions, and information content and flows for each function. Interview transcripts enabled the formulation of UML (Universal Modeling Language) diagrams for feedback from participants. The proposed information architecture was validated with a use-case scenario. RESULTS: The integrated information architecture incorporates progressive design, ergonomic integration, and the home care needs from medical specialist, nursing, physiotherapy, occupational therapy, and social worker care perspectives. The integrated architecture iterative process promoted insight among participants. The use-case scenario evaluation showed the design's robustness. CONCLUSIONS: Complex innovation such as a telerobot must coherently mesh with health-care service delivery needs. The deployment of integrated information architecture bridging development, with specialist and home care applications, is necessary for home care technology innovation. It enables continuing evolution of robot and novel health information design in the same integrated architecture, while accounting for patient ecological need.\"],\n",
    "[460,0,0,\"BACKGROUND AND OBJECTIVE: Hypoxic exercise exacerbates periodic breathing in otherwise healthy, awake humans. Interactions between sleep, exercise and hypoxic exposure have not been fully elucidated. METHODS: Fourteen men were confined 10 days to a simulated altitude of 4175 m (FIO2 = 0.139; PIO2 = 88 mm Hg). They were randomly assigned to an exercise intervention of 2 x 60-min cycle exercise/day at 50% of their hypoxia-specific peak power output (exercise, n = 8), or they completed no exercise (control, n = 6, random order). Sleep and breathing were objectively assessed via full polysomnography on night 1, after 14-h acute exposure (N1), and again on night 10 (N10). RESULTS: The exercise group spent more time in light sleep than control on N10 (95% confidence interval (CI): 8.5-15.0%; P = 0.013) and experienced more stage shifts (CI: 13-44; P = 0.023) on both nights compared with control. The exercise group experienced more apnoea-hypopnoea (AH) events per hour compared with control (CI: 1-110; P = 0.046); AH events that were associated with night desaturations were also higher on N1 (exercise: 397 +/- 320, control: 124 +/- 205, P = 0.047) and N10 (exercise: 375 +/- 229, control: 110 +/- 138, P = 0.028, CI: 49-489 total events; P = 0.020). The length of hyperpnoea was increased from 12.8 +/- 2.2 s on N1 to 14.6 +/- 2.7 s on N10 (P = 0.008), and thus, total cycle length also increased (P = 0.002) in both cohorts. Mean pooled duty ratios were 0.68 +/- 0.02 on N1 and 0.69 +/- 0.02 on N10 (group effect P = 0.617). CONCLUSION: Daily, moderate-intensity exercise in normobaric hypoxia equivalent to 4175 m exacerbated AH events, and negatively affected sleep architecture in exercisers compared with matched controls.\"],\n",
    "[461,0,0,\"Energy resource limitation is a severe problem in traditional wireless sensor networks (WSNs) because it restricts the lifetime of network. Recently, the emergence of energy harvesting techniques has brought with them the expectation to overcome this problem. In particular, it is possible for a sensor node with energy harvesting abilities to work perpetually in an Energy Neutral state. In this paper, a Multi-hop Energy Neutral Clustering (MENC) algorithm is proposed to construct the optimal multi-hop clustering architecture in energy harvesting WSNs, with the goal of achieving perpetual network operation. All cluster heads (CHs) in the network act as routers to transmit data to base station (BS) cooperatively by a multi-hop communication method. In addition, by analyzing the energy consumption of intra- and inter-cluster data transmission, we give the energy neutrality constraints. Under these constraints, every sensor node can work in an energy neutral state, which in turn provides perpetual network operation. Furthermore, the minimum network data transmission cycle is mathematically derived using convex optimization techniques while the network information gathering is maximal. Simulation results show that our protocol can achieve perpetual network operation, so that the consistent data delivery is guaranteed. In addition, substantial improvements on the performance of network throughput are also achieved as compared to the famous traditional clustering protocol LEACH and recent energy harvesting aware clustering protocols.\"],\n",
    "[462,0,0,\"Hand coordination can allow humans to have dexterous control with many degrees of freedom to perform various tasks in daily living. An important contributing factor to this important ability is the complex biomechanical architecture of the human hand. However, drawing a clear functional link between biomechanical architecture and hand coordination is challenging. It is not understood which biomechanical characteristics are responsible for hand coordination and what specific effect each biomechanical characteristic has. To explore this link, we first inspected the characteristics of hand coordination during daily tasks through a statistical analysis of the kinematic data, which were collected from thirty right-handed subjects during a multitude of grasping tasks. Then, the functional link between biomechanical architecture and hand coordination was drawn by establishing the clear corresponding causality between the tendinous connective characteristics of the human hand and the coordinated characteristics during daily grasping activities. The explicit functional link indicates that the biomechanical characteristic of tendinous connective architecture between muscles and articulations is the proper design by the Creator to perform a multitude of daily tasks in a comfortable way. The clear link between the structure and the function of the human hand also suggests that the design of a multifunctional robotic hand should be able to better imitate such basic architecture.\"],\n",
    "[463,0,0,\"This paper introduces a dual-user teleoperation system for hands-on medical training. A shared control based architecture is presented for authority management. In this structure, the combination of control signals is obtained using a dominance factor. Its main improvement is Online Authority Adjustment (OAA): the authority can be adjusted manually/automatically during the training progress. Experimental results are provided to validate the performances of the system.\"],\n",
    "[464,0,0,\"The human hand is considered as the highest example of dexterous system capable of interacting with different objects and adapting its manipulation abilities to them. The control of poliarticulated prosthetic hands represents one important research challenge, typically aiming at replicating the manipulation capabilities of the natural hand. For this reason, this paper wants to propose a bio-inspired learning architecture based on parallel force/position control for prosthetic hands, capable of learning cyclic manipulation capabilities. To this purpose, it is focused on the control of a commercial biomechatronic hand (the IH2 hand) including the main features of recent poliarticulated prosthetic hands. The training phase of the hand was carried out in simulation, the parallel force/position control was tested in simulation whereas preliminary tests were performed on the real IH2 hand. The results obtained in simulation and on the real hand provide an important evidence of the applicability of the bio-inspired neural control to real biomechatronic hand with the typical features of a hand prosthesis.\"],\n",
    "[465,0,0,\"This paper presents the design, development and control of a new robotic system for fracture manipulation. The objective is to improve the precision, ergonomics and safety of the traditional surgical procedure to treat joint fractures. The achievements toward this direction are here reported and include the design, the real-time control architecture and the evaluation of a new robotic manipulator system. The robotic manipulator is a 6-DOF parallel robot with the struts developed as linear actuators. The control architecture is also described here. The high-level controller implements a host-target structure composed by a host computer (PC), a real-time controller, and an FPGA. A graphical user interface was designed allowing the surgeon to comfortably automate and monitor the robotic system. The real-time controller guarantees the determinism of the control algorithms adding an extra level of safety for the robotic automation. The system's positioning accuracy and repeatability have been demonstrated showing a maximum positioning RMSE of 1.18 +/- 1.14mm (translations) and 1.85 +/- 1.54 degrees (rotations).\"],\n",
    "[466,0,0,\"Multilateral teleoperated robots can be used to train humans to perform complex tasks that require collaborative interaction and expert supervision, such as laparoscopic surgical procedures. In this paper, we explain the design and performance evaluation of a shared-control architecture that can be used in trilateral teleoperated training robots. The architecture includes dominance and observation factors inspired by the determinants of motor learning in humans, including observational practice, focus of attention, feedback and augmented feedback, and self-controlled practice. Toward the validation of such an architecture, we (1) verify the stability of a trilateral system by applying Llewellyn's criterion on a two-port equivalent architecture, and (2) demonstrate that system transparency remains generally invariant across relevant observation factors and movement frequencies. In a preliminary experimental study, a dyad of two human users (one novice, one expert) collaborated on the control of a robot to follow a trajectory. The experiment showed that the framework can be used to modulate the efforts of the users and adjust the source and level of haptic feedback to the novice user.\"],\n",
    "[467,0,0,\"Prior to language, human infants are prolific imitators. Developmental science grounds infant imitation in the neural coding of actions, and highlights the use of imitation for learning from and about people. Here, we used computational modeling and a robot implementation to explore the functional value of action imitation. We report 3 experiments using a mutual imitation task between robots, adults, typically developing children, and children with Autism Spectrum Disorder. We show that a particular learning architecture--specifically one combining artificial neural nets for (i) extraction of visual features, (ii) the robot's motor internal state, (iii) posture recognition, and (iv) novelty detection--is able to learn from an interactive experience involving mutual imitation. This mutual imitation experience allowed the robot to recognize the interactive agent in a subsequent encounter. These experiments using robots as tools for modeling human cognitive development, based on developmental theory, confirm the promise of developmental robotics. Additionally, findings illustrate how person recognition may emerge through imitative experience, intercorporeal mapping, and statistical learning.\"],\n",
    "[468,0,0,\"Oncologists all over the globe, relentlessly research on methodologies for detection of cancer and precise localization of cancer therapeutics with minimal adverse effects on healthy tissues. Since the previous decade, the fast growing research in nanotechnology has shown promising possibilities for achieving this dream of every oncologist.Nanorobots (or nanobots) are typical devices ranging in size from 0.1 to 10 mum and constructed of nanoscale or molecular components. Robots will augment the surgeon's motor performance, diagnostic capability and sensations with haptics and augmented reality. The article here aims in briefly describing the architecture of the nanorobots and their role in oncotherapy. Although, research into nanorobots is still in its preliminary stages, the promise of such technology is endless.\"],\n",
    "[469,9,1,\"Currently, there is a plethora of solutions regarding interconnectivity and interoperability for networked robots so that they will fulfill their purposes in a coordinated manner. In addition to that, middleware architectures are becoming increasingly popular due to the advantages that they are capable of guaranteeing (hardware abstraction, information homogenization, easy access for the applications above, etc.). However, there are still scarce contributions regarding the global state of the art in intermediation architectures for underwater robotics. As far as the area of robotics is concerned, this is a major issue that must be tackled in order to get a holistic view of the existing proposals. This challenge is addressed in this paper by studying the most compelling pieces of work for this kind of software development in the current literature. The studied works have been assessed according to their most prominent features and capabilities. Furthermore, by studying the individual pieces of work and classifying them several common weaknesses have been revealed and are highlighted. This provides a starting ground for the development of a middleware architecture for underwater robotics capable of dealing with these issues.\"],\n",
    "[470,0,0,\"Atypical neural architecture causes impairment in communication capabilities and reduces the ability of representing the referential statements of other people in children with autism. During a scenery of 'speaker-listener' communication, we have analyzed verbal and emotional expressions in neurotypical children (n = 20) and in children with autism (n = 20). The speaker was always a child, and the listener was a human or a minimalistic robot which reacts to speech expression by nodding only. Although both groups performed the task, everything happens as if the robot could allow children with autism to elaborate a multivariate equation encoding and conceptualizing within his/her brain, and externalizing into unconscious emotion (heart rate) and conscious verbal speech (words). Such a behavior would indicate that minimalistic artificial environments such as toy robots could be considered as the root of neuronal organization and reorganization with the potential to improve brain activity.\"],\n",
    "[471,9,1,\"In this perspective article, we propose a cognitive architecture model of human action that stresses the importance of cognitive representations stored in long-term memory as reference structures underlying and guiding voluntary motor performance. We introduce an experimental approach to ascertain cognitive representation structures and provide evidence from a variety of different studies, ranging from basic research in manual action to application-oriented research, such as athlete performance and rehabilitation. As results from these studies strongly support the presence of functional links between cognitive and motor processes, we regard this approach as a suitable and valuable tool for a variety of different disciplines related to cognition and movement. We conclude this article by highlighting current advances in ongoing research projects aimed at improving interaction capabilities in technical systems, particularly for rehabilitation and everyday support of the elderly, and outline future research directions.\"],\n",
    "[472,0,0,\"Compressive sensing (CS) theory has opened up new paths for the development of signal processing applications. Based on this theory, a novel single pixel camera architecture has been introduced to overcome the current limitations and challenges of traditional focal plane arrays. However, video quality based on this method is limited by existing acquisition and recovery methods, and the method also suffers from being time-consuming. In this paper, a multi-frame motion estimation algorithm is proposed in CS video to enhance the video quality. The proposed algorithm uses multiple frames to implement motion estimation. Experimental results show that using multi-frame motion estimation can improve the quality of recovered videos. To further reduce the motion estimation time, a block match algorithm is used to process motion estimation. Experiments demonstrate that using the block match algorithm can reduce motion estimation time by 30%.\"],\n",
    "[473,0,0,\"Planar in vitro models have been invaluable tools to identify the mechanical basis of wound closure. Although these models may recapitulate closure dynamics of epithelial cell sheets, they fail to capture how a wounded fibrous tissue rebuilds its 3D architecture. Here we develop a 3D biomimetic model for soft tissue repair and demonstrate that fibroblasts ensconced in a collagen matrix rapidly close microsurgically induced defects within 24 h. Traction force microscopy and time-lapse imaging reveal that closure of gaps begins with contractility-mediated whole-tissue deformations. Subsequently, tangentially migrating fibroblasts along the wound edge tow and assemble a progressively thickening fibronectin template inside the gap that provide the substrate for cells to complete closure. Unlike previously reported mechanisms based on lamellipodial protrusions and purse-string contraction, our data reveal a mode of stromal closure in which coordination of tissue-scale deformations, matrix assembly and cell migration act together to restore 3D tissue architecture.\"],\n",
    "[474,0,0,\"Thin sheets can be assembled into origami tubes to create a variety of deployable, reconfigurable and mechanistically unique three-dimensional structures. We introduce and explore origami tubes with polygonal, translational symmetric cross-sections that can reconfigure into numerous geometries. The tubular structures satisfy the mathematical definitions for flat and rigid foldability, meaning that they can fully unfold from a flattened state with deformations occurring only at the fold lines. The tubes do not need to be straight and can be constructed to follow a non-linear curved line when deployed. The cross-section and kinematics of the tubular structures can be reprogrammed by changing the direction of folding at some folds. We discuss the variety of tubular structures that can be conceived and we show limitations that govern the geometric design. We quantify the global stiffness of the origami tubes through eigenvalue and structural analyses and highlight the mechanical characteristics of these systems. The two-scale nature of this work indicates that, from a local viewpoint, the cross-sections of the polygonal tubes are reconfigurable while, from a global viewpoint, deployable tubes of desired shapes are achieved. This class of tubes has potential applications ranging from pipes and micro-robotics to deployable architecture in buildings.\"],\n",
    "[475,5,0,\"In this paper, we present the experimental results of an embodied cognitive robotic approach for modelling the human cognitive deficit known as unilateral spatial neglect (USN). To this end, we introduce an artificial neural network architecture designed and trained to control the spatial attentional focus of the iCub robotic platform. Like the human brain, the architecture is divided into two hemispheres and it incorporates bio-inspired plasticity mechanisms, which allow the development of the phenomenon of the specialization of the right hemisphere for spatial attention. In this study, we validate the model by replicating a previous experiment with human patients affected by the USN and numerical results show that the robot mimics the behaviours previously exhibited by humans. We also simulated recovery after the damage to compare the performance of each of the two hemispheres as additional validation of the model. Finally, we highlight some possible advantages of modelling cognitive dysfunctions of the human brain by means of robotic platforms, which can supplement traditional approaches for studying spatial impairments in humans.\"],\n",
    "[476,0,0,\"BACKGROUND: A variety of group activities is promoted for nursing home (NH) residents with dementia with the aim to reduce apathy and to increase engagement and social interaction. Investigating behaviors related to these outcomes could produce insights into how the activities work. The aim of this study was to systematically investigate behaviors seen in people with dementia during group activity with the seal robot Paro, differences in behaviors related to severity of dementia, and to explore changes in behaviors. METHODS: Thirty participants from five NHs formed groups of five to six participants at each NH. Group sessions with Paro lasted for 30 minutes twice a week during 12 weeks of intervention. Video recordings were conducted in the second and tenth week. An ethogram, containing 18 accurately defined and described behaviors, mapped the participants' behaviors. Duration of behaviors, such as 'Observing Paro,' 'Conversation with Paro on the lap,' 'Smile/laughter toward other participants,' were converted to percentage of total session time and analyzed statistically. RESULTS: 'Observing Paro' was observed more often in participants with mild to moderate dementia (p = 0.019), while the variable 'Observing other things' occurred more in the group of severe dementia (p = 0.042). 'Smile/laughter toward other participants' showed an increase (p = 0.011), and 'Conversations with Paro on the lap' showed a decrease (p = 0.014) during the intervention period. CONCLUSIONS: Participants with severe dementia seemed to have difficulty in maintaining attention toward Paro during the group session. In the group as a whole, Paro seemed to be a mediator for increased social interactions and created engagement.\"],\n",
    "[477,0,0,\"In this paper we present a method for combining realtime and non-realtime (photorealistic) rendering with open source software. Realtime rendering provides sufficient realism and is a good choice for most simulation and regression testing purposes in robot-assisted surgery. However, for proper end-to-end testing of the system, some computer vision algorithms require high fidelity images that capture more minute details of the real scene. One of the central practical obstacles to combining both worlds in a uniform way is creating models that are suitable for both kinds of rendering paradigms. We build a modeling pipeline using open source tools that builds on established, open standards for data exchange. The result is demonstrated through a unified model of the medical OpenHELP phantom used in the Gazebo robotics simulator, which can at the same time be rendered with more visual fidelity in the Cycles raytracer.\"],\n",
    "[478,0,0,\"Human behaviour is context-dependent-based on predictions and influenced by the environment and other people. We live in a dynamic world where both the social stimuli and their context are constantly changing. Similar dynamic, natural stimuli should, in the future, be increasingly used to study social brain functions, with parallel development of appropriate signal-analysis methods. Understanding dynamic neural processes also requires accurate time-sensitive characterization of the behaviour. To go beyond the traditional stimulus-response approaches, brain activity should be recorded simultaneously from two interacting subjects to reveal why human social interaction is critically different from just reacting to each other. This theme issue on Attending to and neglecting people contains original work and review papers on person perception and social interaction. The articles cover research from neuroscience, psychology, robotics, animal interaction research and microsociology. Some of the papers are co-authored by scientists who presented their own, independent views in the recent Attention and Performance XXVI conference but were brave enough to join forces with a colleague having a different background and views. In the future, information needs to converge across disciplines to provide us a more holistic view of human behaviour, its interactive nature, as well as the temporal dynamics of our social world.\"],\n",
    "[479,0,0,\"PURPOSE: Precise needle placement is an important task during several medical procedures. Ultrasound imaging is often used to guide the needle toward the target region in soft tissue. This task remains challenging due to the user's dependence on image quality, limited field of view, moving target, and moving needle. In this paper, we present a novel dual-robot framework for robotic needle insertions under robotic ultrasound guidance. METHOD: We integrated force-controlled ultrasound image acquisition, registration of preoperative and intraoperative images, vision-based robot control, and target localization, in combination with a novel needle tracking algorithm. The framework allows robotic needle insertion to target a preoperatively defined region of interest while enabling real-time visualization and adaptive trajectory planning to provide safe and quick interactions. We assessed the framework by considering both static and moving targets embedded in water and tissue-mimicking gelatin. RESULTS: The presented dual-robot tracking algorithms allow for accurate needle placement, namely to target the region of interest with an error around 1 mm. CONCLUSION: To the best of our knowledge, we show the first use of two independent robots, one for imaging, the other for needle insertion, that are simultaneously controlled using image processing algorithms. Experimental results show the feasibility and demonstrate the accuracy and robustness of the process.\"],\n",
    "[480,0,0,\"This paper presents the technical description, mechanical design, electronic components, software implementation and possible applications of a tele-operated mobile robot designed as an assisted living tool. This robotic concept has been named Assistant Personal Robot (or APR for short) and has been designed as a remotely telecontrolled robotic platform built to provide social and assistive services to elderly people and those with impaired mobility. The APR features a fast high-mobility motion system adapted for tele-operation in plain indoor areas, which incorporates a high-priority collision avoidance procedure. This paper presents the mechanical architecture, electrical fundaments and software implementation required in order to develop the main functionalities of an assistive robot. The APR uses a tablet in order to implement the basic peer-to-peer videoconference and tele-operation control combined with a tactile graphic user interface. The paper also presents the development of some applications proposed in the framework of an assisted living robot.\"],\n",
    "[481,0,0,\"OBJECTIVE: The aim of this study was to design and validate a functional assessment scale for assisted gait with forearm crutches (Chamorro Assisted Gait Scale-CHAGS) and to assess its reliability in people with sprained ankles. DESIGN: Thirty subjects who suffered from sprained ankle (anterior talofibular ligament first and second degree) were included in the study. A modified Delphi technique was used to obtain the content validity. The selected items were: pelvic and scapular girdle dissociation(1), deviation of Center of Gravity(2), crutch inclination(3), steps rhythm(4), symmetry of step length(5), cross support(6), simultaneous support of foot and crutch(7), forearm off(8), facing forward(9) and fluency(10). Two raters twice visualized the gait of the sample subjects which were recorded. The criterion-related validity was determined by correlation between CHAGS and Coding of eight criteria of qualitative gait analysis (Viel Coding). Internal consistency and inter and intra-rater reliability were also tested. RESULTS: CHAGS obtained a high and negative correlation with Viel Coding. We obtained a good internal consistency and the intra-class correlation coefficients oscillated between 0.97 and 0.99, while the minimal detectable changes were acceptable. CONCLUSION: CHAGS scale is a valid and reliable tool for assessing assisted gait with crutches in people with sprained ankles to perform partial relief of lower limbs.\"],\n",
    "[482,0,0,\"Accurate characterization of particulate matter (PM) exposure in young children is difficult, because personal samplers are often too heavy, bulky or impractical to be used. The Pretoddler Inhalable Particulate Environmental Robotic (PIPER) sampler was developed to help address this problem. In this study, we measured inhalable PM exposures in 2-year-olds via a lightweight personal sampler worn in a small backpack and evaluated the use of a robotic sampler with an identical sampling train for estimating PM exposure in this age group. PM mass concentrations measured by the personal sampler ranged from 100 to almost 1,200 mug/m(3), with a median value of 331 mug/m(3). PM concentrations measured by PIPER were considerably lower, ranging from 14 to 513 mug/m(3) with a median value of 56 mug/m(3). Floor cleaning habits and activity patterns of the 2-year-olds varied widely by home; vigorous play and recent floor cleaning were most associated with higher personal exposure. Our findings highlight the need for additional characterization of children's activity patterns and their effect on personal exposures.\"],\n",
    "[483,5,0,\"The human hand's versatility allows for robust and flexible grasping. To obtain such efficiency, many robotic hands include human biomechanical features such as fingers having their two last joints mechanically coupled. Although such coupling enables human-like grasping, controlling the inverse kinematics of such mechanical systems is challenging. Here we propose a cortical model for fine motor control of a humanoid finger, having its two last joints coupled, that learns the inverse kinematics of the effector. This neural model functionally mimics the population vector coding as well as sensorimotor prediction processes of the brain's motor/premotor and parietal regions, respectively. After learning, this neural architecture could both overtly (actual execution) and covertly (mental execution or motor imagery) perform accurate, robust and flexible finger movements while reproducing the main human finger kinematic states. This work contributes to developing neuro-mimetic controllers for dexterous humanoid robotic/prosthetic upper-extremities, and has the potential to promote human-robot interactions.\"],\n",
    "[484,5,0,\"Some of the authors have previously proposed a cognitively inspired reinforcement learning architecture (LS-Q) that mimics cognitive biases in humans. LS-Q adaptively learns under uniform, coarse-grained state division and performs well without parameter tuning in a giant-swing robot task. However, these results were shown only in simulations. In this study, we test the validity of the LS-Q implemented in a robot in a real environment. In addition, we analyze the learning process to elucidate the mechanism by which the LS-Q adaptively learns under the partially observable environment. We argue that the LS-Q may be a versatile reinforcement learning architecture, which is, despite its simplicity, easily applicable and does not require well-prepared settings.\"],\n",
    "[485,0,0,\"Membrane peeling is a challenging procedure in retinal microsurgery, requiring careful manipulation of delicate tissues by using a micro-forceps and exerting very fine forces that are mostly imperceptible to the surgeon. Previously, we developed a micro-forceps with three integrated fiber Bragg grating (FBG) sensors to sense the lateral forces at the instrument's tip. However, importantly this architecture was insufficient to sense the tissue pulling forces along the forceps axis, which may be significant during membrane peeling. Our previous 3-DOF force sensing solutions developed for pick tools are not appropriate for forceps tools due to the motion and intrinsic forces that develop while opening/closing the forceps jaws. This paper presents a new design that adds another FBG attached to the forceps jaws to measure the axial loads. This involves not only the external tool-to-tissue interactions that we need to measure, but also the adverse effect of intrinsic actuation forces that arise due to the elastic deformation of jaws and friction. In this study, through experiments and finite element analyses, we model the intrinsic actuation force. We investigate the effect of the coefficient of friction and material type (stainless steel, titanium, nitinol) on this model. Then, the obtained model is used to separate the axial tool-to-tissue forces from the raw sensor measurements. Preliminary experiments and simulation results indicate that the developed linear model based on the actuation displacement is feasible to accurately predict the axial forces at the tool tip.\"],\n",
    "[486,0,0,\"The loss of one hand can significantly affect the level of autonomy and the capability of performing daily living, working and social activities. The current prosthetic solutions contribute in a poor way to overcome these problems due to limitations in the interfaces adopted for controlling the prosthesis and to the lack of force or tactile feedback, thus limiting hand grasp capabilities. This paper presents a literature review on needs analysis of upper limb prosthesis users, and points out the main critical aspects of the current prosthetic solutions, in terms of users satisfaction and activities of daily living they would like to perform with the prosthetic device. The ultimate goal is to provide design inputs in the prosthetic field and, contemporary, increase user satisfaction rates and reduce device abandonment. A list of requirements for upper limb prostheses is proposed, grounded on the performed analysis on user needs. It wants to (i) provide guidelines for improving the level of acceptability and usefulness of the prosthesis, by accounting for hand functional and technical aspects; (ii) propose a control architecture of PNS-based prosthetic systems able to satisfy the analyzed user wishes; (iii) provide hints for improving the quality of the methods (e.g., questionnaires) adopted for understanding the user satisfaction with their prostheses.\"],\n",
    "[487,5,0,\"Classification and sequence learning are relevant capabilities used by living beings to extract complex information from the environment for behavioral control. The insect world is full of examples where the presentation time of specific stimuli shapes the behavioral response. On the basis of previously developed neural models, inspired by Drosophila melanogaster, a new architecture for classification and sequence learning is here presented under the perspective of the Neural Reuse theory. Classification of relevant input stimuli is performed through resonant neurons, activated by the complex dynamics generated in a lattice of recurrent spiking neurons modeling the insect Mushroom Bodies neuropile. The network devoted to context formation is able to reconstruct the learned sequence and also to trace the subsequences present in the provided input. A sensitivity analysis to parameter variation and noise is reported. Experiments on a roving robot are reported to show the capabilities of the architecture used as a neural controller.\"],\n",
    "[488,0,0,\"Occupational Health and Safety (OHS) is associated with crucial social, economic, cultural and technical issues. A highly specialized OHS sector deals with the photobiological hazards from artificial optical radiation (AOR), which is divided into visible light, UV and IR emitted during various activities and which is legally covered by European Directive 2006/25/EC. Among the enormous amount of sources emitting AOR, the most important non-coherent ones to consider for health effects to the whole optical range, are arcs created during metal welding. This survey presents the effort to assess the complicated exposure limits of the Directive in the controlled environment of a welding laboratory. Sensors covering the UV and blue light range were set to measure typical welding procedures reproduced in the laboratory. Initial results, apart from apparently justifying the use of Personal Protective Equipment (PPE) due to even subsecond overexposures measured, also set the basis to evaluate PPE's properties and support an integrated risk assessment of the complex welding environment. These results can also improve workers' and employer's information and training about radiation hazards, which is a crucial OHS demand.\"],\n",
    "[489,0,0,\"AIM: The aim of this study was to investigate effects of robot-assisted group activity with Paro on quality of life in older people with dementia. BACKGROUND: Nursing home residents with severe dementia often experience social withdrawal and lower quality of life, which are suggested to be enhanced by non-pharmacological interventions. DESIGN: A cluster-randomized controlled trial. Ten nursing home units were randomized to robot-assisted intervention or control group (treatment as usual). METHODS: Data were collected between March 2013-September 2014. 27 participants participated in group activity for 30 minutes twice a week over 12 weeks, 26 participated in the control group. Change in quality of life was assessed by local nurses through the Quality of Life in Late-Stage Dementia scale at baseline, after end of intervention and at 3 months follow-up. The scale and regular psychotropic medication were analysed stratified by dementia severity. Analysis using mixed model, one-way anova and linear regression were performed. RESULTS: An effect was found among participants with severe dementia from baseline to follow-up showing stable quality of life in the intervention group compared with a decrease in the control group. The intervention explained most of the variance in change in the total scale and in the subscales describing Tension and Well-being for the group with severe dementia. The intervention group used significantly less psychotropic medication compared with the control group after end of intervention. CONCLUSION: Pleasant and engaging activities facilitated by nursing staff, such as group activity with Paro, could improve quality of life in people with severe dementia. The trial is in adherence with the CONSORT statement and is registered at www.clinicaltrials.gov (study ID number: NCT01998490) [corrected].\"],\n",
    "[490,5,0,\"The cerebellar microcircuit has been the work bench for theoretical and computational modeling since the beginning of neuroscientific research. The regular neural architecture of the cerebellum inspired different solutions to the long-standing issue of how its circuitry could control motor learning and coordination. Originally, the cerebellar network was modeled using a statistical-topological approach that was later extended by considering the geometrical organization of local microcircuits. However, with the advancement in anatomical and physiological investigations, new discoveries have revealed an unexpected richness of connections, neuronal dynamics and plasticity, calling for a change in modeling strategies, so as to include the multitude of elementary aspects of the network into an integrated and easily updatable computational framework. Recently, biophysically accurate 'realistic' models using a bottom-up strategy accounted for both detailed connectivity and neuronal non-linear membrane dynamics. In this perspective review, we will consider the state of the art and discuss how these initial efforts could be further improved. Moreover, we will consider how embodied neurorobotic models including spiking cerebellar networks could help explaining the role and interplay of distributed forms of plasticity. We envisage that realistic modeling, combined with closed-loop simulations, will help to capture the essence of cerebellar computations and could eventually be applied to neurological diseases and neurorobotic control systems.\"],\n",
    "[491,9,1,\"Emerging studies indicate that several species such as corvids, apes and children solve 'The Crow and the Pitcher' task (from Aesop's Fables) in diverse conditions. Hidden beneath this fascinating paradigm is a fundamental question: by cumulatively interacting with different objects, how can an agent abstract the underlying cause-effect relations to predict and creatively exploit potential affordances of novel objects in the context of sought goals? Re-enacting this Aesop's Fable task on a humanoid within an open-ended 'learning-prediction-abstraction' loop, we address this problem and (i) present a brain-guided neural framework that emulates rapid one-shot encoding of ongoing experiences into a long-term memory and (ii) propose four task-agnostic learning rules (elimination, growth, uncertainty and status quo) that correlate predictions from remembered past experiences with the unfolding present situation to gradually abstract the underlying causal relations. Driven by the proposed architecture, the ensuing robot behaviours illustrated causal learning and anticipation similar to natural agents. Results further demonstrate that by cumulatively interacting with few objects, the predictions of the robot in case of novel objects converge close to the physical law, i.e. the Archimedes principle: this being independent of both the objects explored during learning and the order of their cumulative exploration.\"],\n",
    "[492,0,0,\"Cellular structures are hydrodynamically interconnected, such that force generation in one location can move distal structures. One example of this phenomenon is cytoplasmic streaming, whereby active forces at the cell cortex induce streaming of the entire cytoplasm. However, it is not known how the spatial distribution and magnitude of these forces move distant objects within the cell. To address this issue, we developed a computational method that used cytoplasm hydrodynamics to infer the spatial distribution of shear stress at the cell cortex induced by active force generators from experimentally obtained flow field of cytoplasmic streaming. By applying this method, we determined the shear-stress distribution that quantitatively reproduces in vivo flow fields in Caenorhabditis elegans embryos and mouse oocytes during meiosis II. Shear stress in mouse oocytes were predicted to localize to a narrower cortical region than that with a high cortical flow velocity and corresponded with the localization of the cortical actin cap. The predicted patterns of pressure gradient in both species were consistent with species-specific cytoplasmic streaming functions. The shear-stress distribution inferred by our method can contribute to the characterization of active force generation driving biological streaming.\"],\n",
    "[493,0,0,\"Crouch gait, a pathological pattern of walking characterized by excessive knee flexion, is one of the most common gait disorders observed in children with cerebral palsy (CP). Effective treatment of crouch during childhood is critical to maintain mobility into adulthood, yet current interventions do not adequately alleviate crouch in most individuals. Powered exoskeletons provide an untapped opportunity for intervention. The multiple contributors to crouch, including spasticity, contracture, muscle weakness, and poor motor control make design and control of such devices challenging in this population. To our knowledge, no evidence exists regarding the feasibility or efficacy of utilizing motorized assistance to alleviate knee flexion in crouch gait. Here, we present the design of and first results from a powered exoskeleton for extension assistance as a treatment for crouch gait in children with CP. Our exoskeleton, based on the architecture of a knee-ankle-foot orthosis, is lightweight (3.2 kg) and modular. On board sensors enable knee extension assistance to be provided during distinct phases of the gait cycle. We tested our device on one six-year-old male participant with spastic diplegia from CP. Our results show that the powered exoskeleton improved knee extension during stance by 18.1 degrees while total knee range of motion improved 21.0 degrees . Importantly, we observed no significant decrease in knee extensor muscle activity, indicating the user did not rely solely on the exoskeleton to extend the limb. These results establish the initial feasibility of robotic exoskeletons for treatment of crouch and provide impetus for continued investigation of these devices with the aim of deployment for long term gait training in this population.\"],\n",
    "[494,0,0,\"Over the last decade robotics has attracted a great deal of interest from teachers and researchers as a valuable educational tool from preschool to highschool levels. The implementation of social-support behaviors in robot tutors, in particular in the emotional dimension, can make a significant contribution to learning efficiency. With the aim of contributing to the rising field of affective robot tutors we have developed ARTIE (Affective Robot Tutor Integrated Environment). We offer an architectural pattern which integrates any given educational software for primary school children with a component whose function is to identify the emotional state of the students who are interacting with the software, and with the driver of a robot tutor which provides personalized emotional pedagogical support to the students. In order to support the development of affective robot tutors according to the proposed architecture, we also provide a methodology which incorporates a technique for eliciting pedagogical knowledge from teachers, and a generic development platform. This platform contains a component for identiying emotional states by analysing keyboard and mouse interaction data, and a generic affective pedagogical support component which specifies the affective educational interventions (including facial expressions, body language, tone of voice,...) in terms of BML (a Behavior Model Language for virtual agent specification) files which are translated into actions of a robot tutor. The platform and the methodology are both adapted to primary school students. Finally, we illustrate the use of this platform to build a prototype implementation of the architecture, in which the educational software is instantiated with Scratch and the robot tutor with NAO. We also report on a user experiment we carried out to orient the development of the platform and of the prototype. We conclude from our work that, in the case of primary school students, it is possible to identify, without using intrusive and expensive identification methods, the emotions which most affect the character of educational interventions. Our work also demonstrates the feasibility of a general-purpose architecture of decoupled components, in which a wide range of educational software and robot tutors can be integrated and then used according to different educational criteria.\"],\n",
    "[495,0,0,\"Soft robots possess many attributes that are difficult, if not impossible, to achieve with conventional robots composed of rigid materials. Yet, despite recent advances, soft robots must still be tethered to hard robotic control systems and power sources. New strategies for creating completely soft robots, including soft analogues of these crucial components, are needed to realize their full potential. Here we report the untethered operation of a robot composed solely of soft materials. The robot is controlled with microfluidic logic that autonomously regulates fluid flow and, hence, catalytic decomposition of an on-board monopropellant fuel supply. Gas generated from the fuel decomposition inflates fluidic networks downstream of the reaction sites, resulting in actuation. The body and microfluidic logic of the robot are fabricated using moulding and soft lithography, respectively, and the pneumatic actuator networks, on-board fuel reservoirs and catalytic reaction chambers needed for movement are patterned within the body via a multi-material, embedded 3D printing technique. The fluidic and elastomeric architectures required for function span several orders of magnitude from the microscale to the macroscale. Our integrated design and rapid fabrication approach enables the programmable assembly of multiple materials within this architecture, laying the foundation for completely soft, autonomous robots.\"],\n",
    "[496,1,0,\"Most current approaches to scene understanding lack the capability to adapt object and situation models to behavioral needs not anticipated by the human system designer. Here, we give a detailed description of a system architecture for self-referential autonomous learning which enables the refinement of object and situation models during operation in order to optimize behavior. This includes structural learning of hierarchical models for situations and behaviors that is triggered by a mismatch between expected and actual action outcome. Besides proposing architectural concepts, we also describe a first implementation of our system within a simulated traffic scenario to demonstrate the feasibility of our approach.\"],\n",
    "[497,0,0,\"Vaccination in HIV-infected patients constitutes an essential tool in the prevention of the most common infectious diseases. The Ligurian Vaccination in HIV Program is a proposed vaccination schedule specifically dedicated to this risk group. Selective strategies are proposed within this program, employing ICT (Information and Communication) tools to identify this susceptible target group, to monitor immunization coverage over time and to manage failures and defaulting. The proposal is to connect an immunization registry system to an existing regional platform that allows clinical data re-use among several medical structures, to completely manage the vaccination process. This architecture will adopt a Service Oriented Architecture (SOA) approach and standard HSSP (Health Services Specification Program) interfaces to support interoperability. According to the presented solution, vaccination administration information retrieved from the immunization registry will be structured according to the specifications within the immunization section of the HL7 (Health Level 7) CCD (Continuity of Care Document) document. Immunization coverage will be evaluated through the continuous monitoring of serology and antibody titers gathered from the hospital LIS (Laboratory Information System) structured into a HL7 Version 3 (v3) Clinical Document Architecture Release 2 (CDA R2).\"],\n",
    "[498,0,0,\"Despite considerable advances in tissue engineering over the past two decades, solutions to some crucial problems remain elusive. Vascularization is one of the most important factors that greatly influence the function of scaffolds. Many research studies have focused on the construction of a vascular-like network with prevascularization structure. Sacrificial materials are widely used to build perfusable vascular-like architectures, but most of these fabricated scaffolds only have a 2D plane-connected network. The fabrication of three-dimensional perfusable branched networks remains an urgent issue. In this work, we developed a novel sacrificial molding technique for fabricating biocompatible scaffolds with a three-dimensional perfusable branched network. Here, 3D-printed poly(vinyl alcohol) (PVA) filament was used as the sacrificial material. The fused PVA was deposited on the surface of a cylinder to create the 3D branched solid network. Gelatin was used to embed the solid network. Then, the PVA mold was dissolved after curing the hydrogel. The obtained architecture shows good perfusability. Cell experiment results indicated that human umbilical vein endothelial cells (HUVECs) successfully attached to the surface of the branched channel and maintained high viability after a few days in culture. In order to prevent deformation of the channel, paraffin was coated on the surface of the printed structure, and hydroxyapatite (HA) was added to gelatin. In conclusion, we demonstrate a novel strategy toward the engineering of prevasculature thick tissues through the integration of the fused PVA filament deposit. This approach has great potential in solving the issue of three-dimensional perfusable branched networks and opens the way to clinical applications.\"],\n",
    "[499,5,0,\"This paper presents a novel inverse kinematics solution for robotic arm based on artificial neural network (ANN) architecture. The motion of robotic arm is controlled by the kinematics of ANN. A new artificial neural network approach for inverse kinematics is proposed. The novelty of the proposed ANN is the inclusion of the feedback of current joint angles configuration of robotic arm as well as the desired position and orientation in the input pattern of neural network, while the traditional ANN has only the desired position and orientation of the end effector in the input pattern of neural network. In this paper, a six DOF Denso robotic arm with a gripper is controlled by ANN. The comprehensive experimental results proved the applicability and the efficiency of the proposed approach in robotic motion control. The inclusion of current configuration of joint angles in ANN significantly increased the accuracy of ANN estimation of the joint angles output. The new controller design has advantages over the existing techniques for minimizing the position error in unconventional tasks and increasing the accuracy of ANN in estimation of robot's joint angles.\"],\n",
    "[500,0,0,\"This article concentrates on open-source implementation on flying object detection in cluttered scenes. It is of significance for ground stereo-aided autonomous landing of unmanned aerial vehicles. The ground stereo vision guidance system is presented with details on system architecture and workflow. The Chan-Vese detection algorithm is further considered and implemented in the robot operating systems (ROS) environment. A data-driven interactive scheme is developed to collect datasets for parameter tuning and performance evaluating. The flying vehicle outdoor experiments capture the stereo sequential images dataset and record the simultaneous data from pan-and-tilt unit, onboard sensors and differential GPS. Experimental results by using the collected dataset validate the effectiveness of the published ROS-based detection algorithm.\"],\n",
    "[501,0,0,\"This paper presents the steps for developing a low-cost POrtableNavigation Tool for Underwater Scenarios (PONTUS) to be used as a localization device for subsea targets. PONTUS consists of an integrated ultra-short baseline acoustic positioning system aided by an inertial navigation system. Built on a practical design, it can be mounted on an underwater robotic vehicle or be operated by a scuba diver. It also features a graphical user interface that provides information on the tracking of the designated target, in addition to some details on the physical properties inside PONTUS. A full disclosure of the architecture of the tool is first presented, followed by thorough technical descriptions of the hardware components ensemble and the software development process. A series of experiments was carried out to validate the developed prototype, and the results are presented herein, which allow assessing its overall performance.\"],\n",
    "[502,0,0,\"Natural control methods based on surface electromyography (sEMG) and pattern recognition are promising for hand prosthetics. However, the control robustness offered by scientific research is still not sufficient for many real life applications, and commercial prostheses are capable of offering natural control for only a few movements. In recent years deep learning revolutionized several fields of machine learning, including computer vision and speech recognition. Our objective is to test its methods for natural control of robotic hands via sEMG using a large number of intact subjects and amputees. We tested convolutional networks for the classification of an average of 50 hand movements in 67 intact subjects and 11 transradial amputees. The simple architecture of the neural network allowed to make several tests in order to evaluate the effect of pre-processing, layer architecture, data augmentation and optimization. The classification results are compared with a set of classical classification methods applied on the same datasets. The classification accuracy obtained with convolutional neural networks using the proposed architecture is higher than the average results obtained with the classical classification methods, but lower than the results obtained with the best reference methods in our tests. The results show that convolutional neural networks with a very simple architecture can produce accurate results comparable to the average classical classification methods. They show that several factors (including pre-processing, the architecture of the net and the optimization parameters) can be fundamental for the analysis of sEMG data. Larger networks can achieve higher accuracy on computer vision and object recognition tasks. This fact suggests that it may be interesting to evaluate if larger networks can increase sEMG classification accuracy too.\"],\n",
    "[503,0,0,\"This paper introduces an architecture as a proof-of-concept for emotion detection and regulation in smart health environments. The aim of the proposal is to detect the patient's emotional state by analysing his/her physiological signals, facial expression and behaviour. Then, the system provides the best-tailored actions in the environment to regulate these emotions towards a positive mood when possible. The current state-of-the-art in emotion regulation through music and colour/light is implemented with the final goal of enhancing the quality of life and care of the subject. The paper describes the three main parts of the architecture, namely 'Emotion Detection', 'Emotion Regulation' and 'Emotion Feedback Control'. 'Emotion Detection' works with the data captured from the patient, whereas 'Emotion Regulation' offers him/her different musical pieces and colour/light settings. 'Emotion Feedback Control' performs as a feedback control loop to assess the effect of emotion regulation over emotion detection. We are currently testing the overall architecture and the intervention in real environments to achieve our final goal.\"],\n",
    "[504,5,0,\"Most theories of learning would predict a gradual acquisition and refinement of skills as learning progresses, and while some highlight exponential growth, this fails to explain why natural cognitive development typically progresses in stages. Models that do span multiple developmental stages typically have parameters to 'switch' between stages. We argue that by taking an embodied view, the interaction between learning mechanisms, the resulting behavior of the agent, and the opportunities for learning that the environment provides can account for the stage-wise development of cognitive abilities. We summarize work relevant to this hypothesis and suggest two simple mechanisms that account for some developmental transitions: neural readiness focuses on changes in the neural substrate resulting from ongoing learning, and perceptual readiness focuses on the perceptual requirements for learning new tasks. Previous work has demonstrated these mechanisms in replications of a wide variety of infant language experiments, spanning multiple developmental stages. Here we piece this work together as a single model of ongoing learning with no parameter changes at all. The model, an instance of the Epigenetic Robotics Architecture (Morse et al 2010) embodied on the iCub humanoid robot, exhibits ongoing multi-stage development while learning pre-linguistic and then basic language skills.\"],\n",
    "[505,0,0,\"The number of perception sensors on automated vehicles increases due to the increasing number of advanced driver assistance system functions and their increasing complexity. Furthermore, fail-safe systems require redundancy, thereby increasing the number of sensors even further. A one-size-fits-all multisensor data fusion architecture is not realistic due to the enormous diversity in vehicles, sensors and applications. As an alternative, this work presents a methodology that can be used to effectively come up with an implementation to build a consistent model of a vehicle's surroundings. The methodology is accompanied by a software architecture. This combination minimizes the effort required to update the multisensor data fusion system whenever sensors or applications are added or replaced. A series of real-world experiments involving different sensors and algorithms demonstrates the methodology and the software architecture.\"],\n",
    "[506,5,0,\"We propose a biologically plausible architecture for unsupervised ensemble learning in a population of spiking neural network classifiers. A mixture of experts type organisation is shown to be effective, with the individual classifier outputs combined via a gating network whose operation is driven by input timing dependent plasticity (ITDP). The ITDP gating mechanism is based on recent experimental findings. An abstract, analytically tractable model of the ITDP driven ensemble architecture is derived from a logical model based on the probabilities of neural firing events. A detailed analysis of this model provides insights that allow it to be extended into a full, biologically plausible, computational implementation of the architecture which is demonstrated on a visual classification task. The extended model makes use of a style of spiking network, first introduced as a model of cortical microcircuits, that is capable of Bayesian inference, effectively performing expectation maximization. The unsupervised ensemble learning mechanism, based around such spiking expectation maximization (SEM) networks whose combined outputs are mediated by ITDP, is shown to perform the visual classification task well and to generalize to unseen data. The combined ensemble performance is significantly better than that of the individual classifiers, validating the ensemble architecture and learning mechanisms. The properties of the full model are analysed in the light of extensive experiments with the classification task, including an investigation into the influence of different input feature selection schemes and a comparison with a hierarchical STDP based ensemble architecture.\"],\n",
    "[507,0,0,\"The Iterative Closest Point (ICP) algorithm is currently one of the most popular methods for rigid registration so that it has become the standard in the Robotics and Computer Vision communities. Many applications take advantage of it to align 2D/3D surfaces due to its popularity and simplicity. Nevertheless, some of its phases present a high computational cost thus rendering impossible some of its applications. In this work, it is proposed an efficient approach for the matching phase of the Iterative Closest Point algorithm. This stage is the main bottleneck of that method so that any efficiency improvement has a great positive impact on the performance of the algorithm. The proposal consists in using low computational cost point-to-point distance metrics instead of classic Euclidean one. The candidates analysed are the Chebyshev and Manhattan distance metrics due to their simpler formulation. The experiments carried out have validated the performance, robustness and quality of the proposal. Different experimental cases and configurations have been set up including a heterogeneous set of 3D figures, several scenarios with partial data and random noise. The results prove that an average speed up of 14% can be obtained while preserving the convergence properties of the algorithm and the quality of the final results.\"],\n",
    "[508,0,0,\"Biological and technical systems operate in a rich multimodal environment. Due to the diversity of incoming sensory streams a system perceives and the variety of motor capabilities a system exhibits there is no single representation and no singular unambiguous interpretation of such a complex scene. In this work we propose a novel sensory processing architecture, inspired by the distributed macro-architecture of the mammalian cortex. The underlying computation is performed by a network of computational maps, each representing a different sensory quantity. All the different sensory streams enter the system through multiple parallel channels. The system autonomously associates and combines them into a coherent representation, given incoming observations. These processes are adaptive and involve learning. The proposed framework introduces mechanisms for self-creation and learning of the functional relations between the computational maps, encoding sensorimotor streams, directly from the data. Its intrinsic scalability, parallelisation, and automatic adaptation to unforeseen sensory perturbations make our approach a promising candidate for robust multisensory fusion in robotic systems. We demonstrate this by applying our model to a 3D motion estimation on a quadrotor.\"],\n",
    "[509,5,0,\"We propose the architecture of a novel robot system merging biological and artificial intelligence based on a neural controller connected to an external agent. We initially built a framework that connected the dissociated neural network to a mobile robot system to implement a realistic vehicle. The mobile robot system characterized by a camera and two-wheeled robot was designed to execute the target-searching task. We modified a software architecture and developed a home-made stimulation generator to build a bi-directional connection between the biological and the artificial components via simple binomial coding/decoding schemes. In this paper, we utilized a specific hierarchical dissociated neural network for the first time as the neural controller. Based on our work, neural cultures were successfully employed to control an artificial agent resulting in high performance. Surprisingly, under the tetanus stimulus training, the robot performed better and better with the increasement of training cycle because of the short-term plasticity of neural network (a kind of reinforced learning). Comparing to the work previously reported, we adopted an effective experimental proposal (i.e. increasing the training cycle) to make sure of the occurrence of the short-term plasticity, and preliminarily demonstrated that the improvement of the robot's performance could be caused independently by the plasticity development of dissociated neural network. This new framework may provide some possible solutions for the learning abilities of intelligent robots by the engineering application of the plasticity processing of neural networks, also for the development of theoretical inspiration for the next generation neuro-prostheses on the basis of the bi-directional exchange of information within the hierarchical neural networks.\"],\n",
    "[510,1,0,\"Inspired by the oscillatory nature of cerebral cortex activity, we recently proposed and studied self-organizing maps (SOMs) based on limit cycle neural activity in an attempt to improve the information efficiency and robustness of conventional single-node, single-pattern representations. Here we explore for the first time the use of limit cycle SOMs to build a neural architecture that controls a robotic arm by solving inverse kinematics in reach-and-hold tasks. This multi-map architecture integrates open-loop and closed-loop controls that learn to self-organize oscillatory neural representations and to harness non-fixed-point neural activity even for fixed-point arm reaching tasks. We show through computer simulations that our architecture generalizes well, achieves accurate, fast, and smooth arm movements, and is robust in the face of arm perturbations, map damage, and variations of internal timing parameters controlling the flow of activity. A robotic implementation is evaluated successfully without further training, demonstrating for the first time that limit cycle maps can control a physical robot arm. We conclude that architectures based on limit cycle maps can be organized to function effectively as neural controllers.\"],\n",
    "[511,9,1,\"Robots are developing in much the same way that personal computers did 40 years ago, and robot operating system is the critical basis. Current robot software is mainly designed for individual robots. We present in this paper the design of micROS, a morphable, intelligent and collective robot operating system for future collective and collaborative robots. We first present the architecture of micROS, including the distributed architecture for collective robot system as a whole and the layered architecture for every single node. We then present the design of autonomous behavior management based on the observe-orient-decide-act cognitive behavior model and the design of collective intelligence including collective perception, collective cognition, collective game and collective dynamics. We also give the design of morphable resource management, which first categorizes robot resources into physical, information, cognitive and social domains, and then achieve morphability based on self-adaptive software technology. We finally deploy micROS on NuBot football robots and achieve significant improvement in real-time performance.\"],\n",
    "[512,0,0,\"Light- and ink-based three-dimensional (3D) printing methods allow the rapid design and fabrication of materials without the need for expensive tooling, dies or lithographic masks. They have led to an era of manufacturing in which computers can control the fabrication of soft matter that has tunable mechanical, electrical and other functional properties. The expanding range of printable materials, coupled with the ability to programmably control their composition and architecture across various length scales, is driving innovation in myriad applications. This is illustrated by examples of biologically inspired composites, shape-morphing systems, soft sensors and robotics that only additive manufacturing can produce.\"],\n",
    "[513,0,0,\"This paper presents a system for identification of wind features, such as gusts and wind shear. These are of particular interest in the context of energy-efficient navigation of Small Unmanned Aerial Systems (UAS). The proposed system generates real-time wind vector estimates and a novel algorithm to generate wind field predictions. Estimations are based on the integration of an off-the-shelf navigation system and airspeed readings in a so-called direct approach. Wind predictions use atmospheric models to characterize the wind field with different statistical analyses. During the prediction stage, the system is able to incorporate, in a big-data approach, wind measurements from previous flights in order to enhance the approximations. Wind estimates are classified and fitted into a Weibull probability density function. A Genetic Algorithm (GA) is utilized to determine the shaping and scale parameters of the distribution, which are employed to determine the most probable wind speed at a certain position. The system uses this information to characterize a wind shear or a discrete gust and also utilizes a Gaussian Process regression to characterize continuous gusts. The knowledge of the wind features is crucial for computing energy-efficient trajectories with low cost and payload. Therefore, the system provides a solution that does not require any additional sensors. The system architecture presents a modular decentralized approach, in which the main parts of the system are separated in modules and the exchange of information is managed by a communication handler to enhance upgradeability and maintainability. Validation is done providing preliminary results of both simulations and Software-In-The-Loop testing. Telemetry data collected from real flights, performed in the Seville Metropolitan Area in Andalusia (Spain), was used for testing. Results show that wind estimation and predictions can be calculated at 1 Hz and a wind map can be updated at 0.4 Hz . Predictions show a convergence time with a 95% confidence interval of approximately 30 s .\"],\n",
    "[514,0,0,\"This paper presents the modular design and control of a novel compliant lower limbmulti-joint exoskeleton for the rehabilitation of ankle kneemobility and locomotion of pediatric patients with neurological diseases, such as Cerebral Palsy (CP). The device consists of an untethered powered knee-ankle-foot orthosis (KAFO), addressed as WAKE-up (Wearable Ankle Knee Exoskeleton), characterized by a position control and capable of operating synchronously and synergistically with the human musculoskeletal system. The WAKE-up mechanical system, control architecture and feature extraction are described. Two test benches were used to mechanically characterize the device. The full system showed a maximum value of hysteresis equal to 8.8% and a maximum torque of 5.6 N m/rad. A pre-clinical use was performed, without body weight support, by four typically developing children and three children with CP. The aims were twofold: 1) to test the structure under weight-bearing conditions and 2) to ascertain its ability to provide appropriate assistance to the ankle and the knee during overground walking in a real environment. Results confirm the effectiveness of the WAKE-up design in providing torque assistance in accordance to the volitionalmovements especially in the recovery of correct foot landing at the start of the gait cycle.\"],\n",
    "[515,0,0,\"Biomechanical analysis of pelvic floor dysfunction requires knowledge of certain biomechanical parameters, such as muscle fiber direction, in order to adequately model function. Magnetic resonance (MR) diffusion tensor imaging (DTI) provides an estimate of overall muscle fiber directionality based on the mathematical description of water diffusivity. This work aimed at evaluating the concurrence between pubovisceralis muscle fiber representations obtained from DTI, and the maximum principal stress lines obtained through the finite element method. Seven datasets from axial T2-weighted images were used to build numerical models, and muscle fiber orientation estimated from the DT images. The in-plane projections of the first eigenvector of both vector fields describing muscle fiber orientation were extracted and compared. The directional consistency was evaluated by calculating the angle between the normalized vectors for the entire muscle and also for the right and left insertions, middle portions, and anorectal area. The values varied between 28 degrees +/- 6 (right middle portion) and 34 degrees +/- 9 (anorectal area), and were higher than the angular precision of the DT estimates, evaluated using wild bootstrapping analysis. Angular dispersion ranged from 17 degrees +/- 4 (left middle portion) to 23 degrees +/- 5 (anorectal area). Further studies are needed to examine acceptability of these differences when integrating the vectors estimated from DTI in the numerical analysis.\"],\n",
    "[516,0,0,\"The aging population with its concomitant medical conditions, physical and cognitive impairments, at a time of strained resources, establishes the urgent need to explore advanced technologies that may enhance function and quality of life. Recently, robotic technology, especially socially assistive robotics has been investigated to address the physical, cognitive, and social needs of older adults. Most system to date have predominantly focused on one-on-one human robot interaction (HRI). In this paper, we present a multi-user engagement-based robotic coach system architecture (ROCARE). ROCARE is capable of administering both one-on-one and multi-user HRI, providing implicit and explicit channels of communication, and individualized activity management for long-term engagement. Two preliminary feasibility studies, a one-on-one interaction and a triadic interaction with two humans and a robot, were conducted and the results indicated potential usefulness and acceptance by older adults, with and without cognitive impairment.\"],\n",
    "[517,0,0,\"Powered lower limb prostheses can assist users in a variety of ambulation modes by providing knee and/or ankle joint power. This study's goal was to develop a flexible control system to allow users to perform a variety of tasks in a natural, accurate, and reliable way. Six transfemoral amputees used a powered knee-ankle prosthesis to ascend/descend a ramp, climb a 3- and 4-step staircase, perform walking and standing transitions to and from the staircase, and ambulate at various speeds. A mode-specific classification architecture was developed to allow seamless transitions at four discrete gait events. Prosthesis mode transitions (i.e., the prosthesis' mechanical response) were delayed by 90 ms. Overall, users were not affected by this small delay. Offline classification results demonstrate significantly reduced error rates with the delayed system compared to the non-delayed system (p < 0.001). The average error rate for all heel contact decisions was 1.65% [0.99%] for the non-delayed system and 0.43% [0.23%] for the delayed system. The average error rate for all toe off decisions was 0.47% [0.16%] for the non-delayed system and 0.13% [0.05%] for the delayed system. The results are encouraging and provide another step towards a clinically viable intent recognition system for a powered knee-ankle prosthesis.\"],\n",
    "[518,0,0,\"Artificial tactile sensing is a challenging research topic in robotics, motor control, and rehabilitation engineering encompassing multi-disciplinary skills and different technologies. This paper presents the development of a wearable tactile thimble system using MEMS barometric sensors and flexible printed circuit board. Barometric sensors were carefully processed to make them able to transduce contact forces. Thumb, index, and medium fingers were equipped with an array of six sensing elements each, covering the central, lateral, and medial aspects of the fingertip. The sensor integration, signal read-out and processing, hardware architecture of the device, along with the calibration protocol, were described. The test results showed adequate sensitivity at very low forces with an almost linear transduction range up to about 4N (RMSE: 0.04N). Tests on object manipulation tasks highlighted the value of the proposed system demonstrating the ability of measuring both the force amplitude and contact points, demonstrating the suitability of barometric sensors for tactile applications.\"],\n",
    "[519,0,0,\"In this paper, a new robotic architecture for plant phenotyping is being introduced. The architecture consists of two robotic platforms: an autonomous ground vehicle (Vinobot) and a mobile observation tower (Vinoculer). The ground vehicle collects data from individual plants, while the observation tower oversees an entire field, identifying specific plants for further inspection by the Vinobot. The advantage of this architecture is threefold: first, it allows the system to inspect large areas of a field at any time, during the day and night, while identifying specific regions affected by biotic and/or abiotic stresses; second, it provides high-throughput plant phenotyping in the field by either comprehensive or selective acquisition of accurate and detailed data from groups or individual plants; and third, it eliminates the need for expensive and cumbersome aerial vehicles or similarly expensive and confined field platforms. As the preliminary results from our algorithms for data collection and 3D image processing, as well as the data analysis and comparison with phenotype data collected by hand demonstrate, the proposed architecture is cost effective, reliable, versatile, and extendable.\"],\n",
    "[520,0,0,\"Experimental evidence indicates that neurophysiological responses to well-known meaningful sensory items and symbols (such as familiar objects, faces, or words) differ from those to matched but novel and senseless materials (unknown objects, scrambled faces, and pseudowords). Spectral responses in the high beta- and gamma-band have been observed to be generally stronger to familiar stimuli than to unfamiliar ones. These differences have been hypothesized to be caused by the activation of distributed neuronal circuits or cell assemblies, which act as long-term memory traces for learned familiar items only. Here, we simulated word learning using a biologically constrained neurocomputational model of the left-hemispheric cortical areas known to be relevant for language and conceptual processing. The 12-area spiking neural-network architecture implemented replicates physiological and connectivity features of primary, secondary, and higher-association cortices in the frontal, temporal, and occipital lobes of the human brain. We simulated elementary aspects of word learning in it, focussing specifically on semantic grounding in action and perception. As a result of spike-driven Hebbian synaptic plasticity mechanisms, distributed, stimulus-specific cell-assembly (CA) circuits spontaneously emerged in the network. After training, presentation of one of the learned 'word' forms to the model correlate of primary auditory cortex induced periodic bursts of activity within the corresponding CA, leading to oscillatory phenomena in the entire network and spontaneous across-area neural synchronization. Crucially, Morlet wavelet analysis of the network's responses recorded during presentation of learned meaningful 'word' and novel, senseless 'pseudoword' patterns revealed stronger induced spectral power in the gamma-band for the former than the latter, closely mirroring differences found in neurophysiological data. Furthermore, coherence analysis of the simulated responses uncovered dissociated category specific patterns of synchronous oscillations in distant cortical areas, including indirectly connected primary sensorimotor areas. Bridging the gap between cellular-level mechanisms, neuronal-population behavior, and cognitive function, the present model constitutes the first spiking, neurobiologically, and anatomically realistic model able to explain high-frequency oscillatory phenomena indexing language processing on the basis of dynamics and competitive interactions of distributed cell-assembly circuits which emerge in the brain as a result of Hebbian learning and sensorimotor experience.\"],\n",
    "[521,0,0,\"Video understanding of robot-assisted surgery (RAS) videos is an active research area. Modeling the gestures and skill level of surgeons presents an interesting problem. The insights drawn may be applied in effective skill acquisition, objective skill assessment, real-time feedback, and human-robot collaborative surgeries. We propose a solution to the tool detection and localization open problem in RAS video understanding, using a strictly computer vision approach and the recent advances of deep learning. We propose an architecture using multimodal convolutional neural networks for fast detection and localization of tools in RAS videos. To the best of our knowledge, this approach will be the first to incorporate deep neural networks for tool detection and localization in RAS videos. Our architecture applies a region proposal network (RPN) and a multimodal two stream convolutional network for object detection to jointly predict objectness and localization on a fusion of image and temporal motion cues. Our results with an average precision of 91% and a mean computation time of 0.1 s per test frame detection indicate that our study is superior to conventionally used methods for medical imaging while also emphasizing the benefits of using RPN for precision and efficiency. We also introduce a new data set, ATLAS Dione, for RAS video understanding. Our data set provides video data of ten surgeons from Roswell Park Cancer Institute, Buffalo, NY, USA, performing six different surgical tasks on the daVinci Surgical System (dVSS) with annotations of robotic tools per frame.\"],\n",
    "[522,0,0,\"Human endothelial cells (ECs) were sent to the International Space Station (ISS) to determine the impact of microgravity on the formation of three-dimensional structures. For this project, an automatic experiment unit (EU) was designed allowing cell culture in space. In order to enable a safe cell culture, cell nourishment and fixation after a pre-programmed timeframe, the materials used for construction of the EUs were tested in regard to their biocompatibility. These tests revealed a high biocompatibility for all parts of the EUs, which were in contact with the cells or the medium used. Most importantly, we found polyether ether ketones for surrounding the incubation chamber, which kept cellular viability above 80% and allowed the cells to adhere as long as they were exposed to normal gravity. After assembling the EU the ECs were cultured therein, where they showed good cell viability at least for 14 days. In addition, the functionality of the automatic medium exchange, and fixation procedures were confirmed. Two days before launch, the ECs were cultured in the EUs, which were afterwards mounted on the SpaceX CRS-8 rocket. 5 and 12 days after launch the cells were fixed. Subsequent analyses revealed a scaffold-free formation of spheroids in space.\"],\n",
    "[523,0,0,\"Object detection and classification have countless applications in human-robot interacting systems. It is a necessary skill for autonomous robots that perform tasks in household scenarios. Despite the great advances in deep learning and computer vision, social robots performing non-trivial tasks usually spend most of their time finding and modeling objects. Working in real scenarios means dealing with constant environment changes and relatively low-quality sensor data due to the distance at which objects are often found. Ambient intelligence systems equipped with different sensors can also benefit from the ability to find objects, enabling them to inform humans about their location. For these applications to succeed, systems need to detect the objects that may potentially contain other objects, working with relatively low-resolution sensor data. A passive learning architecture for sensors has been designed in order to take advantage of multimodal information, obtained using an RGB-D camera and trained semantic language models. The main contribution of the architecture lies in the improvement of the performance of the sensor under conditions of low resolution and high light variations using a combination of image labeling and word semantics. The tests performed on each of the stages of the architecture compare this solution with current research labeling techniques for the application of an autonomous social robot working in an apartment. The results obtained demonstrate that the proposed sensor architecture outperforms state-of-the-art approaches.\"],\n",
    "[524,0,0,\"In this paper, a novel, motorized, multi-degrees-of-freedom (DoF), microsurgical forceps tool is presented, which is based on a master-slave teleoperation architecture. The slave device is a 7-DoF manipulator with: (i) 6-DoF positioning and orientation, (ii) 1 open/close gripper DoF; and (iii) an integrated force/torque sensor for tissue grip-force measurement. The master device is a 7-DoF haptic interface which teleoperates the slave device, and provides haptic feedback in its gripper interface. The combination of the device and the surgeon interface replaces the manual, hand-held device providing easy-to-use and ergonomic tissue control, simplifying the surgical tasks. This makes the system suitable to real surgical scenarios in the operating room (OR). The performance of the system was analysed through the evaluation of teleoperation control and characterization of gripping force. The new system offers an overall positioning error of less than 400 mum demonstrating its safety and accuracy. Improved system precision, usability, and ergonomics point to the potential suitability of the device for the OR and its ability to advance haptic-feedback-enhanced transoral laser microsurgeries.\"],\n",
    "[525,0,0,\"Soft pneumatic actuators (SPAs) are found in mobile robots, assistive wearable devices, and rehabilitative technologies. While soft actuators have been one of the most crucial elements of technology leading the development of the soft robotics field, they fall short of force output and bandwidth requirements for many tasks. In addition, other general problems remain open, including robustness, controllability, and repeatability. The SPA-pack architecture presented here aims to satisfy these standards of reliability crucial to the field of soft robotics, while also improving the basic performance capabilities of SPAs by borrowing advantages leveraged ubiquitously in biology; namely, the structured parallel arrangement of lower power actuators to form the basis of a larger and more powerful actuator module. An SPA-pack module consisting of a number of smaller SPAs will be studied using an analytical model and physical prototype. Experimental measurements show an SPA pack to generate over 112 N linear force, while the model indicates the benefit of parallel actuator grouping over a geometrically equivalent single SPA scale as an increasing function of the number of individual actuators in the group. For a module of four actuators, a 23% increase in force production over a volumetrically equivalent single SPA is predicted and validated, while further gains appear possible up to 50%. These findings affirm the advantage of utilizing a fascicle structure for high-performance soft robotic applications over existing monolithic SPA designs. An example of high-performance soft robotic platform will be presented to demonstrate the capability of SPA-pack modules in a complete and functional system.\"],\n",
    "[526,0,0,\"Wearable devices, such as smart glasses and watches, allow for continuous recording of everyday life in a real world over an extended period of time or lifelong. This possibility helps better understand the cognitive behavior of humans in real life as well as build human-aware intelligent agents for practical purposes. However, modeling the human cognitive activity from wearable-sensor data stream is challenging because learning new information often results in loss of previously acquired information, causing a problem known as catastrophic forgetting. Here we propose a deep-learning neural network architecture that resolves the catastrophic forgetting problem. Based on the neurocognitive theory of the complementary learning systems of the neocortex and hippocampus, we introduce a dual memory architecture (DMA) that, on one hand, slowly acquires the structured knowledge representations and, on the other hand, rapidly learns the specifics of individual experiences. The DMA system learns continuously through incremental feature adaptation and weight transfer. We evaluate the performance on two real-life datasets, the CIFAR-10 image-stream dataset and the 46-day Lifelog dataset collected from Google Glass, showing that the proposed model outperforms other online learning methods.\"],\n",
    "[527,0,0,\"OBJECTIVE: This article presents the results of an exploratory study in which 14 healthcare subject matter experts (H-SMEs) in addition to four research and design subject matter experts (RD-SMEs) at a regional rehabilitation hospital engaged in a series of complementary, participatory activities in order to design an assistive robotic table (ART). BACKGROUND: As designers, human factor experts, and healthcare professionals continue to work to integrate assistive human-robot technologies in healthcare, it is imperative to understand how the technology affects patient care from clinicians' perspectives. METHOD: Fourteen clinical H-SMEs rated a subset of conceptual ART design ideas; participated in the iterative design process of ART; and evaluated a final cardboard prototype, the rehabilitation hospital's current over-the-bed table (OBT), an ART built with true materials, and two therapy surface prototypes. Four RD-SMEs conducted a heuristic evaluation on the ART built with true materials. Data were analyzed by frequency and content analysis. RESULTS: The results include a design and prototype for the next generation ART and a pneumatically controlled therapy surface, a broadened list of specifications for the future design and implementation of assistive robotic furniture, and final observations. CONCLUSION: When compared to the rehabilitation hospital's current OBT, the developed ART in this study was successful. Designing novel features is dependent upon ensuring patient safety. The inclusion of clinicians in the participatory iterative design and evaluation process and the use of personas provided a broadened list of specifications for the successful implementation of assistive robotic furniture.\"],\n",
    "[528,0,0,\"As Moore's law reaches its end, traditional computing technology based on the Von Neumann architecture is facing fundamental limits. Among them is poor energy efficiency. This situation motivates the investigation of different processing information paradigms, such as the use of spiking neural networks (SNNs), which also introduce cognitive characteristics. As applications at very high scale are addressed, the energy dissipation needs to be minimized. This effort starts from the neuron cell. In this context, this paper presents the design of an original artificial neuron, in standard 65 nm CMOS technology with optimized energy efficiency. The neuron circuit response is designed as an approximation of the Morris-Lecar theoretical model. In order to implement the non-linear gating variables, which control the ionic channel currents, transistors operating in deep subthreshold are employed. Two different circuit variants describing the neuron model equations have been developed. The first one features spike characteristics, which correlate well with a biological neuron model. The second one is a simplification of the first, designed to exhibit higher spiking frequencies, targeting large scale bio-inspired information processing applications. The most important feature of the fabricated circuits is the energy efficiency of a few femtojoules per spike, which improves prior state-of-the-art by two to three orders of magnitude. This performance is achieved by minimizing two key parameters: the supply voltage and the related membrane capacitance. Meanwhile, the obtained standby power at a resting output does not exceed tens of picowatts. The two variants were sized to 200 and 35 mum(2) with the latter reaching a spiking output frequency of 26 kHz. This performance level could address various contexts, such as highly integrated neuro-processors for robotics, neuroscience or medical applications.\"],\n",
    "[529,0,0,\"Some insects or mammals use antennae or whiskers to detect by the sense of touch obstacles or recognize objects in environments in which other senses like vision cannot work. Artificial flexible antennae can be used in robotics to mimic this sense of touch in these recognition tasks. We have designed and built a two-degree of freedom (2DOF) flexible antenna sensor device to perform robot navigation tasks. This device is composed of a flexible beam, two servomotors that drive the beam and a load cell sensor that detects the contact of the beam with an object. It is found that the efficiency of such a device strongly depends on the speed and accuracy achieved by the antenna positioning system. These issues are severely impaired by the vibrations that appear in the antenna during its movement. However, these antennae are usually moved without taking care of these undesired vibrations. This article proposes a new closed-loop control schema that cancels vibrations and improves the free movements of the antenna. Moreover, algorithms to estimate the 3D beam position and the instant and point of contact with an object are proposed. Experiments are reported that illustrate the efficiency of these proposed algorithms and the improvements achieved in object detection tasks using a control system that cancels beam vibrations.\"],\n",
    "[530,0,0,\"Weather conditions can affect sensors' readings when sampling outdoors. Although sensors are usually set up covering a wide range of conditions, their operational range must be established. In recent years, depth cameras have been shown as a promising tool for plant phenotyping and other related uses. However, the use of these devices is still challenged by prevailing field conditions. Although the influence of lighting conditions on the performance of these cameras has already been established, the effect of wind is still unknown. This study establishes the associated errors when modeling some tree characteristics at different wind speeds. A system using a Kinect v2 sensor and a custom software was tested from null wind speed up to 10 m.s(-1). Two tree species with contrasting architecture, poplars and plums, were used as model plants. The results showed different responses depending on tree species and wind speed. Estimations of Leaf Area (LA) and tree volume were generally more consistent at high wind speeds in plum trees. Poplars were particularly affected by wind speeds higher than 5 m.s(-1). On the contrary, height measurements were more consistent for poplars than for plum trees. These results show that the use of depth cameras for tree characterization must take into consideration wind conditions in the field. In general, 5 m.s(-1) (18 km.h(-1)) could be established as a conservative limit for good estimations.\"],\n",
    "[531,0,0,\"In this paper, we present a novel automated method for White Matter (WM) lesion segmentation of Multiple Sclerosis (MS) patient images. Our approach is based on a cascade of two 3D patch-wise convolutional neural networks (CNN). The first network is trained to be more sensitive revealing possible candidate lesion voxels while the second network is trained to reduce the number of misclassified voxels coming from the first network. This cascaded CNN architecture tends to learn well from a small (n/=0.97) also with the expected lesion volume.\"],\n",
    "[532,0,0,\"Self-localization is one of the most challenging problems for deploying micro autonomous underwater vehicles ( mu AUV) in confined underwater environments. This paper extends a recently-developed self-localization method that is based on the attenuation of electro-magnetic waves, to the mu AUV domain. We demonstrate a compact, low-cost architecture that is able to perform all signal processing steps present in the original method. The system is passive with one-way signal transmission and scales to possibly large mu AUV fleets. It is based on the spherical localization concept. We present results from static and dynamic position estimation experiments and discuss the tradeoffs of the system.\"],\n",
    "[533,9,1,\"In this article, we present a CAN-based (Controller Area Network) distributed system to integrate sensors, actuators and hardware controllers in a mobile robot platform. With this work, we provide a robust, simple, flexible and open system to make hardware elements or subsystems communicate, that can be applied to different robots or mobile platforms. Hardware modules can be connected to or disconnected from the CAN bus while the system is working. It has been tested in our mobile robot Rato, based on a RWI (Real World Interface) mobile platform, to replace the old sensor and motor controllers. It has also been used in the design of two new robots: BellBot and WatchBot. Currently, our hardware integration architecture supports different sensors, actuators and control subsystems, such as motor controllers and inertial measurement units. The integration architecture was tested and compared with other solutions through a performance analysis of relevant parameters such as transmission efficiency and bandwidth usage. The results conclude that the proposed solution implements a lightweight communication protocol for mobile robot applications that avoids transmission delays and overhead.\"],\n",
    "[534,0,0,\"Tuberculosis (TB) is responsible for a global epidemic. TB treatment requires long-term therapy usually with multiple drugs, which have potential side effects and interactions that may influence patients' adherence to treatment. The TB Ge network is a multi-centric web based platform that collects clinical information of TB affected patients to increase their support and retention in care. The system stores the list of all tuberculosis episodes for each patient with the related data, starting from the first visit including follow-ups clinical evaluations, laboratory tests, imaging and therapies. Data can be manually input through the web interface or can be automatically imported from hospitals Laboratory Information Systems without human intervention. Automatic data import enhances data reuse and prevents errors introduction and time wasting. The network is an implementation of the Healthcare Services Specification Project (HSSP), as the Retrieve, Locate, and Update Service (RLUS) is used to manage patients' data. Clinical data are shared through standard HL7 Clinical Document Architecture (CDA) documents. Semantic interoperability is granted by the adoption of LOINC and ATC codes.\"],\n",
    "[535,0,0,\"The most popular noninvasive Brain Robot Interaction (BRI) technology uses the electroencephalogram- (EEG-) based Brain Computer Interface (BCI), to serve as an additional communication channel, for robot control via brainwaves. This technology is promising for elderly or disabled patient assistance with daily life. The key issue of a BRI system is to identify human mental activities, by decoding brainwaves, acquired with an EEG device. Compared with other BCI applications, such as word speller, the development of these applications may be more challenging since control of robot systems via brainwaves must consider surrounding environment feedback in real-time, robot mechanical kinematics, and dynamics, as well as robot control architecture and behavior. This article reviews the major techniques needed for developing BRI systems. In this review article, we first briefly introduce the background and development of mind-controlled robot technologies. Second, we discuss the EEG-based brain signal models with respect to generating principles, evoking mechanisms, and experimental paradigms. Subsequently, we review in detail commonly used methods for decoding brain signals, namely, preprocessing, feature extraction, and feature classification, and summarize several typical application examples. Next, we describe a few BRI applications, including wheelchairs, manipulators, drones, and humanoid robots with respect to synchronous and asynchronous BCI-based techniques. Finally, we address some existing problems and challenges with future BRI techniques.\"],\n",
    "[536,0,0,\"In order to harmonize robotic devices with human beings, the robots should be able to perceive important psychosomatic impact triggered by emotional states such as frustration or boredom. This paper presents a new type of biocooperative control architecture, which acts toward improving the challenge/skill relation perceived by the user when interacting with a robotic multimodal interface in a cooperative scenario. In the first part of the paper, open-loop experiments revealed which physiological signals were optimal for inclusion in the feedback loop. These were heart rate, skin conductance level, and skin conductance response frequency. In the second part of the paper, the proposed controller, consisting of a biocooperative architecture with two degrees of freedom, simultaneously modulating game difficulty and haptic assistance through performance and psychophysiological feedback, is presented. With this setup, the perceived challenge can be modulated by means of the game difficulty and the perceived skill by means of the haptic assistance. A new metric (FlowIndex) is proposed to numerically quantify and visualize the challenge/skill relation. The results are contrasted with comparable previously published work and show that the new method afforded a higher FlowIndex (i.e., a superior challenge/skill relation) and an improved balance between augmented performance and user satisfaction (higher level of valence, i.e., a more enjoyable and satisfactory experience).\"],\n",
    "[537,5,0,\"Departing from the conventional view of the reasons for the behavior of living systems, this research presents a radical and unique view of that behavior, as the observed side effects of a hierarchical set of simple, continuous, and dynamic negative feedback control systems, by way of an experimental model implemented on a real-world autonomous robotic rover. Rather than generating specific output from input, the systems control their perceptual inputs by varying output. The variables controlled do not exist in the environment, but are entirely internal perceptions constructed as a result of the layout and connections of the neural architecture. As the underlying processes are independent of the domain, the architecture is universal and thus has significant implications not only for understanding natural living systems, but also for the development of robotics systems. The central process of perceptual control has the potential to unify the behavioral sciences and is proposed as the missing behavioral principle of Artificial Life.\"],\n",
    "[538,0,0,\"BACKGROUND: Muscle co-contraction is a strategy of increasing movement accuracy and stability employed in dealing with force perturbation of movement. It is often seen in neuropathological populations. The direction of movement influences the pattern of co-contraction, but not all movements are easily achievable for populations with motor deficits. Manipulating the direction of the force instead, may be a promising rehabilitation protocol to train movement with use of a co-contraction reduction strategy. Force field learning paradigms provide a well described procedure to evoke and test muscle co-contraction. OBJECTIVE: The aim of this study was to test the muscle co-contraction pattern in a wide range of arm muscles in different force-field directions utilising a robot-mediated force field learning paradigm of motor adaptation. METHOD: Forty-two participants volunteered to participate in a study utilising robot-mediated force field motor adaptation paradigm with a clockwise or counter-clockwise force field. Kinematics and surface electromyography (EMG) of eight arm muscles were measured. RESULTS: Both muscle activation and co-contraction was earlier and stronger in flexors in the clockwise condition and in extensors in the counter-clockwise condition. CONCLUSIONS: Manipulating the force field direction leads to changes in the pattern of muscle co-contraction.\"],\n",
    "[539,0,0,\"The sophistication, complexity and intelligence of biological systems is a continuous source of inspiration for mankind. Mimicking the natural intelligence to devise tiny systems that are capable of self-regulated, autonomous action to, for example, distinguish different targets, remains among the grand challenges in biomimetic micro-robotics. Herein, we demonstrate an autonomous soft device, a light-driven flytrap, that uses optical feedback to trigger photomechanical actuation. The design is based on light-responsive liquid-crystal elastomer, fabricated onto the tip of an optical fibre, which acts as a power source and serves as a contactless probe that senses the environment. Mimicking natural flytraps, this artificial flytrap is capable of autonomous closure and object recognition. It enables self-regulated actuation within the fibre-sized architecture, thus opening up avenues towards soft, autonomous small-scale devices.\"],\n",
    "[540,5,0,\"This paper presents a state machine-based architecture, which enhances the flexibility and reusability of industrial robots, more concretely dual-arm multisensor robots. The proposed architecture, in addition to allowing absolute control of the execution, eases the programming of new applications by increasing the reusability of the developed modules. Through an easy-to-use graphical user interface, operators are able to create, modify, reuse and maintain industrial processes, increasing the flexibility of the cell. Moreover, the proposed approach is applied in a real use case in order to demonstrate its capabilities and feasibility in industrial environments. A comparative analysis is presented for evaluating the presented approach versus traditional robot programming techniques.\"],\n",
    "[541,5,0,\"In this paper, we present a novel approach to human-robot control. Taking inspiration from behaviour-based robotics and self-organisation principles, we present an interfacing mechanism, with the ability to adapt both towards the user and the robotic morphology. The aim is for a transparent mechanism connecting user and robot, allowing for a seamless integration of control signals and robot behaviours. Instead of the user adapting to the interface and control paradigm, the proposed architecture allows the user to shape the control motifs in their way of preference, moving away from the case where the user has to read and understand an operation manual, or it has to learn to operate a specific device. Starting from a tabula rasa basis, the architecture is able to identify control patterns (behaviours) for the given robotic morphology and successfully merge them with control signals from the user, regardless of the input device used. The structural components of the interface are presented and assessed both individually and as a whole. Inherent properties of the architecture are presented and explained. At the same time, emergent properties are presented and investigated. As a whole, this paradigm of control is found to highlight the potential for a change in the paradigm of robotic control, and a new level in the taxonomy of human in the loop systems.\"],\n",
    "[542,0,0,\"Human-robot interaction sensing is a compulsory feature in modern robotic systems where direct contact or close collaboration is desired. Rehabilitation and assistive robotics are fields where interaction forces are required for both safety and increased control performance of the device with a more comfortable experience for the user. In order to provide an efficient interaction feedback between the user and rehabilitation device, high performance sensing units are demanded. This work introduces a novel design of a multi-axis force sensor dedicated for measuring pelvis interaction forces in a rehabilitation exoskeleton device. The sensor is conceived such that it has different sensitivity characteristics for the three axes of interest having also movable parts in order to allow free rotations and limit crosstalk errors. Integrated sensor electronics make it easy to acquire and process data for a real-time distributed system architecture. Two of the developed sensors are integrated and tested in a complex gait rehabilitation device for safe and compliant control.\"],\n",
    "[543,0,0,\"Recent advances in omics technologies have not been accompanied by equally efficient, cost-effective, and accurate phenotyping methods required to dissect the genetic architecture of complex traits. Even though high-throughput phenotyping platforms have been developed for controlled environments, field-based aerial and ground technologies have only been designed and deployed for short-stature crops. Therefore, we developed and tested Phenobot 1.0, an auto-steered and self-propelled field-based high-throughput phenotyping platform for tall dense canopy crops, such as sorghum (Sorghum bicolor). Phenobot 1.0 was equipped with laterally positioned and vertically stacked stereo RGB cameras. Images collected from 307 diverse sorghum lines were reconstructed in 3D for feature extraction. User interfaces were developed, and multiple algorithms were evaluated for their accuracy in estimating plant height and stem diameter. Tested feature extraction methods included the following: (1) User-interactive Individual Plant Height Extraction (UsIn-PHe) based on dense stereo three-dimensional reconstruction; (2) Automatic Hedge-based Plant Height Extraction (Auto-PHe) based on dense stereo 3D reconstruction; (3) User-interactive Dense Stereo Matching Stem Diameter Extraction; and (4) User-interactive Image Patch Stereo Matching Stem Diameter Extraction (IPaS-Di). Comparative genome-wide association analysis and ground-truth validation demonstrated that both UsIn-PHe and Auto-PHe were accurate methods to estimate plant height, while Auto-PHe had the additional advantage of being a completely automated process. For stem diameter, IPaS-Di generated the most accurate estimates of this biomass-related architectural trait. In summary, our technology was proven robust to obtain ground-based high-throughput plant architecture parameters of sorghum, a tall and densely planted crop species.\"],\n",
    "[544,0,0,\"The tiger beetle can maintain its stability by controlling the interaction force between its legs and an unstructured terrain while it runs. The biomimetic hexapod robot mimics a tiger beetle, and a comprehensive force sensing system combined with certain algorithms can provide force information that can help the robot understand the unstructured terrain that it interacts with. This study introduces a complicated leg force sensing system for a hexapod robot that is the same for all six legs. First, the layout and configuration of sensing system are designed according to the structure and sizes of legs. Second, the joint toque sensors, 3-DOF foot-end force sensor and force information processing module are designed, and the force sensor performance parameters are tested by simulations and experiments. Moreover, a force sensing system is implemented within the robot control architecture. Finally, the experimental evaluation of the leg force sensor system on the hexapod robot is discussed and the performance of the leg force sensor system is verified.\"],\n",
    "[545,0,0,\"Objective: Despite over 50 years of research on the physiological effects of sustained bed rest, data characterizing its effects on sleep macrostructure and breathing stability in humans are scarce. This study was conducted to determine the effects of continuous exposure to hypoxia and sustained best rest, both individually and combined, on nocturnal sleep and breathing stability. Methods: Eleven participants completed three randomized, counter-balanced, 21-days trials of: (1) normoxic bed rest (NBR, PIO2 = 133.1 +/- 0.3), (2) hypoxic ambulatory confinement (HAMB, PIO2 = 90.0 +/- 0.4) and (3) hypoxic bed rest (HBR, PIO2 = 90.0 +/- 0.4; ~4,000 m equivalent altitude). Full objective polysomnography was performed at baseline, on Night 1 and Night 21 in each condition. Results: In NBR Night 1, more time was spent in light sleep (10 +/- 2%) compared to baseline (8 +/- 2%; p = 0.028); Slow-wave sleep (SWS) was reduced from baseline in the hypoxic-only trial by 18% (HAMB Night 21, p = 0.028) and further reduced by 33% (HBR Night 1, p = 0.010), and 36% (HBR Night 21, p = 0.008) when combined with bed rest. The apnea-hypopnea index doubled from Night 1 to Night 21 in HBR (32-62 events.h(-1)) and HAMB (31-59 events.h(-1); p = 0.002). Those who experienced greatest breathing instability from Night 1 to Night 21 (NBR) were correlated to unchanged or higher (+1%) night SpO2 concentrations (R(2) = 0.471, p = 0.020). Conclusion: Bed rest negatively affects sleep macrostructure, increases the apnea-hypopnea index, and worsens breathing stability, each independently exacerbated by continuous exposure to hypoxia.\"],\n",
    "[546,1,0,\"In this work a design for self-tuning non-linear Fuzzy Proportional Integral Derivative (FPID) controller is presented to control position and speed of Multiple Input Multiple Output (MIMO) fully-actuated Autonomous Underwater Vehicles (AUV) to follow desired trajectories. Non-linearity that results from the hydrodynamics and the coupled AUV dynamics makes the design of a stable controller a very difficult task. In this study, the control scheme in a simulation environment is validated using dynamic and kinematic equations for the AUV model and hydrodynamic damping equations. An AUV configuration with eight thrusters and an inverse kinematic model from a previous work is utilized in the simulation. In the proposed controller, Mamdani fuzzy rules are used to tune the parameters of the PID. Nonlinear fuzzy Gaussian membership functions are selected to give better performance and response in the non-linear system. A control architecture with two feedback loops is designed such that the inner loop is for velocity control and outer loop is for position control. Several test scenarios are executed to validate the controller performance including different complex trajectories with and without injection of ocean current disturbances. A comparison between the proposed FPID controller and the conventional PID controller is studied and shows that the FPID controller has a faster response to the reference signal and more stable behavior in a disturbed non-linear environment.\"],\n",
    "[547,0,0,\"PURPOSE: Focal epilepsy is a neurological disease that can be surgically treated by removing area of the brain generating the seizures. The stereotactic electroencephalography (SEEG) procedure allows patient brain activity to be recorded in order to localize the onset of seizures through the placement of intracranial electrodes. The planning phase can be cumbersome and very time consuming, and no quantitative information is provided to neurosurgeons regarding the safety and efficacy of their trajectories. In this work, we present a novel architecture specifically designed to ease the SEEG trajectory planning using the 3D Slicer platform as a basis. METHODS: Trajectories are automatically optimized following criteria like vessel distance and insertion angle. Multi-trajectory optimization and conflict resolution are optimized through a selective brute force approach based on a conflict graph construction. Additionally, electrode-specific optimization constraints can be defined, and an advanced verification module allows neurosurgeons to evaluate the feasibility of the trajectory. RESULTS: A retrospective evaluation was performed using manually planned trajectories on 20 patients: the planning algorithm optimized and improved trajectories in 98% of cases. We were able to resolve and optimize the remaining 2% by applying electrode-specific constraints based on manual planning values. In addition, we found that the global parameters used discards 68% of the manual planned trajectories, even when they represent a safe clinical choice. CONCLUSIONS: Our approach improved manual planned trajectories in 98% of cases in terms of quantitative indexes, even when applying more conservative criteria with respect to actual clinical practice. The improved multi-trajectory strategy overcomes the previous work limitations and allows electrode optimization within a tolerable time span.\"],\n",
    "[548,0,0,\"This paper illustrates a new architecture for a human-humanoid interaction based on EEG-brain computer interface (EEG-BCI) for patients affected by locked-in syndrome caused by Amyotrophic Lateral Sclerosis (ALS). The proposed architecture is able to recognise users' mental state accordingly to the biofeedback factor , based on users' attention, intention, and focus, that is used to elicit a robot to perform customised behaviours. Experiments have been conducted with a population of eight subjects: four ALS patients in a near locked-in status with normal ocular movement and four healthy control subjects enrolled for age, education, and computer expertise. The results showed as three ALS patients have completed the task with 96.67% success; the healthy controls with 100% success; the fourth ALS has been excluded from the results for his low general attention during the task; the analysis of factor highlights as ALS subjects have shown stronger (81.20%) than healthy controls (76.77%). Finally, a post-hoc analysis is provided to show how robotic feedback helps in maintaining focus on expected task. These preliminary data suggest that ALS patients could successfully control a humanoid robot through a BCI architecture, potentially enabling them to conduct some everyday tasks and extend their presence in the environment.\"],\n",
    "[549,0,0,\"What is the place of emotion in intelligent robots? Researchers have advocated the inclusion of some emotion-related components in the information-processing architecture of autonomous agents. It is argued here that emotion needs to be merged with all aspects of the architecture: cognitive-emotional integration should be a key design principle.\"],\n",
    "[550,5,0,\"A neuromechanical simulation of a planar, bipedal walking robot has been developed. It is constructed as a simplified, planar musculoskeletal model of the biomechanics of the human lower body. The controller consists of a dynamic neural network with central pattern generators (CPGs) entrained by force and movement sensory feedback to generate appropriate muscle forces for walking. The CPG model is a two-level architecture, which consists of separate rhythm generator and pattern formation networks. The biped model walks stably in the sagittal plane without inertial sensors or a centralized posture controller or a 'baby walker' to help overcome gravity. Its gait is similar to humans' and it walks at speeds from 0.850 m s(-1) up to 1.289 m s(-1) with leg length of 0.84 m. The model walks over small unknown steps (6% of leg length) and up and down 5 degrees slopes without any additional higher level control actions.\"],\n",
    "[551,0,0,\"BACKGROUND: Research into robotic systems for single port surgery (SPS) has become widespread around the world in recent years. A new robot arm system for SPS was developed, but its positioning platform and other hardware components were not efficient. Special features of the developed surgical robot system make good teleoperation with safety and efficiency difficult. METHODS: A robot arm is combined and used as new positioning platform, and the remote center motion is realized by a new method using active motion control. A new mapping strategy based on kinematics computation and a novel optimal coordinated control strategy based on real-time approaching to a defined anthropopathic criterion configuration that is referred to the customary ease state of human arms and especially the configuration of boxers' habitual preparation posture are developed. RESULTS: The hardware components, control architecture, control system, and mapping strategy of the robotic system has been updated. A novel optimal coordinated control strategy is proposed and tested. CONCLUSIONS: The new robot system can be more dexterous, intelligent, convenient and safer for preoperative positioning and intraoperative adjustment. The mapping strategy can achieve good following and representation for the slave manipulator arms. And the proposed novel control strategy can enable them to complete tasks with higher maneuverability, lower possibility of self-interference and singularity free while teleoperating.\"],\n",
    "[552,0,0,\"Neglect and hemianopia are two neuropsychological syndromes that are associated with reduced awareness for visual signals in patients' contralesional hemifield. They offer the unique possibility to dissociate the contributions of retino-geniculate and retino-colliculo circuitries in visual perception. Yet, insights from patient fMRI studies are limited by heterogeneity in lesion location and extent, long-term functional reorganization and behavioural compensation after stroke. Transcranial magnetic stimulation (TMS) has therefore been proposed as a complementary method to investigate the effect of transient perturbations on functional brain organization. This concurrent TMS-fMRI study applied TMS perturbation to occipital and parietal cortices with the aim to 'mimick' neglect and hemianopia. Based on the challenges and interpretational limitations of our own study we aim to provide tutorial guidance on how future studies should compare TMS to primary sensory and association areas that are governed by distinct computational principles, neural dynamics and functional architecture.\"],\n",
    "[553,0,0,\"Hydrogels from self-assembling ionic complementary peptides have been receiving a lot of interest from the scientific community as mimetic of the extracellular matrix that can offer three-dimensional supports for cell growth or can become vehicles for the delivery of stem cells, drugs or bioactive proteins. In order to develop a 3D 'architecture' for mesenchymal stem cells, we propose the introduction in the hydrogel of conjugates obtained by chemoselective ligation between a ionic-complementary self-assembling peptide (called EAK) and three different bioactive molecules: an adhesive sequence with 4 Glycine-Arginine-Glycine-Aspartic Acid-Serine-Proline (GRGDSP) motifs per chain, an adhesive peptide mapped on h-Vitronectin and the growth factor Insulin-like Growth Factor-1 (IGF-1). The mesenchymal stem cell adhesion assays showed a significant increase in adhesion and proliferation for the hydrogels decorated with each of the synthesized conjugates; moreover, such functionalized 3D hydrogels support cell spreading and elongation, validating the use of this class of self-assembly peptides-based material as very promising 3D model scaffolds for cell cultures, at variance of the less realistic 2D ones. Furthermore, small amplitude oscillatory shear tests showed that the presence of IGF-1-conjugate did not alter significantly the viscoelastic properties of the hydrogels even though differences were observed in the nanoscale structure of the scaffolds obtained by changing their composition, ranging from long, well-defined fibers for conjugates with adhesion sequences to the compact and dense film for the IGF-1-conjugate.\"],\n",
    "[554,0,0,\"For robots to successfully integrate into everyday life, it is important that they can be effectively controlled by laypeople. However, the task of manually controlling mobile robots can be challenging due to demanding cognitive and sensorimotor requirements. This research explores the effect that the built environment has on the manual control of domestic service robots. In this study, a virtual reality simulation of a domestic robot control scenario was developed. The performance of fifty novice users was evaluated, and their subjective experiences recorded through questionnaires. Through quantitative and qualitative analysis, it was found that untrained operators frequently perform poorly at navigation-based robot control tasks. The study found that passing through doorways accounted for the largest number of collisions, and was consistently identified as a very difficult operation to perform. These findings suggest that homes and other human-orientated settings present significant challenges to robot control.\"],\n",
    "[555,0,0,\"A telepresence mobile robot is a remote-controlled, wheeled device with wireless internet connectivity for bidirectional audio, video and data transmission. In health care, a telepresence robot could be used to have a clinician or a caregiver assist seniors in their homes without having to travel to these locations. Many mobile telepresence robotic platforms have recently been introduced on the market, bringing mobility to telecommunication and vital sign monitoring at reasonable costs. What is missing for making them effective remote telepresence systems for home care assistance are capabilities specifically needed to assist the remote operator in controlling the robot and perceiving the environment through the robot's sensors or, in other words, minimizing cognitive load and maximizing situation awareness. This paper describes our approach adding navigation, artificial audition and vital sign monitoring capabilities to a commercially available telepresence mobile robot. This requires the use of a robot control architecture to integrate the autonomous and teleoperation capabilities of the platform.\"],\n",
    "[556,0,0,\"IntelliTable is a new proof-of-principle assistive technology system with robotic capabilities in the form of an elegant universal cantilever table able to move around by itself, or under user control. We describe the design and current capabilities of the table and the human-centered design methodology used in its development and initial evaluation. The IntelliTable study has delivered robotic platform programmed by a smartphone that can navigate around a typical home or care environment, avoiding obstacles, and positioning itself at the user's command. It can also be configured to navigate itself to pre-ordained places positions within an environment using ceiling tracking, responsive optical guidance and object-based sonar navigation.\"],\n",
    "[557,0,0,\"Cephalopods, the group of animals including octopus, squid, and cuttlefish, have remarkable ability to instantly modulate body coloration and patterns so as to blend into surrounding environments [1, 2] or send warning signals to other animals [3]. Reflectin is expressed exclusively in cephalopods, filling the lamellae of intracellular Bragg reflectors that exhibit dynamic iridescence and structural color change [4]. Here, we trace the possible origin of the reflectin gene back to a transposon from the symbiotic bioluminescent bacterium Vibrio fischeri and report the hierarchical structural architecture of reflectin protein. Intrinsic self-assembly, and higher-order assembly tightly modulated by aromatic compounds, provide insights into the formation of multilayer reflectors in iridophores and spherical microparticles in leucophores and may form the basis of structural color change in cephalopods. Self-assembly and higher-order assembly in reflectin originated from a core repeating octapeptide (here named protopeptide), which may be from the same symbiotic bacteria. The origin of the reflectin gene and assembly features of reflectin protein are of considerable biological interest. The hierarchical structural architecture of reflectin and its domain and protopeptide not only provide insights for bioinspired photonic materials but also serve as unique 'assembly tags' and feasible molecular platforms in biotechnology.\"],\n",
    "[558,5,0,\"Dynamic neural fields (DNFs) are dynamical systems models that approximate the activity of large, homogeneous, and recurrently connected neural networks based on a mean field approach. Within dynamic field theory, the DNFs have been used as building blocks in architectures to model sensorimotor embedding of cognitive processes. Typically, the parameters of a DNF in an architecture are manually tuned in order to achieve a specific dynamic behavior (e.g., decision making, selection, or working memory) for a given input pattern. This manual parameters search requires expert knowledge and time to find and verify a suited set of parameters. The DNF parametrization may be particular challenging if the input distribution is not known in advance, e.g., when processing sensory information. In this paper, we propose the autonomous adaptation of the DNF resting level and gain by a learning mechanism of intrinsic plasticity (IP). To enable this adaptation, an input and output measure for the DNF are introduced, together with a hyper parameter to define the desired output distribution. The online adaptation by IP gives the possibility to pre-define the DNF output statistics without knowledge of the input distribution and thus, also to compensate for changes in it. The capabilities and limitations of this approach are evaluated in a number of experiments.\"],\n",
    "[559,0,0,\"Emotions play a significant role in internal regulatory processes. In this paper, we advocate four key ideas. First, novelty detection can be grounded in the sensorimotor experience and allow higher order appraisal. Second, cognitive processes, such as those involved in self-assessment, influence emotional states by eliciting affects like boredom and frustration. Third, emotional processes such as those triggered by self-assessment influence attentional processes. Last, close emotion-cognition interactions implement an efficient feedback loop for the purpose of top-down behavior regulation. The latter is what we call 'Emotional Metacontrol'. We introduce a model based on artificial neural networks. This architecture is used to control a robotic system in a visual search task. The emotional metacontrol intervenes to bias the robot visual attention during active object recognition. Through a behavioral and statistical analysis, we show that this mechanism increases the robot performance and fosters the exploratory behavior to avoid deadlocks.\"],\n",
    "[560,1,0,\"In this study, a novel decentralized adaptive full-order sliding mode control framework is proposed for the robust synchronized formation motion of multiple unmanned aerial vehicles (UAVs) subject to system uncertainty. First, a full-order sliding mode surface in a decentralized manner is designed to incorporate both the individual position tracking error and the synchronized formation error while the UAV group is engaged in building a certain desired geometric pattern in three dimensional space. Second, a decentralized virtual plant controller is constructed which allows the embedded low-pass filter to attain the chattering free property of the sliding mode controller. In addition, robust adaptive technique is integrated in the decentralized chattering free sliding control design in order to handle unknown bounded uncertainties, without requirements for assuming a priori knowledge of bounds on the system uncertainties as stated in conventional chattering free control methods. Subsequently, system robustness as well as stability of the decentralized full-order sliding mode control of multiple UAVs is synthesized. Numerical simulation results illustrate the effectiveness of the proposed control framework to achieve robust 3D formation flight of the multi-UAV system.\"],\n",
    "[561,0,0,\"Decision-making systems are an integral part of any autonomous device. With the recent developments in bio-nanorobots, smart drugs, and engineered viruses, there is an immediate need of decision-making systems which are bio-compatible in nature. DNA is considered a perfect candidate for designing the computing systems in such decision-making systems because of their bio-compatibility and programmability. Complex biological systems can be easily modeled/controlled using fuzzy logic operations with the help of linguistic rules. In this paper, we propose an enzyme-free DNA strand displacement-based architecture of fuzzy inference engine using the fuzzy operators, such as fuzzy intersection and union. The basic building blocks of this architecture are minimum, maximum, and fan-out gates. All these gates are analog in nature, which means that the input/output values of the gates are represented by the concentration of the input/output DNA strands. To demonstrate the performance of the proposed architecture, a detailed design, analysis, and kinetic simulation of each gate were carried out. Finally, the minimum and maximum gates are cascaded according to the pre-defined rules to design the fuzzy inference engine. All these DNA circuits are implemented and simulated in Visual DSD software.\"],\n",
    "[562,0,0,\"Lifelong learning is fundamental in autonomous robotics for the acquisition and fine-tuning of knowledge through experience. However, conventional deep neural models for action recognition from videos do not account for lifelong learning but rather learn a batch of training data with a predefined number of action classes and samples. Thus, there is the need to develop learning systems with the ability to incrementally process available perceptual cues and to adapt their responses over time. We propose a self-organizing neural architecture for incrementally learning to classify human actions from video sequences. The architecture comprises growing self-organizing networks equipped with recurrent neurons for processing time-varying patterns. We use a set of hierarchically arranged recurrent networks for the unsupervised learning of action representations with increasingly large spatiotemporal receptive fields. Lifelong learning is achieved in terms of prediction-driven neural dynamics in which the growth and the adaptation of the recurrent networks are driven by their capability to reconstruct temporally ordered input sequences. Experimental results on a classification task using two action benchmark datasets show that our model is competitive with state-of-the-art methods for batch learning also when a significant number of sample labels are missing or corrupted during training sessions. Additional experiments show the ability of our model to adapt to non-stationary input avoiding catastrophic interference.\"],\n",
    "[563,5,0,\"Imitation learning through self-exploration is essential in developing sensorimotor skills. Most developmental theories emphasize that social interactions, especially understanding of observed actions, could be first achieved through imitation, yet the discussion on the origin of primitive imitative abilities is often neglected, referring instead to the possibility of its innateness. This paper presents a developmental model of imitation learning based on the hypothesis that humanoid robot acquires imitative abilities as induced by sensorimotor associative learning through self-exploration. In designing such learning system, several key issues will be addressed: automatic segmentation of the observed actions into motion primitives using raw images acquired from the camera without requiring any kinematic model; incremental learning of spatio-temporal motion sequences to dynamically generates a topological structure in a self-stabilizing manner; organization of the learned data for easy and efficient retrieval using a dynamic associative memory; and utilizing segmented motion primitives to generate complex behavior by the combining these motion primitives. In our experiment, the self-posture is acquired through observing the image of its own body posture while performing the action in front of a mirror through body babbling. The complete architecture was evaluated by simulation and real robot experiments performed on DARwIn-OP humanoid robot.\"],\n",
    "[564,0,0,\"The eSource Data Interchange Group, part of the Clinical Data Interchange Standards Consortium, proposed five scenarios to guide stakeholders in the development of solutions for the capture of eSource data. The fifth scenario was subdivided into four tiers to adapt the functionality of electronic health records to support clinical research. In order to develop a system belonging to the 'Interoperable' Tier, the authors decided to adopt the service-oriented architecture paradigm to support technical interoperability, Health Level Seven Version 3 messages combined with LOINC (Logical Observation Identifiers Names and Codes) vocabulary to ensure semantic interoperability, and Healthcare Services Specification Project standards to provide process interoperability. The developed architecture enhances the integration between patient-care practice and medical research, allowing clinical data sharing between two hospital information systems and four clinical data management systems/clinical registries. The core is formed by a set of standardized cloud services connected through standardized interfaces, involving client applications. The system was approved by a medical staff, since it reduces the workload for the management of clinical trials. Although this architecture can realize the 'Interoperable' Tier, the current solution actually covers the 'Connected' Tier, due to local hospital policy restrictions.\"],\n",
    "[565,0,0,\"The eSource Data Interchange Group, part of the Clinical Data Interchange Standards Consortium, proposed five scenarios to guide stakeholders in the development of solutions for the capture of eSource data. The fifth scenario was subdivided into four tiers to adapt the functionality of electronic health records to support clinical research. In order to develop a system belonging to the 'Interoperable' Tier, the authors decided to adopt the service-oriented architecture paradigm to support technical interoperability, Health Level Seven Version 3 messages combined with LOINC (Logical Observation Identifiers Names and Codes) vocabulary to ensure semantic interoperability, and Healthcare Services Specification Project standards to provide process interoperability. The developed architecture enhances the integration between patient-care practice and medical research, allowing clinical data sharing between two hospital information systems and four clinical data management systems/clinical registries. The core is formed by a set of standardized cloud services connected through standardized interfaces, involving client applications. The system was approved by a medical staff, since it reduces the workload for the management of clinical trials. Although this architecture can realize the 'Interoperable' Tier, the current solution actually covers the 'Connected' Tier, due to local hospital policy restrictions.\"],\n",
    "[566,0,0,\"Current models of speech and language processing postulate the involvement of two parallel processing streams (the dual stream model): a ventral stream involved in mapping sensory and phonological representations onto lexical and conceptual representations and a dorsal stream contributing to sound-to-motor mapping, articulation, and to how verbal information is encoded and manipulated in memory. Based on previous evidence showing that music training has an influence on language processing, cognitive functions, and word learning, we examined EEG-based intracranial functional connectivity in the ventral and dorsal streams while musicians and nonmusicians learned the meaning of novel words through picture-word associations. In accordance with the dual stream model, word learning was generally associated with increased beta functional connectivity in the ventral stream compared to the dorsal stream. In addition, in the linguistically most demanding 'semantic task,' musicians outperformed nonmusicians, and this behavioral advantage was accompanied by increased left-hemispheric theta connectivity in both streams. Moreover, theta coherence in the left dorsal pathway was positively correlated with the number of years of music training. These results provide evidence for a complex interplay within a network of brain regions involved in semantic processing and verbal memory functions, and suggest that intensive music training can modify its functional architecture leading to advantages in novel word learning.\"],\n",
    "[567,0,0,\"The core principles of the evolutionary theories of emotions declare that affective states represent crucial drives for action selection in the environment and regulated the behavior and adaptation of natural agents in ancestrally recurrent situations. While many different studies used autonomous artificial agents to simulate emotional responses and the way these patterns can affect decision-making, few are the approaches that tried to analyze the evolutionary emergence of affective behaviors directly from the specific adaptive problems posed by the ancestral environment. A model of the evolution of affective behaviors is presented using simulated artificial agents equipped with neural networks and physically inspired on the architecture of the iCub humanoid robot. We use genetic algorithms to train populations of virtual robots across generations, and investigate the spontaneous emergence of basic emotional behaviors in different experimental conditions. In particular, we focus on studying the emotion of fear, therefore the environment explored by the artificial agents can contain stimuli that are safe or dangerous to pick. The simulated task is based on classical conditioning and the agents are asked to learn a strategy to recognize whether the environment is safe or represents a threat to their lives and select the correct action to perform in absence of any visual cues. The simulated agents have special input units in their neural structure whose activation keep track of their actual 'sensations' based on the outcome of past behavior. We train five different neural network architectures and then test the best ranked individuals comparing their performances and analyzing the unit activations in each individual's life cycle. We show that the agents, regardless of the presence of recurrent connections, spontaneously evolved the ability to cope with potentially dangerous environment by collecting information about the environment and then switching their behavior to a genetically selected pattern in order to maximize the possible reward. We also prove the determinant presence of an internal time perception unit for the robots to achieve the highest performance and survivability across all conditions.\"],\n",
    "[568,0,0,\"Over 50 million United States citizens (1 in 6 people in the US) have a developmental, acquired, or degenerative disability. The average US citizen can expect to live 20% of his or her life with a disability. Rehabilitation technologies play a major role in improving the quality of life for people with a disability, yet widespread and highly challenging needs remain. Within the US, a major effort aimed at the creation and evaluation of rehabilitation technology has been the Rehabilitation Engineering Research Centers (RERCs) sponsored by the National Institute on Disability, Independent Living, and Rehabilitation Research. As envisioned at their conception by a panel of the National Academy of Science in 1970, these centers were intended to take a 'total approach to rehabilitation', combining medicine, engineering, and related science, to improve the quality of life of individuals with a disability. Here, we review the scope, achievements, and ongoing projects of an unbiased sample of 19 currently active or recently terminated RERCs. Specifically, for each center, we briefly explain the needs it targets, summarize key historical advances, identify emerging innovations, and consider future directions. Our assessment from this review is that the RERC program indeed involves a multidisciplinary approach, with 36 professional fields involved, although 70% of research and development staff are in engineering fields, 23% in clinical fields, and only 7% in basic science fields; significantly, 11% of the professional staff have a disability related to their research. We observe that the RERC program has substantially diversified the scope of its work since the 1970's, addressing more types of disabilities using more technologies, and, in particular, often now focusing on information technologies. RERC work also now often views users as integrated into an interdependent society through technologies that both people with and without disabilities co-use (such as the internet, wireless communication, and architecture). In addition, RERC research has evolved to view users as able at improving outcomes through learning, exercise, and plasticity (rather than being static), which can be optimally timed. We provide examples of rehabilitation technology innovation produced by the RERCs that illustrate this increasingly diversifying scope and evolving perspective. We conclude by discussing growth opportunities and possible future directions of the RERC program.\"],\n",
    "[569,0,0,\"Muscle weakness-which can result from neurological injuries, genetic disorders, or typical aging-can affect a person's mobility and quality of life. For many people with muscle weakness, assistive devices provide the means to regain mobility and independence. These devices range from well-established technology, such as wheelchairs, to newer technologies, such as exoskeletons and exosuits. For assistive devices to be used in everyday life, they must provide assistance across activities of daily living (ADLs) in an unobtrusive manner. This article introduces the Myosuit, a soft, wearable device designed to provide continuous assistance at the hip and knee joint when working with and against gravity in ADLs. This robotic device combines active and passive elements with a closed-loop force controller designed to behave like an external muscle (exomuscle) and deliver gravity compensation to the user. At 4.1 kg (4.6 kg with batteries), the Myosuit is one of the lightest untethered devices capable of delivering gravity support to the user's knee and hip joints. This article presents the design and control principles of the Myosuit. It describes the textile interface, tendon actuators, and a bi-articular, synergy-based approach for continuous assistance. The assistive controller, based on bi-articular force assistance, was tested with a single subject who performed sitting transfers, one of the most gravity-intensive ADLs. The results show that the control concept can successfully identify changes in the posture and assist hip and knee extension with up to 26% of the natural knee moment and up to 35% of the knee power. We conclude that the Myosuit's novel approach to assistance using a bi-articular architecture, in combination with the posture-based force controller, can effectively assist its users in gravity-intensive ADLs, such as sitting transfers.\"],\n",
    "[570,0,0,\"Artificial muscles hold promise for safe and powerful actuation for myriad common machines and robots. However, the design, fabrication, and implementation of artificial muscles are often limited by their material costs, operating principle, scalability, and single-degree-of-freedom contractile actuation motions. Here we propose an architecture for fluid-driven origami-inspired artificial muscles. This concept requires only a compressible skeleton, a flexible skin, and a fluid medium. A mechanical model is developed to explain the interaction of the three components. A fabrication method is introduced to rapidly manufacture low-cost artificial muscles using various materials and at multiple scales. The artificial muscles can be programed to achieve multiaxial motions including contraction, bending, and torsion. These motions can be aggregated into systems with multiple degrees of freedom, which are able to produce controllable motions at different rates. Our artificial muscles can be driven by fluids at negative pressures (relative to ambient). This feature makes actuation safer than most other fluidic artificial muscles that operate with positive pressures. Experiments reveal that these muscles can contract over 90% of their initial lengths, generate stresses of approximately 600 kPa, and produce peak power densities over 2 kW/kg-all equal to, or in excess of, natural muscle. This architecture for artificial muscles opens the door to rapid design and low-cost fabrication of actuation systems for numerous applications at multiple scales, ranging from miniature medical devices to wearable robotic exoskeletons to large deployable structures for space exploration.\"],\n",
    "[571,0,0,\"Real-world environments are complex, unstructured, and often fragile. Soft robotics offers a solution for robots to safely interact with the environment and human coworkers, but suffers from a host of challenges in sensing and control of continuously deformable bodies. To overcome these challenges, this article considers a modular soft robotic architecture that offers proprioceptive sensing of pressure-operated bending actuation modules. We present integrated custom magnetic curvature sensors embedded in the neutral axis of bidirectional bending actuators. We describe our recent advances in the design and fabrication of these modules to improve the reliability of proprioceptive curvature feedback over our prior work. In particular, we study the effect of dimensional parameters on improving the linearity of curvature measurements. In addition, we present a sliding-mode controller formulation that drives the binary solenoid valve states directly, giving the control system the ability to hold the actuator steady without continuous pressurization and depressurization. In comparison to other methods, this control approach does not rely on pulse width modulation and hence offers superior dynamic performance (i.e., faster response rates). Our experimental results indicate that the proposed soft robotic modules offer a large range of bending angles with monotonic and more linear embedded curvature measurements, and that the direct sliding-mode control system exhibits improved bandwidth and a notable reduction in binary valve actuation operations compared to our earlier iterative sliding-mode controller.\"],\n",
    "[572,0,0,\"Small, compact and embedded sensors are a pervasive technology in everyday life for a wide number of applications (e.g., wearable devices, domotics, e-health systems, etc.). In this context, wireless transmission plays a key role, and among available solutions, Bluetooth Low Energy (BLE) is gaining more and more popularity. BLE merges together good performance, low-energy consumption and widespread diffusion. The aim of this work is to review the main methodologies adopted to investigate BLE performance. The first part of this review is an in-depth description of the protocol, highlighting the main characteristics and implementation details. The second part reviews the state of the art on BLE characteristics and performance. In particular, we analyze throughput, maximum number of connectable sensors, power consumption, latency and maximum reachable range, with the aim to identify what are the current limits of BLE technology. The main results can be resumed as follows: throughput may theoretically reach the limit of ~230 kbps, but actual applications analyzed in this review show throughputs limited to ~100 kbps; the maximum reachable range is strictly dependent on the radio power, and it goes up to a few tens of meters; the maximum number of nodes in the network depends on connection parameters, on the network architecture and specific device characteristics, but it is usually lower than 10; power consumption and latency are largely modeled and analyzed and are strictly dependent on a huge number of parameters. Most of these characteristics are based on analytical models, but there is a need for rigorous experimental evaluations to understand the actual limits.\"],\n",
    "[573,0,0,\"Soft robotic actuators offer many advantages over their rigid counterparts, but they often are unable to apply highly localized point loads. In contrast, many invertebrates have not only evolved extremely strong 'hybrid appendages' that are composed of rigid ends that can grasp, puncture, and anchor into solid substrates, but they also are compliant and resilient, owing to the functionally graded architecture that integrates rigid termini with their flexible and highly extensible soft musculatures. Inspired by the design principles of these natural hybrid appendages, we demonstrate a synthetic hybrid end effector for soft-bodied robots that exhibits excellent piercing abilities. Through the incorporation of functionally graded interfaces, this design strategy minimizes stress concentrations at the junctions adjoining the fully rigid and soft components and optimizes the bending stiffness to effectively penetrate objects without interfacial failure under shear and compressive loading regimes. In this composite architecture, the radially aligned tooth-like elements apply balanced loads to maximize puncturing ability, resulting in the coordinated fracture of an object of interest.\"],\n",
    "[574,0,0,\"To perform untethered operations, soft robots require mesoscale power units (10-1000 W) with high energy densities. In this perspective, air-breathing combustion offers an interesting alternative to battery-powered systems, provided sufficient overall energy conversion efficiency can be reached. Implementing efficient air-breathing combustion in mesoscale soft robots is notoriously difficult, however, as it requires optimization of very small combustion actuators and simultaneous minimization of fluidic (e.g., hydraulic) losses, which are both inversely impacted by actuations speeds. To overcome such challenges, this article proposes and evaluates the potential of hydrogen-powered, hydraulic free-piston pump architecture. Experimental data, taken from two combustion-driven prototypes, reveal (1) the fundamental role of using hydrogen as the source of fuel to reduce heat losses, (2) the significant impact of compression ratio, equivalence ratio, and surface-to-volume ratio on energy conversion efficiency, and (3) the importance of load matching between combustion and fluidic transmission. In this work, a small-bore combustion actuator demonstrated a 20% efficiency and a net mean output power of 26 W, while a big-bore combustion actuator reached a substantially higher efficiency of 35% and a net mean output power of 197 W. Using the small-bore combustion actuator, the hydrogen-powered, hydraulic free-piston pump provided a 4.6% overall efficiency for a 2.34 W net mean output power, thus underlying the potential of the approach for mesoscale soft robotic applications.\"],\n",
    "[575,0,0,\"Generation of autonomous behavior for robots is a general unsolved problem. Users perceive robots as repetitive tools that do not respond to dynamic situations. This research deals with the generation of natural behaviors in assistive service robots for dynamic domestic environments, particularly, a motivational-oriented cognitive architecture to generate more natural behaviors in autonomous robots. The proposed architecture, called HiMoP, is based on three elements: a Hierarchy of needs to define robot drives; a set of Motivational variables connected to robot needs; and a Pool of finite-state machines to run robot behaviors. The first element is inspired in Alderfer's hierarchy of needs, which specifies the variables defined in the motivational component. The pool of finite-state machine implements the available robot actions, and those actions are dynamically selected taking into account the motivational variables and the external stimuli. Thus, the robot is able to exhibit different behaviors even under similar conditions. A customized version of the 'Speech Recognition and Audio Detection Test,' proposed by the RoboCup Federation, has been used to illustrate how the architecture works and how it dynamically adapts and activates robots behaviors taking into account internal variables and external stimuli.\"],\n",
    "[576,0,0,\"The Wyss Institute for Biologically Inspired Engineering at Harvard University was formed based on the recognition that breakthrough discoveries cannot change the world if they never leave the laboratory. The Institute's mission is to discover the biological principles that Nature uses to build living things, and to harness these insights to create biologically inspired engineering innovations to advance human health and create a more sustainable world. Since its launch in 2009, the Institute has developed a new model for innovation, collaboration, and technology translation within academia, breaking 'silos' to enable collaborations that cross institutional and disciplinary barriers. Institute faculty and staff engage in high-risk research that leads to transformative breakthroughs. The biological principles uncovered are harnessed to develop new engineering solutions for medicine and healthcare, as well as nonmedical areas, such as energy, architecture, robotics, and manufacturing. These technologies are translated into commercial products and therapies through collaborations with clinical investigators, corporate alliances, and the formation of new start-ups that are driven by a unique internal business development team including entrepreneurs-in-residence with domain-specific expertise. Here, we describe this novel organizational model that the Institute has developed to change the paradigm of how fundamental discovery, medical technology innovation, and commercial translation are carried out at the academic-industrial interface.\"],\n",
    "[577,0,0,\"For the mimicry of human visual memory, a prominent challenge is how to detect and store the image information by electronic devices, which demands a multifunctional integration to sense light like eyes and to memorize image information like the brain by transforming optical signals to electrical signals that can be recognized by electronic devices. Although current image sensors can perceive simple images in real time, the image information fades away when the external image stimuli are removed. The deficiency between the state-of-the-art image sensors and visual memory system inspires the logical integration of image sensors and memory devices to realize the sensing and memory process toward light information for the bionic design of human visual memory. Hence, a facile architecture is designed to construct artificial flexible visual memory system by employing an UV-motivated memristor. The visual memory arrays can realize the detection and memory process of UV light distribution with a patterned image for a long-term retention and the stored image information can be reset by a negative voltage sweep and reprogrammed to the same or an other image distribution, which proves the effective reusability. These results provide new opportunities for the mimicry of human visual memory and enable the flexible visual memory device to be applied in future wearable electronics, electronic eyes, multifunctional robotics, and auxiliary equipment for visual handicapped.\"],\n",
    "[578,0,0,\"PURPOSE: This article aims to clarify the current state-of-the-art of robotic/mechanical devices for post-stroke thumb rehabilitation as well as the anatomical characteristics and motions of the thumb that are crucial for the development of any device that aims to support its motion. METHODS: A systematic literature search was conducted to identify robotic/mechanical devices for post-stroke thumb rehabilitation. Specific electronic databases and well-defined search terms and inclusion/exclusion criteria were used for such purpose. A reasoning model was devised to support the structured abstraction of relevant data from the literature of interest. RESULTS: Following the main search and after removing duplicated and other non-relevant studies, 68 articles (corresponding to 32 devices) were left for further examination. These articles were analyzed to extract data relative to (i) the motions assisted/permitted - either actively or passively - by the device per anatomical joint of the thumb and (ii) mechanical-related aspects (i.e., architecture, connections to thumb, other fingers supported, adjustability to different hand sizes, actuators - type, quantity, location, power transmission and motion trajectory). CONCLUSIONS: Most articles describe preliminary design and testing of prototypes, rather than the thorough evaluation of commercially ready devices. Defining appropriate kinematic models of the thumb upon which to design such devices still remains a challenging and unresolved task. Further research is needed before these devices can actually be implemented in clinical environments to serve their intended purpose of complementing the labour of therapists by facilitating intensive treatment with precise and repeatable exercises. Implications for Rehabilitation Post-stroke functional disability of the hand, and particularly of the thumb, significantly affects the capability to perform activities of daily living, threatening the independence and quality of life of the stroke survivors. The latest studies show that a high-dose intensive therapy (in terms of frequency, duration and intensity/effort) is the key to effectively modify neural organization and recover the motor skills that were lost after a stroke. Conventional therapy based on manual interaction with physical therapists makes the procedure labour intensive and increases the costs. Robotic/mechanical devices hold promise for complementing conventional post-stroke therapy. Specifically, these devices can provide reliable and accurate therapy for long periods of time without the associated fatigue. Also, they can be used as a means to assess patients? performance and progress in an objective and consistent manner. The full potential of robot-assisted therapy is still to be unveiled. Further exploration will surely lead to devices that can be well accepted equally by therapists and patients and that can be useful both in clinical and home-based rehabilitation practice such that motor recovery of the hand becomes a common outcome in stroke survivors. This overview provides the reader, possibly a designer of such a device, with a complete overview of the state-of-the-art of robotic/mechanical devices consisting of or including features for the rehabilitation of the thumb. Also, we clarify the anatomical characteristics and motions of the thumb that are crucial for the development of any device that aims to support its motion. Hopefully, this?combined with the outlined opportunities for further research?leads to the improvement of current devices and the development of new technology and knowledge in the field.\"],\n",
    "[579,0,0,\"A material architecture and laser-based microfabrication technique is introduced to produce electrically conductive films (sheet resistance = 2.95 Omega sq(-1) ; resistivity = 1.77 x 10(-6) Omega m) that are soft, elastic (strain limit >100%), and optically transparent. The films are composed of a grid-like array of visually imperceptible liquid-metal (LM) lines on a clear elastomer. Unlike previous efforts in transparent LM circuitry, the current approach enables fully imperceptible electronics that have not only high optical transmittance (>85% at 550 nm) but are also invisible under typical lighting conditions and reading distances. This unique combination of properties is enabled with a laser writing technique that results in LM grid patterns with a line width and pitch as small as 4.5 and 100 microm, respectively-yielding grid-like wiring that has adequate conductivity for digital functionality but is also well below the threshold for visual perception. The electrical, mechanical, electromechanical, and optomechanical properties of the films are characterized and it is found that high conductivity and transparency are preserved at tensile strains of approximately 100%. To demonstrate their effectiveness for emerging applications in transparent displays and sensing electronics, the material architecture is incorporated into a couple of illustrative use cases related to chemical hazard warning.\"],\n",
    "[580,0,0,\"From the start, Kurt Godel observed that computer and brain paradigms were considered on a par by researchers and that researchers had misunderstood his theorems. He hailed with displeasure that the brain transcends computers. In this brief article, we point out that Artificial Intelligence (AI) comprises multitudes of human-made methodologies, systems, and languages, and implemented with computer technology. These advances enhance development in the electron and quantum realms. In the biological realm, animal neurons function, also utilizing electron flow, and are products of evolution. Mirror neurons are an important paradigm in neuroscience research. Moreover, the paradigm shift proposed here - 'hall of mirror neurons' - is a potentially further productive research tactic. These concepts further expand AI and brain research.\"],\n",
    "[581,0,0,\"SpiNNaker is a digital neuromorphic architecture, designed specifically for the low power simulation of large-scale spiking neural networks at speeds close to biological real-time. Unlike other neuromorphic systems, SpiNNaker allows users to develop their own neuron and synapse models as well as specify arbitrary connectivity. As a result SpiNNaker has proved to be a powerful tool for studying different neuron models as well as synaptic plasticity-believed to be one of the main mechanisms behind learning and memory in the brain. A number of Spike-Timing-Dependent-Plasticity(STDP) rules have already been implemented on SpiNNaker and have been shown to be capable of solving various learning tasks in real-time. However, while STDP is an important biological theory of learning, it is a form of Hebbian or unsupervised learning and therefore does not explain behaviors that depend on feedback from the environment. Instead, learning rules based on neuromodulated STDP (three-factor learning rules) have been shown to be capable of solving reinforcement learning tasks in a biologically plausible manner. In this paper we demonstrate for the first time how a model of three-factor STDP, with the third-factor representing spikes from dopaminergic neurons, can be implemented on the SpiNNaker neuromorphic system. Using this learning rule we first show how reward and punishment signals can be delivered to a single synapse before going on to demonstrate it in a larger network which solves the credit assignment problem in a Pavlovian conditioning experiment. Because of its extra complexity, we find that our three-factor learning rule requires approximately 2x as much processing time as the existing SpiNNaker STDP learning rules. However, we show that it is still possible to run our Pavlovian conditioning model with up to 1 x 10(4) neurons in real-time, opening up new research opportunities for modeling behavioral learning on SpiNNaker.\"],\n",
    "[582,0,0,\"Proprioception plays a fundamental role in maintaining posture and executing movement, and the quantitative evaluation of proprioceptive deficits in poststroke patients is important. But currently it is not widely performed due to the complexity of the evaluation tools required for a reliable assessment. The aims of this pilot study were to (a) develop a system architecture for upper limb evaluation and training of proximal and distal sense of position in the horizontal plane and (b) test the system in healthy and pathological subjects. Two robotic devices for evaluation and training of, respectively, wrist flexion/extension and shoulder-elbow manipulation were employed. The system we developed was applied in a group of 12 healthy subjects and 10 patients after stroke. It was able to quantitatively evaluate upper limb sense of position in the horizontal plane thanks to a set of quantitative parameters assessing position estimation errors, variability, and gain. In addition, it was able to distinguish healthy from pathological conditions. The system could thus be a reliable method to detect changes in the sense of position of patients with sensory deficits after stroke and could enable the implementation of novel training approaches for the recovery of normal proprioception.\"],\n",
    "[583,0,0,\"In this paper, a novel approach for recognition of walking activities and gait events with wearable sensors is presented. This approach, called adaptive Bayesian inference system (BasIS), uses a probabilistic formulation with a sequential analysis method, for recognition of walking activities performed by participants. Recognition of gait events, needed to identify the state of the human body during the walking activity, is also provided by the proposed method. In addition, the BasIS system includes an adaptive action-perception method for the prediction of gait events. The adaptive approach uses the knowledge gained from decisions made over time by the inference system. The action-perception method allows the BasIS system to autonomously adapt its performance, based on the evaluation of its own predictions and decisions made over time. The proposed approach is implemented in a layered architecture and validated with the recognition of three walking activities:level-ground, ramp ascent and ramp descent. The validation process employs real data from three inertial measurements units attached to the thigh, shanks and foot of participants while performing walking activities. The experiments show that mean decision times of 240 ms and 40 ms are needed to achieve mean accuracies of 99.87% and 99.82% for recognition of walking activities and gait events, respectively. The validation experiments also show that the performance, in accuracy and speed, is not significantly affected when noise is added to sensor measurements. These results show that the proposed adaptive recognition system is accurate, fast and robust to sensor noise, but also capable to adapt its own performance over time. Overall, the adaptive BasIS system demonstrates to be a robust and suitable computational approach for the intelligent recognition of activities of daily living using wearable sensors.\"],\n",
    "[584,0,0,\"This article proposes a novel dexterous endoscopic parallel manipulator for minimally invasive surgery. The proposed manipulator has 3 degrees of freedom (3-DOF), which consist of two rotational DOFs and one translational DOF (2R1T DOFs). The manipulator consists of 3 limbs exhibiting identical kinematic structure. Each limb contains an active prismatic joint followed by 2 consecutive passive universal joints. The proposed manipulator has a unique arrangement of its joints' axes. This unique arrangement permits large bending angles, +/-90 degrees in any direction, and a workspace almost free from interior singularities. These advantages allow the proposed manipulator to outperforms existing surgical manipulators. However, this unique arrangement makes the analysis of the robot extremely difficult. Therefore, a geometrical/analytical approach is used to facilitate its singularity analysis. Construction of the virtual prototype is accomplished using ADAMS software to validate the proposed manipulator and its bending capability. A closed-form solution for inverse kinematics is obtained analytically. Also, the forward kinematics solution is obtained numerically. Moreover, evaluation of the workspace is achieved using motion/force transmissibility indices. A practical experiment has been performed using a scaling technique and PID controller. The experimental results show the feasibility of the teleoperated surgical system using the proposed parallel manipulator as the slave.\"],\n",
    "[585,0,0,\"A fully integrated sensor interface for a wide operational temperature range is presented. It translates the sensor signal into a pulse width modulated (PWM) signal that is then converted into a 12-bit digital output. The sensor interface is based on a pair of injection locked oscillators used to implement a differential time-domain architecture with low sensitivity to temperature variations. A prototype has been fabricated using a 180 nm partially depleted silicon-on-insulator (SOI) technology. Experimental results demonstrate a thermal stability as low as 65 ppm/ degrees C over a large temperature range from -20 degrees C up to 220 degrees C.\"],\n",
    "[586,0,0,\"Mosquito and tick feeding activity represent a key threat for humans, livestock, pets and wildlife worldwide. Rearing these vectors in laboratory conditions is extremely important to investigate basic facets of their biology, vector competence, new control strategies, as well as mechanisms of pesticide resistance. However, the use of animals or humans to provide blood for hematophagous arthropod feeding poses a strict limit to these researches, due to the accidental transmission of diseases, ethical problems concerning animal welfare, as well as expensive and time-consuming animal rearing procedures. The use of devices to artificially feed arthropod vectors can importantly leverage progresses in parasitology and entomology. The aim of this review is to summarize current knowledge about artificial feeding of mosquitoes and ticks, focusing on key concepts and case studies about the design and fabrication of blood feeding devices. From a technical standpoint, the literature analyzed here showed little standardization of materials used for fabricating membrane interfaces, as well as in the strategy used to heat the 'biomimetic host'. In addition, a lack of uniform methods to design an architecture merging complex and realistic cues with an easy-to-assemble approach have been found. Some commercial products are available, but they are quite expensive, thus hard to reach for many laboratories, especially in developing countries. An important challenge for future research is represented by the introduction of automation and bioinspired engineered solutions in these devices, improving the effectiveness of blood-feeding systems by increasing their host-mimicking features. Automation can reduce labor costs and provide interesting solutions - in line with the 3R principle 'reduce, replace and refine' - aimed to minimize the employ of experimental animals in research.\"],\n",
    "[587,0,0,\"Soft and tough materials are critical for engineering applications in medical devices, stretchable and wearable electronics, and soft robotics. Toughness in synthetic materials is mostly accomplished by increasing energy dissipation near the crack tip with various energy dissipation techniques. However, bio-materials exhibit extreme toughness by combining multi-scale energy dissipation with the ability to deflect and blunt an advancing crack tip. Here, we demonstrate a synthetic materials architecture that also exhibits multi-modal toughening, whereby embedding a suspension of micron sized and highly deformable liquid metal (LM) droplets inside a soft elastomer, the fracture energy dramatically increases by up to 50x (from 250 +/- 50 J m(-2) to 11,900 +/- 2600 J m(-2) ) over an unfilled polymer. For some LM-embedded elastomer (LMEE) compositions, the toughness is measured to be 33,500 +/- 4300 J m(-2) , which far exceeds the highest value previously reported for a soft elastic material. This extreme toughening is achieved by (i) increasing energy dissipation, (ii) adaptive crack movement, and (iii) effective elimination of the crack tip. Such properties arise from the deformability of the LM inclusions during loading, providing a new mechanism to not only prevent crack initiation, but also resist the propagation of existing tears for ultra tough, soft materials.\"],\n",
    "[588,0,0,\"Large-area stretchable electronics are critical for progress in wearable computing, soft robotics and inflatable structures. Recent efforts have focused on engineering electronics from soft materials-elastomers, polyelectrolyte gels and liquid metal. While these materials enable elastic compliance and deformability, they are vulnerable to tearing, puncture and other mechanical damage modes that cause electrical failure. Here, we introduce a material architecture for soft and highly deformable circuit interconnects that are electromechanically stable under typical loading conditions, while exhibiting uncompromising resilience to mechanical damage. The material is composed of liquid metal droplets suspended in a soft elastomer; when damaged, the droplets rupture to form new connections with neighbours and re-route electrical signals without interruption. Since self-healing occurs spontaneously, these materials do not require manual repair or external heat. We demonstrate this unprecedented electronic robustness in a self-repairing digital counter and self-healing soft robotic quadruped that continue to function after significant damage.\"],\n",
    "[589,0,0,\"BACKGROUND: Due to the problem of aging societies, there is a need for smart buildings to monitor and support people with various disabilities, including rheumatoid arthritis. OBJECTIVE: The aim of this paper is to elaborate on novel techniques for wireless motion capture systems for the monitoring and rehabilitation of disabled people for application in smart buildings. METHODS: The proposed techniques are based on cross-verification of distance measurements between markers and transponders in an environment with highly variable parameters. To their verification, algorithms that enable comprehensive investigation of a system with different numbers of transponders and varying ambient parameters (temperature and noise) were developed. In the estimation of the real positions of markers, various linear and nonlinear filters were used. Several thousand tests were carried out for various system parameters and different marker locations. RESULTS: The results show that localization error may be reduced by as much as 90%. It was observed that repetition of measurements reduces localization error by as much as one order of magnitude. CONCLUSIONS: The proposed system, based on wireless techniques, offers a high commercial potential. However, it requires extensive cooperation between teams, including hardware and software design, system modelling, and architectural design.\"],\n",
    "[590,0,0,\"Summary: Second use of clinical data commonly involves annotating biomedical text with terminologies and ontologies. The National Center for Biomedical Ontology Annotator is a frequently used annotation service, originally designed for biomedical data, but not very suitable for clinical text annotation. In order to add new functionalities to the NCBO Annotator without hosting or modifying the original Web service, we have designed a proxy architecture that enables seamless extensions by pre-processing of the input text and parameters, and post processing of the annotations. We have then implemented enhanced functionalities for annotating and indexing free text such as: scoring, detection of context (negation, experiencer, temporality), new output formats and coarse-grained concept recognition (with UMLS Semantic Groups). In this paper, we present the NCBO Annotator+, a Web service which incorporates these new functionalities as well as a small set of evaluation results for concept recognition and clinical context detection on two standard evaluation tasks (Clef eHealth 2017, SemEval 2014). Availability and implementation: The Annotator+ has been successfully integrated into the SIFR BioPortal platform-an implementation of NCBO BioPortal for French biomedical terminologies and ontologies-to annotate English text. A Web user interface is available for testing and ontology selection (http://bioportal.lirmm.fr/ncbo_annotatorplus); however the Annotator+ is meant to be used through the Web service application programming interface (http://services.bioportal.lirmm.fr/ncbo_annotatorplus). The code is openly available, and we also provide a Docker packaging to enable easy local deployment to process sensitive (e.g. clinical) data in-house (https://github.com/sifrproject). Contact: andon.tchechmedjiev@lirmm.fr. Supplementary information: Supplementary data are available at Bioinformatics online.\"],\n",
    "[591,0,0,\"Studying the effects of small molecules on root system development in the context of a large-scale chemical genetic screen has previously been a technical challenge. The recent development of novel seedling growth devices ('Phytostrips'), used in combination with standard 96-well microtiter plates, has made it possible to perform detailed studies of changes in root morphology and root system architecture following the application of a library of chemical compounds. Phytostrips were originally designed to allow automated robotic capture of images of roots and shoots of the model species Arabidopsis thaliana, but can also be used for manual screens that are more laborious but do not require the investment in expensive robotics.Here we describe a protocol for the use of Phytostrips to perform chemical genetic screens that rely on clearly observable changes in root morphology or root system architecture. As an example, we describe the use of polyethylene glycol to impose an abiotic stress related to reduced water potential and the application of a chemical screen for small molecules that are able to rescue Arabidopsis root development from the disruptive effect of the polyethylene glycol treatment. The protocol we describe provides a template for the application of a multiplicity of other screens for compounds that can antagonize the effects of a range of abiotic stresses on root development.\"],\n",
    "[592,0,0,\"Targeted prostate biopsy, incorporating multi-parametric magnetic resonance imaging (mp-MRI) and its registration with ultrasound, is currently the state-of-the-art in prostate cancer diagnosis. The registration process in most targeted biopsy systems today relies heavily on accurate segmentation of ultrasound images. Automatic or semi-automatic segmentation is typically performed offline prior to the start of the biopsy procedure. In this paper, we present a deep neural network based real-time prostate segmentation technique during the biopsy procedure, hence paving the way for dynamic registration of mp-MRI and ultrasound data. In addition to using convolutional networks for extracting spatial features, the proposed approach employs recurrent networks to exploit the temporal information among a series of ultrasound images. One of the key contributions in the architecture is to use residual convolution in the recurrent networks to improve optimization. We also exploit recurrent connections within and across different layers of the deep networks to maximize the utilization of the temporal information. Furthermore, we perform dense and sparse sampling of the input ultrasound sequence to make the network robust to ultrasound artifacts. Our architecture is trained on 2,238 labeled transrectal ultrasound images, with an additional 637 and 1,017 unseen images used for validation and testing, respectively. We obtain a mean Dice similarity coefficient of 93%, a mean surface distance error of 1.10 mm and a mean Hausdorff distance error of 3.0 mm. A comparison of the reported results with those of a state-of-the-art technique indicates statistically significant improvement achieved by the proposed approach.\"],\n",
    "[593,0,0,\"Exoskeletons arise as the common ground between robotics and biomechanics, where rehabilitation is the main field in which these two disciplines find cohesion. One of the most relevant challenges in upper limb exoskeleton design relies in the high complexity of the human shoulder, where current devices implement elaborate systems only to emulate the drifting center of rotation of the shoulder joint. This paper proposes the use of 3D scanning vision technologies to ease the design process and its implementation on a variety of subjects, while a motion tracking system based on vision technologies is applied to assess the exoskeleton reachable workspace compared with an asymptomatic subject. Furthermore, the anatomic fitting index is proposed, which compares the anatomic workspace of the user with the exoskeleton workspace and provides insight into its features. This work proposes an exoskeleton architecture that considers the clavicle motion over the coronal plane whose workspace is determined by substituting the direct kinematics model with the dimensional parameters of the user. Simulations and numerical examples are used to validate the analytical results and to conciliate the experimental results provided by the vision tracking system.\"],\n",
    "[594,0,0,\"We present here a learning system using the iCub humanoid robot and the SpiNNaker neuromorphic chip to solve the real-world task of object-specific attention. Integrating spiking neural networks with robots introduces considerable complexity for questionable benefit if the objective is simply task performance. But, we suggest, in a cognitive robotics context, where the goal is understanding how to compute, such an approach may yield useful insights to neural architecture as well as learned behavior, especially if dedicated neural hardware is available. Recent advances in cognitive robotics and neuromorphic processing now make such systems possible. Using a scalable, structured, modular approach, we build a spiking neural network where the effects and impact of learning can be predicted and tested, and the network can be scaled or extended to new tasks automatically. We introduce several enhancements to a basic network and show how they can be used to direct performance toward behaviorally relevant goals. Results show that using a simple classical spike-timing-dependent plasticity (STDP) rule on selected connections, we can get the robot (and network) to progress from poor task-specific performance to good performance. Behaviorally relevant STDP appears to contribute strongly to positive learning: 'do this' but less to negative learning: 'don't do that.' In addition, we observe that the effect of structural enhancements tends to be cumulative. The overall system suggests that it is by being able to exploit combinations of effects, rather than any one effect or property in isolation, that spiking networks can achieve compelling, task-relevant behavior.\"],\n",
    "[595,5,0,\"To realize human-like robot intelligence, a large-scale cognitive architecture is required for robots to understand their environment through a variety of sensors with which they are equipped. In this paper, we propose a novel framework named Serket that enables the construction of a large-scale generative model and its inferences easily by connecting sub-modules to allow the robots to acquire various capabilities through interaction with their environment and others. We consider that large-scale cognitive models can be constructed by connecting smaller fundamental models hierarchically while maintaining their programmatic independence. Moreover, the connected modules are dependent on each other and their parameters must be optimized as a whole. Conventionally, the equations for parameter estimation have to be derived and implemented depending on the models. However, it has become harder to derive and implement equations of large-scale models. Thus, in this paper, we propose a parameter estimation method that communicates the minimum parameters between various modules while maintaining their programmatic independence. Therefore, Serket makes it easy to construct large-scale models and estimate their parameters via the connection of modules. Experimental results demonstrated that the model can be constructed by connecting modules, the parameters can be optimized as a whole, and they are comparable with the original models that we have proposed.\"],\n",
    "[596,0,0,\"For robots equipped with an advanced computer vision-based system, object recognition has stringent real-time requirements. When the environment becomes complicated and keeps changing, existing works (e.g., template-matching strategy and machine-learning strategy) are computationally expensive, compromising object recognition performance and even stability. In order to detect objects accurately, it is necessary to build an efficient imaging sensor architecture as the neural architecture. Inspired by the neural mechanism of primary visual cortex, this paper presents an efficient three-layer architecture and proposes an approach of constraint propagation examination to efficiently extract and process information (linear contour). Through applying this architecture in the preprocessing phase to extract lines, the running time of object detection is decreased dramatically because not only are all lines represented as very simple vectors, but also the number of lines is very limited. In terms of the second measure of improving efficiency, we apply a shape-based recognition method because it does not need any high-dimensional feature descriptor, long-term training, or time-expensive preprocessing. The final results perform well. It is proved that detection performance is good. The brain is the result of natural optimization, so we conclude that a visual cortex-inspired imaging sensor architecture can greatly improve the efficiency of information processing.\"],\n",
    "[597,0,0,\"PURPOSE: The development of common ontologies has recently been identified as one of the key challenges in the emerging field of surgical data science (SDS). However, past and existing initiatives in the domain of surgery have mainly been focussing on individual groups and failed to achieve widespread international acceptance by the research community. To address this challenge, the authors of this paper launched a European initiative-OntoSPM Collaborative Action-with the goal of establishing a framework for joint development of ontologies in the field of SDS. This manuscript summarizes the goals and the current status of the international initiative. METHODS: A workshop was organized in 2016, gathering the main European research groups having experience in developing and using ontologies in this domain. It led to the conclusion that a common ontology for surgical process models (SPM) was absolutely needed, and that the existing OntoSPM ontology could provide a good starting point toward the collaborative design and promotion of common, standard ontologies on SPM. RESULTS: The workshop led to the OntoSPM Collaborative Action-launched in mid-2016-with the objective to develop, maintain and promote the use of common ontologies of SPM relevant to the whole domain of SDS. The fundamental concept, the architecture, the management and curation of the common ontology have been established, making it ready for wider public use. CONCLUSION: The OntoSPM Collaborative Action has been in operation for 24 months, with a growing dedicated membership. Its main result is a modular ontology, undergoing constant updates and extensions, based on the experts' suggestions. It remains an open collaborative action, which always welcomes new contributors and applications.\"],\n",
    "[598,0,0,\"The next generation of robot companions or robot working partners will need to satisfy social requirements somehow similar to the famous laws of robotics envisaged by Isaac Asimov time ago (Asimov, 1942). The necessary technology has almost reached the required level, including sensors and actuators, but the cognitive organization is still in its infancy and is only partially supported by the current understanding of brain cognitive processes. The brain of symbiotic robots will certainly not be a 'positronic' replica of the human brain: probably, the greatest part of it will be a set of interacting computational processes running in the cloud. In this article, we review the challenges that must be met in the design of a set of interacting computational processes as building blocks of a cognitive architecture that may give symbiotic capabilities to collaborative robots of the next decades: (1) an animated body-schema; (2) an imitation machinery; (3) a motor intentions machinery; (4) a set of physical interaction mechanisms; and (5) a shared memory system for incremental symbiotic development. We would like to stress that our approach is totally un-hierarchical: the five building blocks of the shared cognitive architecture are fully bi-directionally connected. For example, imitation and intentional processes require the 'services' of the animated body schema which, on the other hand, can run its simulations if appropriately prompted by imitation and/or intention, with or without physical interaction. Successful experiences can leave a trace in the shared memory system and chunks of memory fragment may compete to participate to novel cooperative actions. And so on and so forth. At the heart of the system is lifelong training and learning but, different from the conventional learning paradigms in neural networks, where learning is somehow passively imposed by an external agent, in symbiotic robots there is an element of free choice of what is worth learning, driven by the interaction between the robot and the human partner. The proposed set of building blocks is certainly a rough approximation of what is needed by symbiotic robots but we believe it is a useful starting point for building a computational framework.\"],\n",
    "[599,0,0,\"Feature extraction and classification is a vital part in motor imagery-based brain-computer interface (BCI) system. Traditional deep learning (DL) methods usually perform better with more labeled training samples. Unfortunately, the labeled samples are usually scarce for electroencephalography (EEG) data, while unlabeled samples are available in large quantity and easy to collect. In addition, traditional DL algorithms are notoriously time-consuming for the training process. To address these issues, a novel method of hierarchical semi-supervised extreme learning machine (HSS-ELM) is proposed in this paper and applied for motor imagery (MI) task classification. Firstly, the deep architecture of hierarchical ELM (H-ELM) approach is employed for feature learning automatically, and then these new high-level features are classified using the semi-supervised ELM (SS-ELM) algorithm which can exploit the information from both labeled and unlabeled data. Extensive experiments were conducted on some benchmark datasets and EEG datasets to evaluate the effectiveness of the proposed method. Compared with several state-of-the-art methods, including SVM, ELM, SAE, H-ELM, and SS-ELM, our HSS-ELM method can achieve better classification accuracy, a mean kappa value of 0.7945 and 0.5701 across all subjects in the training and evaluation sessions of BCI Competition IV Dataset 2a, respectively. Finally, it comes to the conclusion that the proposed method has achieved superior performance for feature extraction and classification of EEG signals. Graphical abstract The schematic of the proposed HSS-ELM algorithm.\"],\n",
    "[600,0,0,\"Poly(lactic acid) has been extensively investigated in the biomedical field because of its good biocompatibility and biodegradability. As an important method of poly(lactic acid) synthesis, metal complex-catalyzed ring-opening polymerization (ROP) of lactide can achieve a controllable lactide polymerization through the selection of appropriate ligands and metals. In this study, a novel metal (LTi-O)2 complex was synthesized and structurally characterized. (LTi-O)2 showed a relatively high catalytic activity and controllability of Poly(D, L-lactide) (PDLLA) molecular weights (polydispersity index of 1.02-1.22) in the ROP of D,L-lactide. The kinetic equation of D,L-LA ROP catalyzed by (LTi-O)2 could be expressed as-d[M]/dt = k[M]2[(LTi-O)2]1, and the reaction activation energy was 95.67 kJ.mol-1. Physical/chemical properties and biocompatibility evaluation results showed that PDLLA obtained through the (LTi-O)2-catalyzed ROP of D,L- lactide exhibited a good degradation performance and excellent biocompatibility.\"],\n",
    "[601,0,0,\"The identification of compounds for dissecting biological functions and the development of novel drug molecules are central tasks that often require screening campaigns. However, the required architecture is cost- and time-intensive. Herein we describe the devices and technologies that comprise a Robotics-Assisted Screening Platform for Efficient Ligand Discovery (RASPELD), which we set up in an academic laboratory. RASPELD provides semi-automated high-end screening, and it can be maintained by graduate students. We demonstrate its successful application in biochemical and cellular screens for the identification and validation of bioactive chemical entities as candidate cancer-relevant inhibitors. Specifically, we examined the interaction between a transcription factor, Nrf2, and its key regulator, Keap1. We also examined drug-resistant mutants of the epidermal growth factor receptor (EGFR). Screening campaigns with more than 30 000 compounds were performed in a reasonable period of time. We identified the molecule RSL6586 as a starting point for hit optimization, which is currently ongoing.\"],\n",
    "[602,0,0,\"Orthoses for the lower limbs support patients to perform movements that they could not perform on their own. In traditional devices, generic gait models for a limited set of supported movements restrict the patients mobility and device acceptance. To overcome such limitations, we propose a modular neural control approach with user feedback for personalizable Knee-Ankle-Foot-Orthoses (KAFO). The modular controller consists of two main neural components: neural orthosis control for gait phase tracking and neural internal models for gait prediction and selection. A user interface providing online feedback allows the user to shape the control output that adjusts the knee damping parameter of a KAFO. The accuracy and robustness of the control approach were investigated in different conditions including walking on flat ground and descending stairs as well as stair climbing. We show that the controller accurately tracks and predicts the user's movements and generates corresponding gaits. Furthermore, based on the modular control architecture, the controller can be extended to support various distinguishable gaits depending on differences in sensory feedback.\"],\n",
    "[603,0,0,\"How the brain represents the external world is an unresolved issue for neuroscience, which could provide fundamental insights into brain circuitry operation and solutions for artificial intelligence and robotics. The neurons of the cuneate nucleus form the first interface for the sense of touch in the brain. They were previously shown to have a highly skewed synaptic weight distribution for tactile primary afferent inputs, suggesting that their connectivity is strongly shaped by learning. Here we first characterized the intracellular dynamics and inhibitory synaptic inputs of cuneate neurons in vivo and modeled their integration of tactile sensory inputs. We then replaced the tactile inputs with input from a sensorized bionic fingertip and modeled the learning-induced representations that emerged from varied sensory experiences. The model reproduced both the intrinsic membrane dynamics and the synaptic weight distributions observed in cuneate neurons in vivo. In terms of higher level model properties, individual cuneate neurons learnt to identify specific sets of correlated sensors, which at the population level resulted in a decomposition of the sensor space into its recurring high-dimensional components. Such vector components could be applied to identify both past and novel sensory experiences and likely correspond to the fundamental haptic input features these neurons encode in vivo. In addition, we show that the cuneate learning architecture is robust to a wide range of intrinsic parameter settings due to the neuronal intrinsic dynamics. Therefore, the architecture is a potentially generic solution for forming versatile representations of the external world in different sensor systems.\"],\n",
    "[604,0,0,\"INTRODUCTION:: This article focuses on the integration of omics data in electronic health records and on interoperability aspects relating to big data analysis for precision medicine. METHODS:: Omics data integration methods for electronic health record and for systems interoperability are considered, with special reference to the high number of specific software tools used to manage different aspects of patient treatment. This is an important barrier against the use of this integrated approach in daily clinical routine. RESULTS:: The correct use of all three levels of interoperability (technical, semantic, and process interoperability) plays a key role in order to achieve an easy access to a significant amount of data, all with correct contextualization, which is the only way to obtain a real value from data for precision medicine. CONCLUSIONS:: The proposed architecture could improve the potentialities of data routinely collected in many health information systems to form a real patient center information environment.\"],\n",
    "[605,0,0,\"In recent years, deep convolutional neural networks (CNNs) have shown record-shattering performance in a variety of computer vision problems, such as visual object recognition, detection and segmentation. These methods have also been utilised in medical image analysis domain for lesion segmentation, anatomical segmentation and classification. We present an extensive literature review of CNN techniques applied in brain magnetic resonance imaging (MRI) analysis, focusing on the architectures, pre-processing, data-preparation and post-processing strategies available in these works. The aim of this study is three-fold. Our primary goal is to report how different CNN architectures have evolved, discuss state-of-the-art strategies, condense their results obtained using public datasets and examine their pros and cons. Second, this paper is intended to be a detailed reference of the research activity in deep CNN for brain MRI analysis. Finally, we present a perspective on the future of CNNs in which we hint some of the research directions in subsequent years.\"],\n",
    "[606,0,0,\"Affective Computing has emerged as an important field of study that aims to develop systems that can automatically recognize emotions. Up to the present, elicitation has been carried out with non-immersive stimuli. This study, on the other hand, aims to develop an emotion recognition system for affective states evoked through Immersive Virtual Environments. Four alternative virtual rooms were designed to elicit four possible arousal-valence combinations, as described in each quadrant of the Circumplex Model of Affects. An experiment involving the recording of the electroencephalography (EEG) and electrocardiography (ECG) of sixty participants was carried out. A set of features was extracted from these signals using various state-of-the-art metrics that quantify brain and cardiovascular linear and nonlinear dynamics, which were input into a Support Vector Machine classifier to predict the subject's arousal and valence perception. The model's accuracy was 75.00% along the arousal dimension and 71.21% along the valence dimension. Our findings validate the use of Immersive Virtual Environments to elicit and automatically recognize different emotional states from neural and cardiac dynamics; this development could have novel applications in fields as diverse as Architecture, Health, Education and Videogames.\"],\n",
    "[607,0,0,\"Aimed at building autonomous service robots, reasoning, perception, and action should be properly integrated. In this paper, the depth cue has been analysed as an early stage given its importance for robotic tasks. So, from neuroscience findings, a hierarchical four-level dorsal architecture has been designed and implemented. Mainly, from a stereo image pair, a set of complex Gabor filters is applied for estimating an egocentric quantitative disparity map. This map leads to a quantitative depth scene representation that provides the raw input for a qualitative approach. So, the reasoning method infers the data required to make the right decision at any time. As it will be shown, the experimental results highlight the robust performance of the biologically inspired approach presented in this paper.\"],\n",
    "[608,0,0,\"In this paper, a novel Pixel-Voxel network is proposed for dense 3D semantic mapping, which can perform dense 3D mapping while simultaneously recognizing and labelling the semantic category each point in the 3D map. In our approach, we fully leverage the advantages of different modalities. That is, the PixelNet can learn the high-level contextual information from 2D RGB images, and the VoxelNet can learn 3D geometrical shapes from the 3D point cloud. Unlike the existing architecture that fuses score maps from different modalities with equal weights, we propose a softmax weighted fusion stack that adaptively learns the varying contributions of PixelNet and VoxelNet and fuses the score maps according to their respective confidence levels. Our approach achieved competitive results on both the SUN RGB-D and NYU V2 benchmarks, while the runtime of the proposed system is boosted to around 13 Hz, enabling near-real-time performance using an i7 eight-cores PC with a single Titan X GPU.\"],\n",
    "[609,0,0,\"Developing untethered millirobots that can adapt to harsh environments with high locomotion efficiency is of interest for emerging applications in various industrial and biomedical settings. Despite recent success in exploiting soft materials to impart sophisticated functions which are not available in conventional rigid robotics, it remains challenging to achieve superior performances in both wet and dry conditions. Inspired by the flexible, soft, and elastic leg/foot structures of many living organisms, here we report an untethered soft millirobot decorated with multiple tapered soft feet architecture. Such robot design yields superior adaptivity to various harsh environments with ultrafast locomotion speed (>40 limb length/s), ultra-strong carrying capacity (>100 own weight), and excellent obstacle-crossing ability (stand up 90 degrees and across obstacle >10 body height). Our work represents an important advance in the emerging area of bio-inspired robotics and will find a wide spectrum of applications.\"],\n",
    "[610,0,0,\"Multi-step pathways-which consist of a sequence of reconfigurations of a structure-are central to the functionality of various natural and artificial systems. Such pathways execute autonomously in self-guided processes such as protein folding(1) and self-assembly(2-5), but have previously required external control to execute in macroscale mechanical systems, provided by, for example, actuators in robotics(6-9) or manual folding in origami(8,10-12). Here we demonstrate shape-changing, macroscale mechanical metamaterials that undergo self-guided, multi-step reconfiguration in response to global uniform compression. We avoid the need for external control by using metamaterials that are made purely of passive components. The design of the metamaterials combines nonlinear mechanical elements with a multimodal architecture that enables a sequence of topological reconfigurations caused by the formation of internal self-contacts between the elements of the metamaterial. We realize the metamaterials by using computer-controlled water-jet cutting of flexible materials, and show that the multi-step pathway and final configuration can be controlled by rational design of the nonlinear mechanical elements. We also demonstrate that the self-contacts suppress errors in the pathway. Finally, we create hierarchical architectures to extend the number of distinct reconfiguration steps. Our work establishes general principles for designing mechanical pathways, opening up new avenues for self-folding media(11,12), pluripotent materials(9,13) and pliable devices(14) in areas such as stretchable electronics and soft robotics(15).\"],\n",
    "[611,0,0,\"BACKGROUND: Endoscopy has replaced open surgery, especially in spinal surgery. Among them, image-guided epiduroscopy allows pain generators to be identified, including epidural adhesion, fibrotic tissues, root compression, and spinal stenosis. However, the heavy lead apron worn by pain physicians to avoid exposure to radiation can induce occupational hazards, such as orthopedic complications and radiation-induced cancer. Hence, we developed a robotic system to address these problems. OBJECTIVE: The aim of the study was to evaluate the feasibility of a robot-controlled epiduroscopic system. STUDY DESIGN: In vivo animal experiment. SETTING: University in Republic of Korea. METHODS: The robot-controlled epiduroscopic system was developed using the open architecture robot system (The Raven Surgical Robotic System, CITRIS, Berkley, CA, USA). The robotic system consists of a lab-made epiduroscope, steering section, robotic arm, and manipulator. For the in vivo study, 2 Yorkshire pigs were used to simulate an epiduroscopic procedure with the robotic system. RESULTS: The insertion and steering of the catheter was performed safely, and epiduroscopic visualization was obtained without side effects. There were no device-related complications. Radiation exposure for the primary operator was 80% lower than the levels found during conventional epiduroscopic procedures. All live pigs showed normal behavior without any signs of pain. The mean time to reach the target region was less than 8 minutes. LIMITATIONS: The epiduroscopic procedure was performed on pigs and not on humans. The dimensions of the spinal canal of pigs cannot compare to those of humans. CONCLUSIONS: We demonstrated the feasibility of the robot-assisted epiduroscopic system. KEY WORDS: Epiduroscopy, robotic system, spine, pig, animal model.\"],\n",
    "[612,0,0,\"The aim of this study was to perform a finite element and experimental comparative analysis of the mechanical characteristics of surgical drill bits used in bone and joint surgery applications with and without an irrigation channel. Internally cooled drills are very efficient in maintaining the drilling temperature below the critical level. However, a cooling channel could potentially have a negative influence on the drill structure, particularly in the flutes zone. A commercially available type of surgical drill bit without irrigation channel and a modified variant with the built-in channel were simultaneously loaded with torque, axial and bending forces with magnitudes similar to and higher than those utilized in clinical practice. When loaded under the same conditions, both types of drills showed very similar mechanical properties in the sense of the average von Mises stress in chosen sections and the deflections after plastic deformation. The highest stress was observed in the bending zone which was located at the beginning of the flutes section of the drill. All analysed drills suffered only from plastic deformation without any breakage despite the fact that they were loaded with forces higher than those expected in normal operational conditions.\"],\n",
    "[613,0,0,\"BACKGROUND: Despite a wide adoption of English in science, a significant amount of biomedical data are produced in other languages, such as French. Yet a majority of natural language processing or semantic tools as well as domain terminologies or ontologies are only available in English, and cannot be readily applied to other languages, due to fundamental linguistic differences. However, semantic resources are required to design semantic indexes and transform biomedical (text)data into knowledge for better information mining and retrieval. RESULTS: We present the SIFR Annotator ( http://bioportal.lirmm.fr/annotator ), a publicly accessible ontology-based annotation web service to process biomedical text data in French. The service, developed during the Semantic Indexing of French Biomedical Data Resources (2013-2019) project is included in the SIFR BioPortal, an open platform to host French biomedical ontologies and terminologies based on the technology developed by the US National Center for Biomedical Ontology. The portal facilitates use and fostering of ontologies by offering a set of services -search, mappings, metadata, versioning, visualization, recommendation- including for annotation purposes. We introduce the adaptations and improvements made in applying the technology to French as well as a number of language independent additional features -implemented by means of a proxy architecture- in particular annotation scoring and clinical context detection. We evaluate the performance of the SIFR Annotator on different biomedical data, using available French corpora -Quaero (titles from French MEDLINE abstracts and EMEA drug labels) and CepiDC (ICD-10 coding of death certificates)- and discuss our results with respect to the CLEF eHealth information extraction tasks. CONCLUSIONS: We show the web service performs comparably to other knowledge-based annotation approaches in recognizing entities in biomedical text and reach state-of-the-art levels in clinical context detection (negation, experiencer, temporality). Additionally, the SIFR Annotator is the first openly web accessible tool to annotate and contextualize French biomedical text with ontology concepts leveraging a dictionary currently made of 28 terminologies and ontologies and 333 K concepts. The code is openly available, and we also provide a Docker packaging for easy local deployment to process sensitive (e.g., clinical) data in-house ( https://github.com/sifrproject ).\"],\n",
    "[614,0,0,\"Following the inception of transoral robotic surgery (TORS) in 2005, the field of robotic head and neck surgery has undergone refinement and innovation. Optimizing patient outcome, preserving function, and limiting morbidity are the key drivers. The next leap forward is another generation of flexible robotic surgical systems. Several such systems are under clinical and preclinical evaluation. A new single-port (Sp) robotic surgical architecture is now available integrating three fully articulating instruments and a flexible three-dimensional high-definition camera delivered through a 25-mm cannula. Preclinical feasibility studies of the Sp in human cadaver and porcine models suggest improved application compared to existing platforms for oropharyngeal and nasopharyngeal resection. With 3-handed manipulation of tissue, traction and countertraction may be used to deliver a more precise surgical dissection of head and neck anatomy than is currently possible. The single-port design permits greater access and maneuverability for the bedside surgical assistant. An alternative currently available in clinical use includes the Flex(R) system using a robotic camera and manually controlled endoscopic instruments. The Cambridge Medical Robotics Versius system is undergoing preclinical evaluation for TORS and may offer a novel modular approach. All of these systems allow the head and neck surgeon to reach further beyond the upper aerodigestive tract with greater agility and precision, expanding the boundaries of minimal access head and neck surgery.\"],\n",
    "[615,0,0,\"Articular cartilage is a tissue of fundamental importance for the mechanics of joints, since it provides a smooth and lubricated surface for the proper transfer of loads. From a mechanical point of view, this tissue is an anisotropic poroviscoelastic material: its characteristics at the macroscopic level depend on the complex microscopic architecture. With the ability to probe the local microscopic features, dynamic nanoindentation test is a powerful tool to investigate cartilage mechanics. In this work we focus on a length scale where the time dependent behaviour is regulated by poroelasticity more than viscoelasticity and we aim to understand the effect of the anisotropic permeability on the mechanics of the superficial layer of the articular cartilage. In a previous work, a finite element model for the dynamic nanoindentation test has been presented. In this work, we improve the model by considering the presence of an anisotropic permeability tensor that depends on the collagen fibers distribution. Our sensitivity analysis highlights that the permeability decreases with increasing indentation, thus making the tissue stiffer than the case of isotropic permeability, when solicited at the same frequency. With this improved model, a revised identification of the mechanical and physical parameters for articular cartilage is provided. To this purpose the model was used to simulate experimental data from tests performed on bovine tissue, giving a better estimation of the anisotropy in the elastic properties. A relation between the identified macroscopic anisotropic permeability properties and the microscopic rearrangement of the fiber/matrix structure during indentation is also provided.\"],\n",
    "[616,0,0,\"Phase extraction from repetitive movements is one crucial part in various applications such as interactive robotics, physical rehabilitation, or gait analysis. However, pre-existing automatic phase extraction techniques are specific to a target movement due to some handcrafted-features. To make it more universal, a novel unsupervised-learning-based phase extraction technique is proposed. A neural network architecture and a cost function are designed to learn the concept of phase from records of a repetitive movement without any given phase label. The method is tested on a rat's gait cycle and a human's upper limb movement. The phases are successfully extracted at the sample level despite the variations in movement speed, trajectory, or subject's anthropometric features.\"],\n",
    "[617,0,0,\"Morphogenesis is a phenomenon by which a wide variety of functional organs are formed in biological systems. In plants, morphogenesis is primarily driven by differential growth of tissues. Much effort has been devoted to identifying the role of genetic and biomolecular pathways in regulating cell division and cell expansion and in influencing shape formation in plant organs. However, general principles dictating how differential growth controls the formation of complex 3D shapes in plant leaves and flower petals remain largely unknown. Through quantitative measurements on live plant organs and detailed finite-element simulations, we show how the morphology of a growing leaf is determined by both the maximum value and the spatial distribution of growth strain. With this understanding, we develop a broad scientific framework for a morphological phase diagram that is capable of rationalizing four configurations commonly found in plant organs: twisting, helical twisting, saddle bending, and edge waving. We demonstrate the robustness of these findings and analyses by recourse to synthetic reproduction of all four configurations using controlled polymerization of a hydrogel. Our study points to potential approaches to innovative geometrical design and actuation in such applications as building architecture, soft robotics and flexible electronics.\"],\n",
    "[618,0,0,\"Background: Atypical vascular pattern is one of the most important features by differentiating between benign and malignant pigmented skin lesions. Detection and analysis of vascular structures is a necessary initial step for skin mole assessment; it is a prerequisite step to provide an accurate outcome for the widely used 7-point checklist diagnostic algorithm. Methods: In this research we present a fully automated machine learning approach for segmenting vascular structures in dermoscopy colour images. The U-Net architecture is based on convolutional networks and designed for fast and precise segmentation of images. After preprocessing the images are randomly divided into 146516 patches of 64 x 64 pixels each. Results: On the independent validation dataset including 74 images our implemented method showed high segmentation accuracy. For the U-Net convolutional neural network, an average DSC of 0.84, sensitivity 0.85, and specificity 0.81 has been achieved. Conclusion: Vascular structures due to small size and similarity to other local structures create enormous difficulties during the segmentation and assessment process. The use of advanced segmentation methods like deep learning, especially convolutional neural networks, has the potential to improve the accuracy of advanced local structure detection.\"],\n",
    "[619,0,0,\"The in vitro reproduction of three-dimensional (3D) cellular constructs to physiologically mimic human liver is highly desired for drug screening and clinical research. However, the fabrication of a liver-mimetic 3D model using traditional bottom-up technologies is challenging owing to the complex architecture and specific functions of real liver tissue. This work proposes a versatile strategy for spatially assembling gear-like microstructures encapsulating multiple cell types, and reorganizing them into 3D lobule-like micro-architecture with physiological relevance to native liver tissue. Gear-like microstructures were fabricated by photo-crosslinking poly(ethylene glycol) diacrylate (PEGDA) hydrogel mixed with hepatocytes and fibroblasts, in a digital micromirror device (DMD)-based microfluidic channel. The microstructures were assembled through coordinated micromanipulation based on local fluid force, and spatially self-aligned through hydrophilic-hydrophobic interactions into a 3D integrated construct with lobule-like morphology and a perfusable central lumen. The resulting 3D lobule-like constructs allowed long-term co-culture of hepatocytes and fibroblasts with high cell viability. The co-cultured constructs enhanced hepatocyte proliferation and spreading, as well as liver functions including a 50% increase in albumin secretion and urea synthesis. For hepatotoxicity assessment, the 3D lobule-like construct enabled drug perfusion through its built-in lumen for simulation of drug diffusion in the liver, which could improve the response sensitivity and efficiency to hepatotoxic drug. These results demonstrated that this method provides a valuable 3D co-culture model with perfusable lobule-like architecture and physiological functions, which has potential applications in drug discovery and tissue engineering applications.\"],\n",
    "[620,0,0,\"Facial action units (AUs) may be represented spatially, temporally, and in terms of their correlation. Previous research focuses on one or another of these aspects or addresses them disjointly. We propose a hybrid network architecture that jointly models spatial and temporal representations and their correlation. In particular, we use a Convolutional Neural Network (CNN) to learn spatial representations, and a Long Short-Term Memory (LSTM) to model temporal dependencies among them. The outputs of CNNs and LSTMs are aggregated into a fusion network to produce per-frame prediction of multiple AUs. The hybrid network was compared to previous state-of-the-art approaches in two large FACS-coded video databases, GFT and BP4D, with over 400,000 AU-coded frames of spontaneous facial behavior in varied social contexts. Relative to standard multi-label CNN and feature-based state-of-the-art approaches, the hybrid system reduced person-specific biases and obtained increased accuracy for AU detection. To address class imbalance within and between batches during training the network, we introduce multi-labeling sampling strategies that further increase accuracy when AUs are relatively sparse. Finally, we provide visualization of the learned AU models, which, to the best of our best knowledge, reveal for the first time how machines see AUs.\"],\n",
    "[621,9,1,\"Mobile multirobot systems play an increasing role in many disciplines. Their capabilities can be used, e.g., to transport workpieces in industrial applications or to support operational forces in search and rescue scenarios, among many others. Depending on the respective application, the hardware design and accompanying software of mobile robots are of various forms, especially for integrating different sensors and actuators. Concerning this design, robots of one system compared to each other can be classified to exclusively be either homogeneous or heterogeneous, both resulting in different system properties. While homogeneously configured systems are known to be robust against failures through redundancy but are highly specialized for specific use cases, heterogeneously designed systems can be used for a broad range of applications but suffer from their specialization, i.e., they can only hardly compensate for the failure of one specialist. Up to now, there has been no known approach aiming to unify the benefits of both these types of system. In this paper, we present our approach to filling this gap by introducing a reference architecture for mobile robots that defines the interplay of all necessary technologies for achieving this goal. We introduce the class of robot systems implementing this architecture as multipotent systems that bring together the benefits of both system classes, enabling homogeneously designed robots to become heterogeneous specialists at runtime. When many of these robots work together, we call the structure of this cooperation an ensemble. To achieve multipotent ensembles, we also integrate reconfigurable and self-descriptive hardware (i.e., sensors and actuators) in this architecture, which can be freely combined to change the capabilities of robots at runtime. Because typically a high degree of autonomy in such systems is a prerequisite for their practical usage, we also present the integration of necessary mechanisms and algorithms for achieving the systems' multipotency. We already achieved the first results with robots implementing our approach of multipotent systems in real-world experiments as well as in a simulation environment, which we present in this paper.\"],\n",
    "[622,0,0,\"PURPOSE: Glioblastoma multiforme treatment is a challenging task in clinical oncology. Convection- enhanced delivery (CED) is showing encouraging but still suboptimal results due to drug leakages. Numerical models can predict drug distribution within the brain, but require retrieving brain physical properties, such as the axon diameter distribution (ADD), through axon architecture analysis. The goal of this work was to provide an automatic, accurate and fast method for axon segmentation in electronic microscopy images based on fully convolutional neural network (FCNN) as to allow automatic ADD computation. METHODS: The segmentation was performed using a residual FCNN inspired by U-Net and Resnet. The FCNN training was performed exploiting mini-batch gradient descent and the Adam optimizer. The Dice coefficient was chosen as loss function. RESULTS: The proposed segmentation method achieved results comparable with already existing methods for axon segmentation in terms of Information Theoretic Scoring ([Formula: see text]) with a faster training (5 h on the deployed GPU) and without requiring heavy post-processing (testing time was 0.2 s with a non-optimized code). The ADDs computed from the segmented and ground-truth images were statistically equivalent. CONCLUSIONS: The algorithm proposed in this work allowed fast and accurate axon segmentation and ADD computation, showing promising performance for brain microstructure analysis for CED delivery optimization.\"],\n",
    "[623,0,0,\"Multiagent activity is commonplace in everyday life and can improve the behavioral efficiency of task performance and learning. Thus, augmenting social contexts with the use of interactive virtual and robotic agents is of great interest across health, sport, and industry domains. However, the effectiveness of human-machine interaction (HMI) to effectively train humans for future social encounters depends on the ability of artificial agents to respond to human coactors in a natural, human-like manner. One way to achieve effective HMI is by developing dynamical models utilizing dynamical motor primitives (DMPs) of human multiagent coordination that not only capture the behavioral dynamics of successful human performance but also, provide a tractable control architecture for computerized agents. Previous research has demonstrated how DMPs can successfully capture human-like dynamics of simple nonsocial, single-actor movements. However, it is unclear whether DMPs can be used to model more complex multiagent task scenarios. This study tested this human-centered approach to HMI using a complex dyadic shepherding task, in which pairs of coacting agents had to work together to corral and contain small herds of virtual sheep. Human-human and human-artificial agent dyads were tested across two different task contexts. The results revealed (i) that the performance of human-human dyads was equivalent to those composed of a human and the artificial agent and (ii) that, using a 'Turing-like' methodology, most participants in the HMI condition were unaware that they were working alongside an artificial agent, further validating the isomorphism of human and artificial agent behavior.\"],\n",
    "[624,0,0,\"Humans are capable of complex manipulation interactions with the environment, relying on the intrinsic adaptability and compliance of their hands. Recently, soft robotic manipulation has attempted to reproduce such an extraordinary behavior, through the design of deformable yet robust end-effectors. To this goal, the investigation of human behavior has become crucial to correctly inform technological developments of robotic hands that can successfully exploit environmental constraint as humans actually do. Among the different tools robotics can leverage on to achieve this objective, deep learning has emerged as a promising approach for the study and then the implementation of neuro-scientific observations on the artificial side. However, current approaches tend to neglect the dynamic nature of hand pose recognition problems, limiting the effectiveness of these techniques in identifying sequences of manipulation primitives underpinning action generation, e.g., during purposeful interaction with the environment. In this work, we propose a vision-based supervised Hand Pose Recognition method which, for the first time, takes into account temporal information to identify meaningful sequences of actions in grasping and manipulation tasks. More specifically, we apply Deep Neural Networks to automatically learn features from hand posture images that consist of frames extracted from grasping and manipulation task videos with objects and external environmental constraints. For training purposes, videos are divided into intervals, each associated to a specific action by a human supervisor. The proposed algorithm combines a Convolutional Neural Network to detect the hand within each video frame and a Recurrent Neural Network to predict the hand action in the current frame, while taking into consideration the history of actions performed in the previous frames. Experimental validation has been performed on two datasets of dynamic hand-centric strategies, where subjects regularly interact with objects and environment. Proposed architecture achieved a very good classification accuracy on both datasets, reaching performance up to 94%, and outperforming state of the art techniques. The outcomes of this study can be successfully applied to robotics, e.g., for planning and control of soft anthropomorphic manipulators.\"],\n",
    "[625,0,0,\"Robots in assisted living (RAL) are an alternative to support families and professional caregivers with a wide range of possibilities to take care of elderly people. Navigation of mobile robots is a challenging problem due to the uncertainty and dynamics of environments found in the context of places for elderly. To accomplish this goal, the navigation system tries to replicate such a complicated process inspired on the perception and judgment of human beings. In this work, we propose a novel nature-inspired control system for mobile RAL navigation using an artificial organic controller enhanced with vision-based strategies such as Hermite optical flow (OF) and convolutional neural networks (CNNs). Particularly, the Hermite OF is employed for obstacle motion detection while CNNs are occupied for obstacle distance estimation. We train the CNN using OF visual features guided by ultrasonic sensor-based measures in a 3D scenario. Our application is oriented to avoid mobile and fixed obstacles using a monocular camera in a simulated environment. For the experiments, we use the robot simulator V-REP, which is an integrated development environment into a distributed control architecture. Security and smoothness metrics as well as quantitative evaluation are computed and analyzed. Results showed that the proposed method works successfully in simulation conditions.\"],\n",
    "[626,0,0,\"BACKGROUND: Surgical resection of tongue cancer may impair swallowing and speech. Knowledge of tongue muscle architecture affected by the resection could aid in patient counseling. Diffusion tensor imaging (DTI) enables reconstructions of muscle architecture in vivo. Reconstructing crossing fibers in the tongue requires a higher-order diffusion model. PURPOSE: To develop a clinically feasible diffusion imaging protocol, which facilitates both DTI and constrained spherical deconvolution (CSD) reconstructions of tongue muscle architecture in vivo. STUDY TYPE: Cross-sectional study. SUBJECTS/SPECIMEN: One ex vivo bovine tongue resected en bloc from mandible to hyoid bone. Ten healthy volunteers (mean age 25.5 years; range 21-34 years; four female). FIELD STRENGTH/SEQUENCE: Diffusion-weighted echo planar imaging at 3 T using a high-angular resolution diffusion imaging scheme acquired twice with opposing phase-encoding for B0 -field inhomogeneity correction. The scan of the healthy volunteers was divided into four parts, in between which the volunteers were allowed to swallow, resulting in a total acquisition time of 10 minutes. ASSESSMENT: The ability of resolving crossing muscle fibers using CSD was determined on the bovine tongue specimen. A reproducible response function was estimated and the optimal peak threshold was determined for the in vivo tongue. The quality of tractography of the in vivo tongue was graded by three experts. STATISTICAL TESTS: The within-subject coefficient of variance was calculated for the response function. The qualitative results of the grading of DTI and CSD tractography were analyzed using a multilevel proportional odds model. RESULTS: Fiber orientation distributions in the bovine tongue specimen showed that CSD was able to resolve crossing muscle fibers. The response function could be determined reproducibly in vivo. CSD tractography displayed significantly improved tractography compared with DTI tractography (P = 0.015). DATA CONCLUSION: The 10-minute diffusion imaging protocol facilitates CSD fiber tracking with improved reconstructions of crossing tongue muscle fibers compared with DTI. LEVEL OF EVIDENCE: 2 Technical Efficacy: Stage 1 J. Magn. Reson. Imaging 2019.\"],\n",
    "[627,0,0,\"CDH1 encodes E-cadherin, a key protein in adherens junctions. Given that E-cadherin is involved in major cellular processes such as embryogenesis and maintenance of tissue architecture, it is no surprise that deleterious effects arise from its loss of function. E-cadherin is recognised as a tumour suppressor gene, and it is well established that CDH1 genetic alterations cause diffuse gastric cancer and lobular breast cancer-the foremost manifestations of the hereditary diffuse gastric cancer syndrome. However, in the last decade, evidence has emerged demonstrating that CDH1 mutations can be associated with lobular breast cancer and/or several congenital abnormalities, without any personal or family history of diffuse gastric cancer. To date, no genotype-phenotype correlations have been observed. Remarkably, there are reports of mutations affecting the same nucleotide but inducing distinct clinical outcomes. In this review, we bring together a comprehensive analysis of CDH1-associated disorders and germline alterations found in each trait, providing important insights into the biological mechanisms underlying E-cadherin's pleiotropic effects. Ultimately, this knowledge will impact genetic counselling and will be relevant to the assessment of risk of cancer development or congenital malformations in CDH1 mutation carriers.\"],\n",
    "[628,0,0,\"Brain connectivity networks have been shown to represent gender differences under a number of cognitive tasks. Recently, it has been conjectured that fMRI signals decomposed into different resolutions embed different types of cognitive information. In this paper, we combine multiresolution analysis and connectivity networks to study gender differences under a variety of cognitive tasks, and propose a machine learning framework to discriminate individuals according to their gender. For this purpose, we estimate a set of brain networks, formed at different resolutions while the subjects perform different cognitive tasks. First, we decompose fMRI signals recorded under a sequence of cognitive stimuli into its frequency subbands using Discrete Wavelet Transform (DWT). Next, we represent the fMRI signals by mesh networks formed among the anatomic regions for each task experiment at each subband. The mesh networks are constructed by ensembling a set of local meshes, each of which represents the relationship of an anatomical region as a weighted linear combination of its neighbors. Then, we estimate the edge weights of each mesh by ridge regression. The proposed approach yields 2CL functional mesh networks for each subject, where C is the number of cognitive tasks and L is the number of subband signals obtained after wavelet decomposition. This approach enables one to classify gender under different cognitive tasks and different frequency subbands. The final step of the suggested framework is to fuse the complementary information of the mesh networks for each subject to discriminate the gender. We fuse the information embedded in mesh networks formed for different tasks and resolutions under a three-level fuzzy stacked generalization (FSG) architecture. In this architecture, different layers are responsible for fusion of diverse information obtained from different cognitive tasks and resolutions. In the experimental analyses, we use Human Connectome Project task fMRI dataset. Results reflect that fusing the mesh network representations computed at multiple resolutions for multiple tasks provides the best gender classification accuracy compared to the single subband task mesh networks or fusion of representations obtained using only multitask or only multiresolution data. Besides, mesh edge weights slightly outperform pairwise correlations between regions, and significantly outperform raw fMRI signals. In addition, we analyze the gender discriminative power of mesh edge weights for different tasks and resolutions.\"],\n",
    "[629,0,0,\"Heliaphen is an outdoor platform designed for high-throughput phenotyping. It allows the automated management of drought scenarios and monitoring of plants throughout their lifecycles. A robot moving between plants growing in 15-L pots monitors the plant water status and phenotypes the leaf or whole-plant morphology. From these measurements, we can compute more complex traits, such as leaf expansion (LE) or transpiration rate (TR) in response to water deficit. Here, we illustrate the capabilities of the platform with two practical cases in sunflower (Helianthus annuus): a genetic and genomic study of the response of yield-related traits to drought, and a modeling study using measured parameters as inputs for a crop simulation. For the genetic study, classical measurements of thousand-kernel weight (TKW) were performed on a biparental population under automatically managed drought stress and control conditions. These data were used for an association study, which identified five genetic markers of the TKW drought response. A complementary transcriptomic analysis identified candidate genes associated with these markers that were differentially expressed in the parental backgrounds in drought conditions. For the simulation study, we used a crop simulation model to predict the impact on crop yield of two traits measured on the platform (LE and TR) for a large number of environments. We conducted simulations in 42 contrasting locations across Europe using 21 years of climate data. We defined the pattern of abiotic stresses occurring at the continental scale and identified ideotypes (i.e., genotypes with specific trait values) that are more adapted to specific environment types. This study exemplifies how phenotyping platforms can assist the identification of the genetic architecture controlling complex response traits and facilitate the estimation of ecophysiological model parameters to define ideotypes adapted to different environmental conditions.\"],\n",
    "[630,0,0,\"Finding sources of airborne chemicals with mobile sensing systems finds applications across safety, security, environmental monitoring, and medical domains. In this paper, we present an algorithm based on Source Term Estimation for odor source localization that is coupled with a navigation method based on partially observable Markov decision processes. We propose a novel strategy to balance exploration and exploitation in navigation. Moreover, we study two variants of the algorithm, one exploiting a global and the other one a local framework. The method was evaluated through high-fidelity simulations and in a wind tunnel emulating a quasi-laminar air flow in a controlled environment, in particular by systematically investigating the impact of multiple algorithmic and environmental parameters (wind speed and source release rate) on the overall performance. The outcome of the experiments showed that the algorithm is robust to different environmental conditions in the global framework, but, in the local framework, it is only successful in relatively high wind speeds. In the local framework, on the other hand, the algorithm is less demanding in terms of energy consumption as it does not require any absolute positioning information from the environment and the robot travels less distance compared to the global framework.\"],\n",
    "[631,0,0,\"Robotic weed control has seen increased research of late with its potential for boosting productivity in agriculture. Majority of works focus on developing robotics for croplands, ignoring the weed management problems facing rangeland stock farmers. Perhaps the greatest obstacle to widespread uptake of robotic weed control is the robust classification of weed species in their natural environment. The unparalleled successes of deep learning make it an ideal candidate for recognising various weed species in the complex rangeland environment. This work contributes the first large, public, multiclass image dataset of weed species from the Australian rangelands; allowing for the development of robust classification methods to make robotic weed control viable. The DeepWeeds dataset consists of 17,509 labelled images of eight nationally significant weed species native to eight locations across northern Australia. This paper presents a baseline for classification performance on the dataset using the benchmark deep learning models, Inception-v3 and ResNet-50. These models achieved an average classification accuracy of 95.1% and 95.7%, respectively. We also demonstrate real time performance of the ResNet-50 architecture, with an average inference time of 53.4 ms per image. These strong results bode well for future field implementation of robotic weed control methods in the Australian rangelands.\"],\n",
    "[632,0,0,\"The emerging demographic trends toward an aging population, demand new ways and solutions to improve the quality of elderly life. These include, prolonged independent living, improved health care, and reduced social isolation. Recent technological advances in the field of assistive robotics bring higher sophistication and various assistive abilities that can help in achieving these goals. In this paper, we present design and validation of a low-cost telepresence robot that can assist the elderly and their professional caregivers, in everyday activities. The developed robot structure and its control objectives were tested in, both, a simulation and experimental environment. On-field experiments were done in a private elderly care center involving elderly persons and caregivers as participants. The goal of the evaluation study was to test the software architecture and the robot capabilities for navigation, as well as the robot manipulator. Moreover, participants' reactions toward a possible adoption of the developed robot system in everyday activities were assessed. The obtained results of the conducted evaluation study are also presented and discussed.\"],\n",
    "[633,0,0,\"The persistent surveillance problem has been proved to be an NP hard problem for multiple unmanned aerial vehicle systems (UAVs). However, most studies in multiple UAV control focus on control cooperative path planning in a single swarm, while dynamic deployment of a multiswarm system is neglected. This paper proposes a collective control scheme to drive a multiswarm UAVs system to spread out over a time-sensible environment to provide persistent adaptive sensor coverage in event-related surveillance scenarios. We design the digital turf model to approximate the mixture information of mission requirements and surveillance reward. Moreover, we design a data clustering-based algorithm for the dynamic assignment of UAV swarms, which can promote workload balance, while also allowing real-time response to emergencies. Finally, we evaluate the proposed architecture by means of simulation and find that our method is superior to the conventional control strategy in terms of detection efficiency and subswarm equilibrium degree.\"],\n",
    "[634,0,0,\"Tough, biological materials (e.g., collagen or titin) protect tissues from irreversible damage caused by external loads. Mimicking these protective properties is important in packaging and in emerging applications such as durable electronic skins and soft robotics. This paper reports the formation of tough, metamaterial-like core-shell fibers that maintain stress at the fracture strength of a metal throughout the strain of an elastomer. The shell experiences localized strain enhancements that cause the higher modulus core to fracture repeatedly, increasing the energy dissipated during extension. Normally, fractures are catastrophic. However, in this architecture, the fractures are localized to the core. In addition to dissipating energy, the metallic core provides electrical conductivity and enables repair of the fractured core for repeated use. The fibers are 2.5 times tougher than titin and hold more than 15,000 times their own weight for a period 100 times longer than a hollow elastomeric fiber.\"],\n",
    "[635,0,0,\"Polymeric microstructures (PMs) are useful to a broad range of technologies applicable to, for example, sensing, energy storage, and soft robotics. Due to the diverse application space of PMs, many techniques (e. g., photolithography, 3D printing, micromilling, etc.) have been developed to fabricate these structures. Stemming from their generality and unique capabilities, the tools encompassed by soft lithography (e. g., replica molding, microcontact printing, etc.), which use soft elastomeric materials as masters in the fabrication of PMs, are particularly relevant. By taking advantage of the characteristics of elastomeric masters, particularly their mechanical and chemical properties, soft lithography has enabled the use of non-planar substrates and relatively inexpensive equipment in the generation of many types of PMs, redefining existing communities and creating new ones. Traditionally, these elastomeric masters have been produced from relief patterns fabricated using photolithography; however, recent efforts have led to the emergence of new methods that make use of masters that are self-forming, dynamic in their geometric and chemical properties, 3D in architecture, and/or sacrificial (i. e., easily removed/released using phase changes). These 'next generation' soft lithographic masters include self-assembled liquid droplets, microscale balloons, templates derived from natural materials, and hierarchically microstructured surfaces. The new methods of fabrication supported by these unique masters enable access to numerous varieties of PMs (e. g., those with hierarchical microstructures, overhanging features, and 3D architectures) that would not be possible following established methods of soft lithography. This review explores these emergent soft lithographic methods, addressing their operational principles and the application space they can impact.\"],\n",
    "[636,0,0,\"Make and model recognition (MMR) of vehicles plays an important role in automatic vision-based systems. This paper proposes a novel deep learning approach for MMR using the SqueezeNet architecture. The frontal views of vehicle images are first extracted and fed into a deep network for training and testing. The SqueezeNet architecture with bypass connections between the Fire modules, a variant of the vanilla SqueezeNet, is employed for this study, which makes our MMR system more efficient. The experimental results on our collected large-scale vehicle datasets indicate that the proposed model achieves 96.3% recognition rate at the rank-1 level with an economical time slice of 108.8 ms. For inference tasks, the deployed deep model requires less than 5 MB of space and thus has a great viability in real-time applications.\"],\n",
    "[637,0,0,\"The advent of autonomous navigation, positioning, and general robotics technologies has enabled the improvement of small to miniature-sized unmanned aerial vehicles (UAVs, or 'drones') and their wide uses in engineering practice. Recent research endeavors further envision a systematic integration of aerial drones and traditional contact-based or ground-based sensors, leading to an aerial(-)ground wireless sensor network (AG-WSN), in which the UAV serves as both a gateway besides and a remote sensing platform. This paper serves two goals. First, we will review the recent development in architecture, design, and algorithms related to UAVs as a gateway and particularly illustrate its nature in realizing an opportunistic sensing network. Second, recognizing the opportunistic sensing need, we further aim to focus on achieving energy efficiency through developing an active radio frequency (RF)-based wake-up mechanism for aerial(-)ground data transmission. To prove the effectiveness of energy efficiency, several sensor wake-up solutions are physically implemented and evaluated. The results show that the RF-based wake-up mechanism can potentially save more than 98.4% of the energy that the traditional duty-cycle method would otherwise consume, and 96.8% if an infrared-receiver method is used.\"],\n",
    "[638,0,0,\"PURPOSE: Surgical robotics has developed throughout the past 30 years resulting in more than 5000 different approaches proposed for various surgical disciplines supporting different surgical task sequences and differing ways of human-machine cooperation or degrees of automation. However, this diversity of systems influences cost as well as usability and might hinder their widespread adoption. In combination with the current trend toward open and modular 'plug and play' dynamic networks of medical devices and IT systems in the operating room, a modular human-robot system design with versatile access to cooperative functions with varying degrees of automation on demand is desirable. Therefore, standardized robotic device profiles describing essential functional characteristics of cooperative robotic systems are mandatory. METHODS: Surgical robotics is analyzed from a human-machine interaction perspective to identify generic cooperative robotic device profiles, features and use cases. Therefore, cooperative aspects are introduced from a general point of view. Relevant communication channels used for human-machine interaction are then analyzed, referenced by surgical scenarios. Subsequently, proposed classifications of surgical task sequences and surgical robotic systems are analyzed with a focus on a modular design for cooperative robotics in surgery. RESULTS: Considerations based on cooperative guidelines are given and features are identified and summarized in a classification scheme used to define distinct generic cooperative robotic device profiles. The latter can be the basis for a modular architecture of future surgical robot systems. CONCLUSION: Modular system design can be expanded toward functionalities or different degrees of autonomy, shared or manual control. The proposed device profiles of cooperative surgical robots could lay the foundation for integration into open and modular dynamic 'plug and play' networks in the operating room to enhance versatility, benefit-to-cost ratio and, thereby, market spread of surgical robotics.\"],\n",
    "[639,0,0,\"Trust is a critical issue in human-robot interactions: as robotic systems gain complexity, it becomes crucial for them to be able to blend into our society by maximizing their acceptability and reliability. Various studies have examined how trust is attributed by people to robots, but fewer have investigated the opposite scenario, where a robot is the trustor and a human is the trustee. The ability for an agent to evaluate the trustworthiness of its sources of information is particularly useful in joint task situations where people and robots must collaborate to reach shared goals. We propose an artificial cognitive architecture based on the developmental robotics paradigm that can estimate the trustworthiness of its human interactors for the purpose of decision making. This is accomplished using Theory of Mind (ToM), the psychological ability to assign to others beliefs and intentions that can differ from one's owns. Our work is focused on a humanoid robot cognitive architecture that integrates a probabilistic ToM and trust model supported by an episodic memory system. We tested our architecture on an established developmental psychological experiment, achieving the same results obtained by children, thus demonstrating a new method to enhance the quality of human and robot collaborations. This article is part of the theme issue 'From social brains to social robots: applying neurocognitive insights to human-robot interaction'.\"],\n",
    "[640,0,0,\"Possessing a sense of touch is fundamental for robots to operate outside controlled environments. Nevertheless, pressure and force-sensing technologies are still less mature than vision or proprioception solutions in commercial robots. In this study we present a novel spatially resolved force sensor that allows dynamic measurement of both the intensity and the direction of forces exerted on a custom-shaped surface. Originally designed for biomechanics of arboreal primates, this sensor meets several challenges in engineering robotic skin. Of importance, its ability to measure tangential forces would be instrumental for robotic hands to grasp deformable and unknown objects. Based on optical measurements of deformations, this array sensor presents a soft, biocompatible, weather resistant body, immune to electromagnetic interferences. Central to the cost-effectiveness of this solution is an architecture where a single image sensor handles hundreds of force measurement points simultaneously. We demonstrate the performance of this sensor in reconstructing normal and slantwise forces on a flat prototype adapted to forces under 3 N. Finally, we discuss the broad range of possible customizations and extensions for applications in biomechanics and robotics.\"],\n",
    "[641,0,0,\"AIM: The aim of this review paper is to summarize recent developments and research in robotics, relevant to the field of ankle rehabilitation, to overview new findings and determine the actual state of the art. METHOD: The literature search was performed using scientific and medical databases (Scopus, PubMed and Web of Science) and other websites related to robots used in the area of ankle rehabilitation, analysing studies from 1950s to present. Information about the mechanical and kinematic specifications, actuation and stage of development was extracted from the selected literature. RESULTS: Several types of rehabilitation robots have been considered, and they were classified depending on their architecture and design features. We we found that, regardless of the differences in architectures, only a few of them have been commercialized. The majority of rehabilitation robots designs allows plantarflexion-dorsiflexion movements. Unless some exceptions, most of the wearable robots do not allow the adduction-abduction movement. Neither the physical appearance of the robot nor the user's perception towards it has not regularly been taken into account in the design stage. This limits the possibility of successful commercialization. CONCLUSIONS: Up to the present moment, the main challenges in the field of robot rehabilitation are the lack of unique rehabilitation protocols capable to fulfil the needs of all types of patients and the additional resources to measure the effectiveness of proposals that have not yet been commercialized. Nonetheless, we have mentioned above three areas were the challenges in design are more pressing. The first one is the robot architecture, which still presents some incommodities nowadays to emulate the ankle joint movement in a natural way. Thus, the displacements experienced by the axes in the joint must be adaptable to each patient and a wide range of pathologies. Moreover, many proposals are not been conceived to the purpose of commercialization, and even less to become an object of personal use. Implications for rehabilitation This review states that the use of robotic devices for ankle rehabilitation is a consolidated paradigm in the ankle's rehabilitation. Platform-based robots allow to do complex and specialized spatial movements and these architectures endow the device with high stiffness, a balanced force distribution and better adaptability to the mechanical properties of human ankle joints. Unless some exceptions, most of the wearable robots do not allow the adduction-abduction movement. For a full integration of these technologies in the ankle's rehabilitation field, more clinical evaluations are needed. Regardless of the potential of robotic devices in rehabilitation, only a few of them have been commercialized.\"],\n",
    "[642,0,0,\"The dynamic response of gas sensors based on poly(3-hexylthiophene) (P3HT) nanofibers(NFs) to gaseous acetone was assessed using a setup based on flow-injection analysis, aimed atemulating actual breath exhalation. The setup was validated by using a commercially available sensor.The P3HT NFs sensors tested in dynamic flow conditions showed satisfactory reproducibility down toabout 3.5 ppm acetone concentration, a linear response over a clinically relevant concentration range(3.5-35 ppm), excellent baseline recovery and reversibility upon repeated exposures to the analyte,short pulse rise and fall times (less than 1 s and about 2 s, respectively) and low power consumption(few nW), with no relevant response to water. Comparable responses' decay times under eithernitrogen or dry air suggest that the mechanisms at work is mainly attributable to specific analytesemiconductingpolymer interactions. These results open the way to the use of P3HT NFs-basedsensing elements for the realization of portable, real-time electronic noses for on-the-fly exhaledbreath analysis.\"],\n",
    "[643,0,0,\"Electroactive ionic soft actuators, a type of artificial muscles containing a polymer electrolyte membrane sandwiched between two electrodes, have been intensively investigated owing to their potential applications to bioinspired soft robotics, wearable electronics, and active biomedical devices. However, the design and synthesis of an efficient polymer electrolyte suitable for ion migration have been major challenges in developing high-performance ionic soft actuators. Herein, a highly bendable ionic soft actuator based on an unprecedented block copolymer is reported, i.e., polystyrene-b-poly(1-ethyl-3-methylimidazolium-4-styrenesulfonate) (PS-b-PSS-EMIm), with a functionally antagonistic core-shell architecture that is specifically designed as an ionic exchangeable polymer electrolyte. The corresponding actuator shows exceptionally good actuation performance, with a high displacement of 8.22 mm at an ultralow voltage of 0.5 V, a fast rise time of 5 s, and excellent durability over 14 000 cycles. It is envisaged that the development of this high-performance ionic soft actuator could contribute to the progress toward the realization of the aforementioned applications. Furthermore, the procedure described herein can also be applied for developing novel polymer electrolytes related to solid-state lithium batteries and fuel cells.\"],\n",
    "[644,0,0,\"4D printing represents one of the most advanced fabrication techniques for prospective applications in tissue engineering, biomedical devices, and soft robotics, among others. In this study, a novel multiresponsive architecture is developed through stereolithography-based 4D printing, where a universal concept of stress-induced shape transformation is applied to achieve the 4D reprogramming. The light-induced graded internal stress followed by a subsequent solvent-induced relaxation, driving an autonomous and reversible change of the programmed configuration after printing, is employed and investigated in depth and details. Moreover, the fabricated construct possesses shape memory property, offering a characteristic of multiple shape change. Using this novel multiple responsive 4D technique, a proof-of-concept smart nerve guidance conduit is demonstrated on a graphene hybrid 4D construct providing outstanding multifunctional characteristics for nerve regeneration including physical guidance, chemical cues, dynamic self-entubulation, and seamless integration. By employing this fabrication technique, creating multiresponsive smart architectures, as well as demonstrating application potential, this work paves the way for truly initiation of 4D printing in various high-value research fields.\"],\n",
    "[645,0,0,\"Three-dimensional (3D) object detection has important applications in robotics, automatic loading, automatic driving and other scenarios. With the improvement of devices, people can collect multi-sensor/multimodal data from a variety of sensors such as Lidar and cameras. In order to make full use of various information advantages and improve the performance of object detection, we proposed a Complex-Retina network, a convolution neural network for 3D object detection based on multi-sensor data fusion. Firstly, a unified architecture with two feature extraction networks was designed, and the feature extraction of point clouds and images from different sensors realized synchronously. Then, we set a series of 3D anchors and projected them to the feature maps, which were cropped into 2D anchors with the same size and fused together. Finally, the object classification and 3D bounding box regression were carried out on the multipath of fully connected layers. The proposed network is a one-stage convolution neural network, which achieves the balance between the accuracy and speed of object detection. The experiments on KITTI datasets show that the proposed network is superior to the contrast algorithms in average precision (AP) and time consumption, which shows the effectiveness of the proposed network.\"],\n",
    "[646,0,0,\"Most automated facial expression analysis methods treat the face as a 2D object, flat like a sheet of paper. That works well provided images are frontal or nearly so. In real- world conditions, moderate to large head rotation is common and system performance to recognize expression degrades. Multi-view Convolutional Neural Networks (CNNs) have been proposed to increase robustness to pose, but they require greater model sizes and may generalize poorly across views that are not included in the training set. We propose FACSCaps architecture to handle multi-view and multi-label facial action unit (AU) detection within a single model that can generalize to novel views. Additionally, FACSCaps's ability to synthesize faces enables insights into what is leaned by the model. FACSCaps models video frames using matrix capsules, where hierarchical pose relationships between face parts are built into internal representations. The model is trained by jointly optimizing a multi-label loss and the reconstruction accuracy. FACSCaps was evaluated using the FERA 2017 facial expression dataset that includes spontaneous facial expressions in a wide range of head orientations. FACSCaps outperformed both state-of-the-art CNNs and their temporal extensions.\"],\n",
    "[647,0,0,\"The following is a study of the performance of soft cable-driven polymer actuators produced by multimaterial 3D printing. We demonstrate that the mechanical response of the polymer actuator with an embedded cable can be flexibly tuned through the targeted selection of actuator architecture. Various strategies, such as the addition of discrete or periodic stiff inserts, the sectioning of the actuator, or the shifting of the cable channel are employed to demonstrate ways to achieve more controllable deformed shape during weight lifting or reduce the required actuation force. To illustrate these concepts, we design and manufacture a prototype of the soft polymer gripper, which is capable of manipulating small, delicate objects. The explored strategies can be utilized in other types of soft actuators, employing, for instance, actuation by means of electroactive polymers.\"],\n",
    "[648,0,0,\"Generative conversational systems consisting of a neural network-based structural model and a linguistic model have always been considered to be an attractive area. However, conversational systems tend to generate single-turn responses with a lack of diversity and informativeness. For this reason, the conversational system method is further developed by modeling and analyzing the joint structural and linguistic model, as presented in the paper. Firstly, we establish a novel dual-encoder structural model based on the new Convolutional Neural Network architecture and strengthened attention with intention. It is able to effectively extract the features of variable-length sequences and then mine their deep semantic information. Secondly, a linguistic model combining the maximum mutual information with the foolish punishment mechanism is proposed. Thirdly, the conversational system for the joint structural and linguistic model is observed and discussed. Then, to validate the effectiveness of the proposed method, some different models are tested, evaluated and compared with respect to Response Coherence, Response Diversity, Length of Conversation and Human Evaluation. As these comparative results show, the proposed method is able to effectively improve the response quality of the generative conversational system.\"],\n",
    "[649,0,0,\"Tremendous progress has been made with continually expanding genomics technologies to unravel and understand crop genomes. However, the impact of genomics data on crop improvement is still far from satisfactory, in large part due to a lack of effective phenotypic data; our capacity to collect useful high quality phenotypic data lags behind the current capacity to generate high-throughput genomics data. Thus, the research bottleneck in plant sciences is shifting from genotyping to phenotyping. This article review the current status of efforts made in the last decade to systematically collect phenotypic data to alleviate this 'phenomics bottlenecks' by recording trait data through sophisticated non-invasive imaging, spectroscopy, image analysis, robotics, high-performance computing facilities and phenomics databases. These modern phenomics platforms and tools aim to record data on traits like plant development, architecture, plant photosynthesis, growth or biomass productivity, on hundreds to thousands of plants in a single day, as a phenomics revolution. It is believed that this revolution will provide plant scientists with the knowledge and tools necessary for unlocking information coded in plant genomes. Efforts have been also made to present the advances made in the last 10 years in phenomics platforms and their use in generating phenotypic data on different traits in several major crops including rice, wheat, barley, and maize. The article also highlights the need for phenomics databases and phenotypic data sharing for crop improvement. The phenomics data generated has been used to identify genes/QTL through QTL mapping, association mapping and genome-wide association studies (GWAS) for genomics-assisted breeding (GAB) for crop improvement.\"],\n",
    "[650,0,0,\"Three-dimensional (3D) tissue models replicating liver architectures and functions are increasingly being needed for regenerative medicine. However, traditional studies are focused on establishing 2D environments for hepatocytes culture since it is challenging to recreate biodegradable 3D tissue-like architecture at a micro scale by using hydrogels. In this paper, we utilized a gelatin methacryloyl (GelMA) hydrogel as a matrix to construct 3D lobule-like microtissues for co-culture of hepatocytes and fibroblasts. GelMA hydrogel with high cytocompatibility and high structural fidelity was determined to fabricate hepatocytes encapsulated micromodules with central radial-type hole by photo-crosslinking through a digital micromirror device (DMD)-based microfluidic channel. The cellular micromodules were assembled through non-contact pick-up strategy relying on local fluid-based micromanipulation. Then the assembled micromodules were coated with fibroblast-laden GelMA, subsequently irradiated by ultraviolet for integration of the 3D lobule-like microtissues encapsulating multiple cell types. With long-term co-culture, the 3D lobule-like microtissues encapsulating hepatocytes and fibroblasts maintained over 90% cell viability. The liver function of albumin secretion was enhanced for the co-cultured 3D microtissues compared to the 3D microtissues encapsulating only hepatocytes. Experimental results demonstrated that 3D lobule-like microtissues fabricated by GelMA hydrogels capable of multicellular co-culture with high cell viability and liver function, which have huge potential for liver tissue engineering and regenerative medicine applications.\"],\n",
    "[651,0,0,\"Biological tissues are multiresponsive and functional, and similar properties might be possible in synthetic systems by merging responsive polymers with hierarchical soft architectures. For example, mechanochromic polymers have applications in force-responsive colorimetric sensors and soft robotics, but their integration into sensitive, multifunctional devices remains challenging. Herein, a hierarchical nanoparticle-in-micropore (NP-MP) architecture in porous mechanochromic polymers, which enhances the mechanosensitivity and stretchability of mechanochromic electronic skins (e-skins), is reported. The hierarchical NP-MP structure results in stress-concentration-induced mechanochemical activation of mechanophores, significantly improving the mechanochromic sensitivity to both tensile strain and normal force (critical tensile strain: 50% and normal force: 1 N). Furthermore, the porous mechanochromic composites exhibit a reversible mechanochromism under a strain of 250%. This architecture enables a dual-mode mechanochromic e-skin for detecting static/dynamic forces via mechanochromism and triboelectricity. The hierarchical NP-MP architecture provides a general platform to develop mechanochromic composites with high sensitivity and stretchability.\"],\n",
    "[652,0,0,\"To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org.proxy.library.dmu.ac.uk/10.1016/j.mechatronics.2017.04.005 In this paper we introduce a novel cloud robotics architecture that provides different functionalities to support enhanced coordination of groups of Automated Guided Vehicles (AGVs) used for industrial logistics. In particular, we define a cooperative data fusion system that, gathering data from different sensing sources, provides a constantly updated global live view of the industrial environment, for coordinating the motion of the AGVs in an optimized manner. In fact, local sensing capabilities are complemented with global information, thus extending the field of view of each AGV. This knowledge extension allows to support a cooperative and flexible global route assignment and local path planning in order to avoid congestion zones, obstacles reported in the global live view map and deal with unexpected obstacles in the current path. The proposed methodology is validated in a real industrial environment, allowing an AGV to safely perform an obstacle avoidance procedure.; In this paper we introduce a novel cloud robotics architecture that provides different functionalities to support enhanced coordination of groups of Automated Guided Vehicles (AGVs) used for industrial logistics. In particular, we define a cooperative data fusion system that, gathering data from different sensing sources, provides a constantly updated global live view of the industrial environment, for coordinating the motion of the AGVs in an optimized manner. In fact, local sensing capabilities are complemented with global information, thus extending the field of view of each AGV. This knowledge extension allows to support a cooperative and flexible global route assignment and local path planning in order to avoid congestion zones, obstacles reported in the global live view map and deal with unexpected obstacles in. the current path. The proposed methodology is validated in a real industrial environment, allowing an AGV to safely perform an obstacle avoidance procedure. (c) 2017 Elsevier Ltd. All rights reserved.; In this paper we introduce a novel cloud robotics architecture that provides different functionalities to support enhanced coordination of groups of Automated Guided Vehicles (AGVs) used for industrial logistics. In particular, we define a cooperative data fusion system that, gathering data from different sensing sources, provides a constantly updated global live view of the industrial environment, for coordinating the motion of the AGVs in an optimized manner. In fact, local sensing capabilities are complemented with global information, thus extending the field of view of each AGV. This knowledge extension allows to support a cooperative and flexible global route assignment and local path planning in order to avoid congestion zones, obstacles reported in the global live view map and deal with unexpected obstacles in the current path. The proposed methodology is validated in a real industrial environment, allowing an AGV to safely perform an obstacle avoidance procedure.\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(database)):\n",
    "    if database[i][FIELD_BzNDX_INT_CLASS] == 0:\n",
    "        database[i][FIELD_BzNDX_ABSTRACT] = EMPTY_DOCUMENT_VALUE\n",
    "    else:\n",
    "        print(\"Keeping\",i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
