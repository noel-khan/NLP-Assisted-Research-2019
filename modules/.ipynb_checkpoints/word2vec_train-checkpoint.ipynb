{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEGIN train smart-filer_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                               # perf mon \n",
    "import gensim.models.word2vec as w2v      # semantic model\n",
    "import multiprocessing                    # required by w2v\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL OVERRIDES FOR DEV + TEST\n",
    "#USERARG_QTY_FEATURES        = 300\n",
    "#USERARG_QTY_MINWORDS        = 3\n",
    "#USERARG_SIZE_CONTEXT        = 7\n",
    "#USERARG_DOWNSAMPLING        = 1e-3   # 1e-5\n",
    "#USERARG_RANDOMNOSEED        = 1 # to debug else x\n",
    "\n",
    "#%run ./common_preprocessor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_trn_filename():\n",
    "    W2V_USERARG_PATH='models/w2v__arg' \n",
    "    W2V_USERARG_PATH+='-dblim=' + str(USERARG_RECORD_LIMITER) \n",
    "    W2V_USERARG_PATH+='-pos=' + str(USERARG_FILTER_POS) \n",
    "    W2V_USERARG_PATH+='-lim=' + str(USERARG_FILTER_WORDS)\n",
    "    W2V_USERARG_PATH+='-fea=' + str(USERARG_QTY_FEATURES) \n",
    "    W2V_USERARG_PATH+='-min=' + str(USERARG_QTY_MINWORDS) \n",
    "    W2V_USERARG_PATH+='-wnd=' + str(USERARG_SIZE_CONTEXT) \n",
    "    W2V_USERARG_PATH+='-sam=' + str(USERARG_DOWNSAMPLING) \n",
    "    W2V_USERARG_PATH += '-db='  + USERARG_DATABASEFILE\n",
    "    W2V_USERARG_PATH+='.model'\n",
    "    return W2V_USERARG_PATH\n",
    "\n",
    "def get_list_of_wordlists():\n",
    "    print(\"\\tCompiling list of word-lists from database[FIELD_BzNDX_ABSTRACT_WORDS]...\")\n",
    "    iTime = time.time()\n",
    "    return [ record[FIELD_BzNDX_ABSTRACT_WORDS] for record in database[0:] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate VARIABLES\n",
    "_sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompiling sentences...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'database' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b1eb9e0dbb94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0miTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0m_sentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mFIELD_BzNDX_ABSTRACT_WORDS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\tCompleted in\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0miTime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"seconds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'database' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\tCompiling sentences...\")\n",
    "iTime = time.time()\n",
    "\n",
    "_sentences = list([database[i][FIELD_BzNDX_ABSTRACT_WORDS] for i in range(len(database))])\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tInitializing word2vec model...\")\n",
    "iTime = time.time()\n",
    "\n",
    "model_w2v = w2v.Word2Vec(\n",
    "    sg          = 1, # Skip-Gram=1 ELSE CBOW=0\n",
    "    seed        = USERARG_RANDOMNOSEED,\n",
    "    workers     = multiprocessing.cpu_count(),\n",
    "    size        = USERARG_QTY_FEATURES,\n",
    "    min_count   = USERARG_QTY_MINWORDS,\n",
    "    window      = USERARG_SIZE_CONTEXT,\n",
    "    sample      = USERARG_DOWNSAMPLING\n",
    ")\n",
    "\n",
    "#model_w2v.build_vocab(_sentences)\n",
    "model_w2v.build_vocab(get_list_of_wordlists())\n",
    "\n",
    "print(model_w2v)\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tTraining word2vec model...\")\n",
    "iTime = time.time()\n",
    "\n",
    "model_w2v.train(_sentences, total_examples=model_w2v.corpus_count, epochs=model_w2v.epochs)\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classifier\n",
    "print(\"\\tSaving word2vec model...\")\n",
    "iTime = time.time()\n",
    "model_w2v.save(w2v_trn_filename())\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tINFO\\API: model_w2v.wv.most_similar(<word>) synonyms by proximity\")\n",
    "\n",
    "print(\"\\tAnalyzing keyword proximity-based synonyms...\")\n",
    "iTime = time.time()\n",
    "\n",
    "def most_similar(w):\n",
    "    try:\n",
    "        model_w2v.wv.most_similar(w)\n",
    "    except:\n",
    "        print(\"\")\n",
    "\n",
    "most_similar(\"topology\")\n",
    "# cnns node optimize neat fire connection consequences representing represented neuron\n",
    "\n",
    "most_similar(\"architecture\")\n",
    "#approach present control inspired novel based implemented proposed framework propose\n",
    "\n",
    "most_similar(\"control\")\n",
    "# implemented approach proposed present architecture presented real based controller robot\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tINFO\\API: <IPYTHON>.nearest_similarity_cosmul(s1,e1,e2) = s2, synonyms by vector-math\")\n",
    "\n",
    "print(\"\\tAnalyzing Analogy: 'topology->architecture ~ design->?'...\")\n",
    "iTime = time.time()\n",
    "\n",
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    try:\n",
    "        similarities = model_w2v.wv.most_similar_cosmul(\n",
    "            positive=[end2, start1],\n",
    "            negative=[end1]\n",
    "        )\n",
    "        start2 = similarities[0][0]\n",
    "        print(\"\\t\\t>>{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "        return start2\n",
    "    except:\n",
    "        print(\"\")\n",
    "\n",
    "nearest_similarity_cosmul(\"topology\", \"architecture\", \"design\")\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tINFO\\API: <IPYTHON>.cosine_similar_pairs(s1,e1,e2) = s2, synonyms by vector-differences\")\n",
    "\n",
    "print(\"\\tAnalyzing Cosine Similar Pairs...\")\n",
    "iTime = time.time()\n",
    "\n",
    "\n",
    "def cosine_similar_pairs(start1,end1,end2):\n",
    "    try:\n",
    "        mapping = model_w2v.wv.most_similar_cosmul(\n",
    "            positive=[end2,start1],\n",
    "            negative=[end1]\n",
    "        )\n",
    "        start2 = mapping[0][0]\n",
    "        print(\"\\t\\t>>{start1} is to {end1}, as {start2} is to {end2}\".format(**locals()))\n",
    "        return start2\n",
    "    except:\n",
    "        print(\"\\tERROR: Non-fatal, just couldn't determine cosine-similarity of words:\", start1, \",\",end1,\",\", end2)\n",
    "\n",
    "cosine_similar_pairs(\"topology\", \"architecture\", \"robot\")\n",
    "cosine_similar_pairs(\"architecture\", \"topology\", \"robot\")\n",
    "cosine_similar_pairs(\"control\", \"behavior\", \"function\")\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"END train smart-filer_word2vec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
