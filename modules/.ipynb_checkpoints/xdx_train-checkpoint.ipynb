{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEGIN \", USERARG_TOPIC_MODEL, \"_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                       # performance/completion feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python\n",
    "#%run ./common_preprocessor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "#USERARG_LDA_ITERATIONS=100\n",
    "#USERARG_LDA_CHUNKSIZE=len(database)\n",
    "\n",
    "\n",
    "def xdx_train_filename():\n",
    "    _xDx_FILE  = USERARG_TOPIC_MODEL + '__arg'\n",
    "    _xDx_FILE +='-dblim=' + str(USERARG_RECORD_LIMITER) \n",
    "    _xDx_FILE += '-num=' + str(USERARG_NUMTOPICS)\n",
    "    _xDx_FILE += '-min=' + str(USERARG_NGRAM_MINCOUNT)\n",
    "    _xDx_FILE += '-thr=' + str(USERARG_NGRAM_THRESHOLD)\n",
    "    _xDx_FILE += '-wpt=' + str(USERARG_WORDS_PER_TOPIC)\n",
    "\n",
    "    if USERARG_TOPIC_MODEL=='LDA':\n",
    "        _xDx_FILE += '-itr=' + str(USERARG_LDA_ITERATIONS)\n",
    "        _xDx_FILE += '-chk=' + str(USERARG_LDA_CHUNKSIZE)\n",
    "        \n",
    "    _xDx_FILE += '-db='  + USERARG_DATABASEFILE\n",
    "        \n",
    "    return _xDx_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM SANITIZE\n",
    "def get_list_of_wordlists():\n",
    "    print(\"\\tCompiling list of word-lists from database[FIELD_BzNDX_ABSTRACT_WORDS]...\")\n",
    "    iTime = time.time()\n",
    "    return [ record[FIELD_BzNDX_ABSTRACT_WORDS] for record in database[0:] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tImporting packages...\")\n",
    "iTime = time.time()\n",
    "\n",
    "import re                         # for reformatting xdx report\n",
    "from pprint import pprint\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel, LdaModel, HdpModel, LdaMulticore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tCreating \",USERARG_TOPIC_MODEL,\"-model (takes over a minute)...\")\n",
    "iTime = time.time()\n",
    "\n",
    "#corpus_i2w = from featurize\n",
    "\n",
    "if USERARG_TOPIC_MODEL=='HDP':\n",
    "    model_xdx = gensim.models.hdpmodel.HdpModel(corpus=corpus_i2w, id2word=id2words)\n",
    "    \n",
    "elif USERARG_TOPIC_MODEL=='LDA':\n",
    "    try:\n",
    "        print(\"\\tINFO: Multicore-LDA doesn't use the USERARG_LDA_ITERATIONS argument.\")\n",
    "        model_xdx = LdaMulticore(corpus=corpus_i2w,\n",
    "                                id2word=id2words,\n",
    "                                num_topics=USERARG_NUMTOPICS, \n",
    "                                random_state=100,\n",
    "                                chunksize=USERARG_LDA_CHUNKSIZE,\n",
    "                                passes=USERARG_LDA_ITERATIONS)\n",
    "\n",
    "    except:\n",
    "        print(\"\\tWARN: Multicore-LDA failed. Falling back to the single core implementation...\")\n",
    "        model_xdx = LdaModel(corpus=corpus_i2w,\n",
    "                            id2word=id2words,\n",
    "                            num_topics=USERARG_NUMTOPICS, \n",
    "                            random_state=100,\n",
    "                            update_every=1,                 # iterations between model-param updates\n",
    "                            chunksize=USERARG_LDA_CHUNKSIZE,# qty documents used per training iteration\n",
    "                            passes=USERARG_LDA_ITERATIONS,  # training iterations\n",
    "                            alpha='auto',\n",
    "                            per_word_topics=True)\n",
    "        \n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "print(\"\\t\", USERARG_TOPIC_MODEL,\"report on\",USERARG_NUMTOPICS,\"topics...\")\n",
    "if USERARG_TOPIC_MODEL==\"HDP\":\n",
    "    default_report = model_xdx.print_topics()\n",
    "    print(\"\\tNOTE: HDP found\", len(default_report),\"topics, but only reporting on the top\", USERARG_NUMTOPICS)\n",
    "iTime = time.time()\n",
    "\n",
    "#model_lda.show_topics() #shows... nothing\n",
    "#pprint(model_xdx.print_topics())\n",
    "default_report = model_xdx.print_topics(num_topics=USERARG_NUMTOPICS)\n",
    "\n",
    "# Compute Coherence Score\n",
    "# \"Score model: Model perplexity and topic coherence provide \n",
    "# a convenient measure to judge how good a given topic model is. \n",
    "# In my experience, topic coherence score, in particular, has been \n",
    "# more helpful.\"\n",
    "\n",
    "#ngrams = [ record[FIELD_BzNDX_ABSTRACT_WORDS] for record in database[0:]]\n",
    "ngrams = get_list_of_wordlists()\n",
    "\n",
    "\n",
    "coherence_model = CoherenceModel(model=model_xdx, texts=ngrams, dictionary=id2words, coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "print('\\tINFO: Coherence Score:  ', coherence)\n",
    "\n",
    "if USERARG_TOPIC_MODEL=='LDA':\n",
    "    print('\\tINFO: Perplexity Score: ', model_xdx.log_perplexity(corpus_i2w))  # a measure of how good the model is. lower the better.\n",
    "else:\n",
    "    print(\"\\tINFO:\",USERARG_TOPIC_MODEL,\" doesn't have a perplexity score\")\n",
    "    \n",
    "ngrams = None\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tFormatting\",USERARG_TOPIC_MODEL,\"topic report...\")\n",
    "iTime = time.time()\n",
    "\n",
    "topic_keywords = []\n",
    "new_report = []\n",
    "\n",
    "for pg in default_report: # default_report = [ (#,\"over-puntuated-string\")...]\n",
    "    tokens = re.findall(\"[\\w\\.']+\", pg[1])\n",
    "    topic = []\n",
    "    for i in range(0,len(tokens),2):\n",
    "        keyword_weight = tuple([tokens[i+1], float(tokens[i]) ])\n",
    "        topic.append(keyword_weight)\n",
    "        if tokens[i+1] not in topic_keywords:\n",
    "            topic_keywords.append(tokens[i+1])\n",
    "        \n",
    "    new_report.append( tuple([pg[0], topic]) )\n",
    "topic = None\n",
    "    \n",
    "if USERARG_VERBOSE==1:\n",
    "    print(\"\\tReformatted report:\",new_report)\n",
    "    print(\"\\tTopic keywords:\",topic_keywords)\n",
    "    \n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\",USERARG_TOPIC_MODEL,\"topic analysis...\")\n",
    "iTime = time.time()\n",
    "\n",
    "# visualize topics\n",
    "print(\"\\tTopicKeyword,RawTopicID\", str(list(range(USERARG_NUMTOPICS))))\n",
    "topic_matrix = \"\"\n",
    "found = \"\"\n",
    "for word in topic_keywords:\n",
    "    topic_matrix = \"\\t\\t\" + topic_matrix + word \n",
    "    for topic in new_report:\n",
    "        found = \"\"\n",
    "        for topic_tuple in topic[1]: \n",
    "            if topic_tuple[0] == word:\n",
    "                found = topic_tuple\n",
    "                break\n",
    "        \n",
    "        if found:\n",
    "            topic_matrix = topic_matrix + \",\" + str(found[1])\n",
    "        else:\n",
    "            topic_matrix = topic_matrix + \",\"\n",
    "\n",
    "    topic_matrix = topic_matrix + \"\\n\"\n",
    "\n",
    "topic = None\n",
    "new_report = None\n",
    "    \n",
    "print(\"\\txDx Results (keyword vs topic#)\",topic_matrix)\n",
    "\n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tSaving results...\")\n",
    "iTime = time.time()\n",
    "\n",
    "# save reports\n",
    "_TMP_FILE = 'reports/' + xdx_train_filename() + '_topics.csv'\n",
    "with open(_TMP_FILE, 'w') as filehandle:\n",
    "    filehandle.writelines(\"TopicKeyword,\" + str(list(range(USERARG_NUMTOPICS))) + \"\\n\")\n",
    "    filehandle.writelines(topic_matrix)\n",
    "    print('\\tINFO: xDx topic visualization saved to ' + _TMP_FILE)\n",
    "\n",
    "_TMP_FILE = 'reports/' + xdx_train_filename() + '_topics.lst'\n",
    "with open(_TMP_FILE, 'w') as filehandle:\n",
    "    for topic in default_report:\n",
    "        filehandle.writelines(\",\".join([str(topic[0]), topic[1],\"\\n\"]))\n",
    "    print('\\tINFO: xDx topic listing saved to ' + _TMP_FILE)\n",
    "\n",
    "# save model\n",
    "model_xdx.save('models/' + xdx_train_filename() + '.model')\n",
    "\n",
    "topic = None\n",
    "topic_keywords = None\n",
    "topic_matrix = None\n",
    "    \n",
    "print(\"\\tCompleted in\", round(time.time() - iTime,3),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"END \",USERARG_TOPIC_MODEL,\"_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
